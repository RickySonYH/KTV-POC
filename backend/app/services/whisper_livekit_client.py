# [advice from AI] WhisperLiveKit í´ë¼ì´ì–¸íŠ¸ (í¬íŠ¸ 6470)
# ì‹¤ì‹œê°„ STT ì„œë²„ ì—°ë™ - ë§ˆì´í¬/ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì§€ì›

import os
import asyncio
import json
import subprocess
from typing import AsyncGenerator, Optional
from dataclasses import dataclass
import websockets

from .realtime_stt import RealtimeSubtitle
# [advice from AI] í›„ì²˜ë¦¬ ëª¨ë“ˆ ì„í¬íŠ¸
from .postprocessing import (
    postprocess_text,
    is_hallucination,
    clean_text,
    apply_dictionary_mapping,
)


@dataclass
class WhisperLiveKitConfig:
    """WhisperLiveKit ì„¤ì •"""
    host: str = "localhost"
    port: int = 8000
    sample_rate: int = 16000


class WhisperLiveKitSTT:
    """
    WhisperLiveKit í´ë¼ì´ì–¸íŠ¸
    
    API ìŠ¤í™:
    - WebSocket: ws://<HOST>:<PORT>/asr
    - ì˜¤ë””ì˜¤: PCM int16, mono, 16kHz
    - ì‘ë‹µ: {"lines": [...], "buffer_transcription": "...", "status": "..."}
    """
    
    def __init__(self, config: Optional[WhisperLiveKitConfig] = None):
        self.config = config or WhisperLiveKitConfig(
            host=os.getenv("WHISPER_HOST", "whisper-livekit"),
            port=int(os.getenv("WHISPER_PORT", "8000")),
        )
        self.segment_id = 0
        self.websocket = None
        self.current_audio_time = 0.0
        self.last_lines_count = 0  # ë§ˆì§€ë§‰ìœ¼ë¡œ ì²˜ë¦¬í•œ lines ìˆ˜
    
    def get_ws_uri(self) -> str:
        """WebSocket URI ìƒì„±"""
        return f"ws://{self.config.host}:{self.config.port}/asr"
    
    async def process_audio_stream(
        self,
        input_path: str,
        enable_diarization: bool = True,
        start_offset: float = 0.0,
        sync_mode: bool = False
    ) -> AsyncGenerator[RealtimeSubtitle, None]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ìë§‰ ìƒì„±
        
        Args:
            input_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ (MP4, WAV ë“±)
            enable_diarization: í™”ì ë¶„ë¦¬ í™œì„±í™” (WhisperLiveKitì€ ì„œë²„ì—ì„œ ì„¤ì •)
            start_offset: ì‹œì‘ ìœ„ì¹˜ (ì´ˆ)
            sync_mode: Trueë©´ ì˜ìƒ ì¬ìƒ ì†ë„(1x)ì— ë§ì¶° ì²˜ë¦¬
        
        Yields:
            RealtimeSubtitle: ì‹¤ì‹œê°„ ìë§‰
        """
        self.start_offset = start_offset
        uri = self.get_ws_uri()
        
        print(f"[WLK-STT] ========================================")
        print(f"[WLK-STT] ğŸš€ WhisperLiveKit STT ì‹œì‘")
        print(f"[WLK-STT] URI: {uri}")
        print(f"[WLK-STT] ì…ë ¥: {input_path}")
        print(f"[WLK-STT] â±ï¸ ì‹œì‘ ìœ„ì¹˜: {start_offset}ì´ˆ")
        print(f"[WLK-STT] ğŸ”„ ë™ê¸°í™” ëª¨ë“œ: {sync_mode}")
        print(f"[WLK-STT] ========================================")
        
        results_queue = asyncio.Queue()
        send_done = asyncio.Event()
        self.last_lines_count = 0
        
        try:
            print(f"[WLK-STT] ğŸ”Œ WebSocket ì—°ê²° ì‹œë„: {uri}")
            async with websockets.connect(
                uri, 
                ping_interval=30, 
                ping_timeout=60, 
                close_timeout=10,
                open_timeout=10
            ) as ws:
                print(f"[WLK-STT] âœ… WebSocket ì—°ê²° ì„±ê³µ!")
                
                # config ë©”ì‹œì§€ ëŒ€ê¸°
                try:
                    config_msg = await asyncio.wait_for(ws.recv(), timeout=5.0)
                    config_data = json.loads(config_msg)
                    if config_data.get("type") == "config":
                        use_worklet = config_data.get("useAudioWorklet", False)
                        print(f"[WLK-STT] âš™ï¸ ì„œë²„ ì„¤ì •: useAudioWorklet={use_worklet}")
                except asyncio.TimeoutError:
                    print(f"[WLK-STT] âš ï¸ config ë©”ì‹œì§€ ì—†ìŒ, ê³„ì† ì§„í–‰")
                except Exception as e:
                    print(f"[WLK-STT] âš ï¸ config íŒŒì‹± ì‹¤íŒ¨: {e}")
                
                async def stream_audio():
                    """FFmpegë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œí•˜ì—¬ ì „ì†¡"""
                    nonlocal send_done
                    
                    # PCM 16kHz mono ë³€í™˜
                    ffmpeg_cmd = [
                        'ffmpeg',
                        '-i', input_path,
                        '-ss', str(start_offset),
                        '-vn',
                        '-acodec', 'pcm_s16le',
                        '-ar', str(self.config.sample_rate),
                        '-ac', '1',
                        '-f', 's16le',
                        '-'
                    ]
                    
                    print(f"[WLK-STT] ğŸ¬ FFmpeg ì‹œì‘: {' '.join(ffmpeg_cmd[:6])}...")
                    
                    process = await asyncio.create_subprocess_exec(
                        *ffmpeg_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.DEVNULL
                    )
                    
                    chunk_size = self.config.sample_rate * 2 // 10  # 100ms ì²­í¬
                    bytes_sent = 0
                    
                    try:
                        while True:
                            chunk = await process.stdout.read(chunk_size)
                            if not chunk:
                                break
                            
                            await ws.send(chunk)
                            bytes_sent += len(chunk)
                            
                            # ì˜¤ë””ì˜¤ ì‹œê°„ ê³„ì‚°
                            self.current_audio_time = start_offset + (bytes_sent / (self.config.sample_rate * 2))
                            
                            # ë™ê¸°í™” ëª¨ë“œë©´ ì‹¤ì‹œê°„ ì†ë„ë¡œ
                            if sync_mode:
                                await asyncio.sleep(0.1)
                            else:
                                await asyncio.sleep(0.01)
                        
                        # ì¢…ë£Œ ì‹œê·¸ë„ (ë¹ˆ Blob)
                        await ws.send(b'')
                        print(f"[WLK-STT] ğŸ“¤ ì „ì†¡ ì™„ë£Œ: {bytes_sent / 1024:.1f}KB")
                        
                    except Exception as e:
                        print(f"[WLK-STT] âŒ ì „ì†¡ ì˜¤ë¥˜: {e}")
                    finally:
                        send_done.set()
                        if process.returncode is None:
                            process.kill()
                
                async def receive_results():
                    """ì„œë²„ ì‘ë‹µ ìˆ˜ì‹ """
                    nonlocal send_done
                    
                    try:
                        while True:
                            try:
                                msg = await asyncio.wait_for(ws.recv(), timeout=1.0)
                                data = json.loads(msg)
                                
                                # ready_to_stop ì²˜ë¦¬
                                if data.get("type") == "ready_to_stop":
                                    print(f"[WLK-STT] ğŸ ì²˜ë¦¬ ì™„ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                                    break
                                
                                # config ë¬´ì‹œ
                                if data.get("type") == "config":
                                    continue
                                
                                # ìë§‰ ì²˜ë¦¬
                                lines = data.get("lines", [])
                                buffer_text = data.get("buffer_transcription", "")
                                status = data.get("status", "active_transcription")
                                
                                # ìƒˆë¡œìš´ linesë§Œ ì²˜ë¦¬
                                for i, line in enumerate(lines):
                                    if i >= self.last_lines_count:
                                        raw_text = line.get("text", "").strip()
                                        
                                        # [advice from AI] í›„ì²˜ë¦¬ ì ìš©
                                        # 1. í• ë£¨ì‹œë„¤ì´ì…˜ í•„í„°
                                        if is_hallucination(raw_text):
                                            print(f"[WLK-STT] ğŸš« í• ë£¨ì‹œë„¤ì´ì…˜ í•„í„°: {raw_text[:30]}...")
                                            continue
                                        
                                        # 2. í›„ì²˜ë¦¬ (ì •ë¦¬ + ì‚¬ì „ ë§¤ì¹­ + ë¹„ì†ì–´ í•„í„°)
                                        processed_text = postprocess_text(raw_text)
                                        
                                        if not processed_text:
                                            continue
                                        
                                        self.segment_id += 1
                                        
                                        # [advice from AI] íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ floatë¡œ ë³€í™˜ (ë¬¸ìì—´ì¼ ìˆ˜ ìˆìŒ)
                                        start_time_val = line.get("start", self.current_audio_time)
                                        end_time_val = line.get("end", self.current_audio_time + 3.0)
                                        try:
                                            start_time_float = float(start_time_val) if start_time_val is not None else self.current_audio_time
                                            end_time_float = float(end_time_val) if end_time_val is not None else (self.current_audio_time + 3.0)
                                        except (ValueError, TypeError):
                                            start_time_float = self.current_audio_time
                                            end_time_float = self.current_audio_time + 3.0
                                        
                                        subtitle = RealtimeSubtitle(
                                            id=self.segment_id,
                                            start_time=start_time_float,
                                            end_time=end_time_float,
                                            text=processed_text,
                                            speaker=f"í™”ì{line.get('speaker', 1)}" if line.get("speaker", 0) > 0 else None,
                                            is_final=True
                                        )
                                        
                                        if subtitle.text:
                                            await results_queue.put(subtitle)
                                            print(f"[WLK-STT] ğŸ¤ [{subtitle.start_time:.1f}s] {subtitle.text[:40]}...")
                                
                                self.last_lines_count = len(lines)
                                
                                # ë²„í¼ í…ìŠ¤íŠ¸ë„ ì¤‘ê°„ ê²°ê³¼ë¡œ ì „ì†¡ (ì„ íƒì )
                                if buffer_text and buffer_text.strip():
                                    self.segment_id += 1
                                    buffer_subtitle = RealtimeSubtitle(
                                        id=self.segment_id,
                                        start_time=self.current_audio_time,
                                        end_time=self.current_audio_time + 2.0,
                                        text=buffer_text.strip(),
                                        speaker=None,
                                        is_final=False
                                    )
                                    # ì¤‘ê°„ ê²°ê³¼ëŠ” ì„ íƒì ìœ¼ë¡œ ì „ì†¡
                                    # await results_queue.put(buffer_subtitle)
                                
                            except asyncio.TimeoutError:
                                if send_done.is_set():
                                    break
                                continue
                                
                    except websockets.exceptions.ConnectionClosed:
                        print(f"[WLK-STT] ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ")
                    except Exception as e:
                        print(f"[WLK-STT] âŒ ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
                    
                    await results_queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸
                
                # ì†¡ìˆ˜ì‹  íƒœìŠ¤í¬ ì‹œì‘
                send_task = asyncio.create_task(stream_audio())
                recv_task = asyncio.create_task(receive_results())
                
                # ê²°ê³¼ yield
                while True:
                    result = await results_queue.get()
                    if result is None:
                        break
                    yield result
                
                # ì •ë¦¬
                await send_task
                await recv_task
                
        except ConnectionRefusedError:
            # [advice from AI] websockets.exceptions.ConnectionRefusedError ëŒ€ì‹  í‘œì¤€ ì˜ˆì™¸ ì‚¬ìš©
            print(f"[WLK-STT] âŒ ì—°ê²° ê±°ë¶€ë¨: {uri}")
            print(f"[WLK-STT] WhisperLiveKit ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
        except Exception as e:
            print(f"[WLK-STT] âŒ ì˜¤ë¥˜: {e}")
        
        print(f"[WLK-STT] ğŸ STT ì¢…ë£Œ")
