# [advice from AI] ì‹¤ì‹œê°„ STT - FFmpeg ìŠ¤íŠ¸ë¦¬ë° + HAIV ë³‘ë ¬ ì²˜ë¦¬
# ì‹¤ì‹œê°„ ë°©ì†¡ì²˜ëŸ¼ ì˜¤ë””ì˜¤ê°€ ë‚˜ì˜¤ëŠ” ëŒ€ë¡œ ë°”ë¡œ STT ì²˜ë¦¬

import os
import asyncio
import subprocess
from typing import AsyncGenerator, Optional, Dict, Any
from dataclasses import dataclass


@dataclass
class RealtimeSubtitle:
    """ì‹¤ì‹œê°„ ìë§‰"""
    id: int
    start_time: float
    end_time: float
    text: str
    speaker: Optional[str] = None
    is_final: bool = True


# [advice from AI] HAIV ì—”ì§„ í”„ë¦¬ì…‹ ì„¤ì •
HAIV_PRESETS: Dict[str, Dict[str, Any]] = {
    # ê¸°ì¡´ HAIV (8K)
    "haiv": {
        "host": "haiv.timbel.net:40001",
        "model": "KOREAN_ONLINE_8K",
        "project_id": "2ec95f1c-3b52-4eaa-a29a-6065e2d95d61",
        "byterate": 16000,
        "sample_rate": 16000,
        "name": "HAIV (8K)",
    },
    # ìƒˆ HAIV E2E (16K) - ì‹¤ì‹œê°„
    "haiv_e2e": {
        "host": "49.50.136.163:40001",
        "model": "KOREAN_ONLINE_16K",
        "project_id": "3ab9f7a5-234b-48e6-a794-cb8f826d0f8e",
        "byterate": 32000,
        "sample_rate": 16000,
        "name": "HAIV E2E (16K)",
    },
    # ìƒˆ HAIV Whisper (16K) - ì‹¤ì‹œê°„
    "haiv_whisper": {
        "host": "49.50.136.163:40001",
        "model": "KOREAN_16K_OSTT",
        "project_id": "3ab9f7a5-234b-48e6-a794-cb8f826d0f8e",
        "byterate": 32000,
        "sample_rate": 16000,
        "name": "HAIV Whisper (16K)",
    },
}


class HAIVStreamingSTT:
    """
    HAIV ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT
    - FFmpegë¡œ ì˜¤ë””ì˜¤ë¥¼ ì‹¤ì‹œê°„ ì¶”ì¶œ
    - ì¶”ì¶œë˜ëŠ” ëŒ€ë¡œ ë°”ë¡œ HAIVë¡œ ì „ì†¡
    - ê²°ê³¼ ìˆ˜ì‹  ì¦‰ì‹œ yield
    """
    
    def __init__(self, preset: str = "haiv"):
        """
        Args:
            preset: 'haiv', 'haiv_e2e', 'haiv_whisper' ì¤‘ ì„ íƒ
        """
        self.segment_id = 0
        
        # [advice from AI] í”„ë¦¬ì…‹ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        if preset in HAIV_PRESETS:
            preset_config = HAIV_PRESETS[preset]
            self.config = {
                'host': os.getenv(f"HAIV_{preset.upper()}_URL", preset_config['host']),
                'model': preset_config['model'],
                'project_id': preset_config['project_id'],
                'byterate': preset_config['byterate'],
                'sample_rate': preset_config['sample_rate'],
                'language': 'ko',
                'num_speaker': None,
                'name': preset_config['name'],
            }
        else:
            # ê¸°ë³¸ê°’ (í•˜ìœ„ í˜¸í™˜ì„±)
            self.config = {
                'host': os.getenv("HAIV_URL", "haiv.timbel.net:40001"),
                'model': os.getenv("HAIV_MODEL", "KOREAN_ONLINE_8K"),
                'project_id': os.getenv("HAIV_PROJECT_ID", "2ec95f1c-3b52-4eaa-a29a-6065e2d95d61"),
                'byterate': int(os.getenv("HAIV_BYTERATE", "16000")),
                'sample_rate': 16000,
                'language': 'ko',
                'num_speaker': None,
                'name': 'HAIV (ê¸°ë³¸)',
            }
    
    def _build_uri(self, verbosity: str = "final") -> str:
        """HAIV WebSocket URI
        
        Args:
            verbosity: 'final'(ë¬¸ì¥ ì™„ì„± í›„) / 'partial'(ì‹¤ì‹œê°„ ë¶€ë¶„ ê²°ê³¼)
        """
        uri = f"ws://{self.config['host']}/client/ws/speech"
        uri += f"?model={self.config['model']}"
        if self.config['num_speaker']:
            uri += f"&num-speaker={self.config['num_speaker']}"
        uri += f"&verbosity={verbosity}&lang={self.config['language']}"
        return uri
    
    def get_ws_uri(self, verbosity: str = "final") -> str:
        """ì™¸ë¶€ì—ì„œ WebSocket URI ê°€ì ¸ì˜¤ê¸°"""
        return self._build_uri(verbosity=verbosity)
    
    async def process_video(
        self,
        input_path: str,
        enable_diarization: bool = True,
        start_offset: float = 0.0,
        sync_mode: bool = False
    ) -> AsyncGenerator[RealtimeSubtitle, None]:
        """
        ì˜ìƒì„ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° STT ì²˜ë¦¬
        - FFmpegê°€ ì˜¤ë””ì˜¤ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì¶œ
        - ì¶”ì¶œë˜ëŠ” ëŒ€ë¡œ HAIVë¡œ ë°”ë¡œ ì „ì†¡
        - ê²°ê³¼ ìˆ˜ì‹  ì¦‰ì‹œ yield
        
        Args:
            start_offset: ì‹œì‘ ìœ„ì¹˜ (ì´ˆ) - ì˜ìƒ ì¬ìƒ ìœ„ì¹˜ì™€ ë™ê¸°í™”
            sync_mode: Trueë©´ ì˜ìƒ ì¬ìƒ ì†ë„(1x)ì— ë§ì¶° ì²˜ë¦¬
        """
        import websockets
        import json
        
        print(f"[HAIV-STT] ========================================")
        print(f"[HAIV-STT] ğŸ¬ process_video ì‹œì‘!")
        print(f"[HAIV-STT] ğŸ“ ì…ë ¥ íŒŒì¼: {input_path}")
        print(f"[HAIV-STT] â±ï¸ ì‹œì‘ ìœ„ì¹˜: {start_offset}ì´ˆ")
        print(f"[HAIV-STT] ğŸ”„ ë™ê¸°í™” ëª¨ë“œ: {sync_mode}")
        print(f"[HAIV-STT] ğŸ”§ ì„¤ì •: {self.config}")
        
        # [advice from AI] HAIVëŠ” í•­ìƒ final (ì›ë˜ ì„¤ì • - ê±´ë“œë¦¬ì§€ ì•ŠìŒ!)
        uri = self._build_uri(verbosity="final")
        print(f"[HAIV-STT] ğŸ”— WebSocket URI: {uri}")
        
        try:
            async with websockets.connect(uri, ping_interval=20, ping_timeout=60) as ws:
                print(f"[HAIV-STT] âœ… HAIV ì—°ê²° ì„±ê³µ!")
                
                results_queue = asyncio.Queue()
                send_done = asyncio.Event()
                
                async def stream_audio_to_haiv():
                    """FFmpegë¡œ ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì¶”ì¶œ â†’ HAIV ì „ì†¡"""
                    # [advice from AI] HAIVëŠ” ì›ë³¸ ì˜¤ë””ì˜¤ë¥¼ ê·¸ëŒ€ë¡œ ë°›ìŒ
                    # WAV í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ (í—¤ë” í¬í•¨)
                    ffmpeg_cmd = ['ffmpeg']
                    
                    # [advice from AI] ì‹œì‘ ìœ„ì¹˜ ì§€ì • (ì˜ìƒ ì¬ìƒê³¼ ë™ê¸°í™”)
                    if start_offset > 0:
                        ffmpeg_cmd.extend(['-ss', str(start_offset)])
                    
                    ffmpeg_cmd.extend([
                        '-i', input_path,
                        '-vn',                    # ë¹„ë””ì˜¤ ì œì™¸
                        '-acodec', 'pcm_s16le',   # 16bit PCM
                        '-ar', '16000',           # 16kHz (ì›ë³¸ HAIV í´ë¼ì´ì–¸íŠ¸ì™€ ë™ì¼)
                        '-ac', '1',               # ëª¨ë…¸
                        '-f', 'wav',              # WAV í˜•ì‹ (í—¤ë” í¬í•¨!)
                        '-loglevel', 'error',
                        'pipe:1'                  # stdoutìœ¼ë¡œ ì¶œë ¥
                    ])
                    
                    print(f"[HAIV-STT] ğŸ¬ FFmpeg ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {input_path} (offset: {start_offset}ì´ˆ)")
                    
                    process = await asyncio.create_subprocess_exec(
                        *ffmpeg_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    
                    # [advice from AI] byterate / 4 = 4000 bytes per chunk (0.25ì´ˆ ë¶„ëŸ‰)
                    chunk_size = self.config['byterate'] // 4  # 4000 bytes
                    total_bytes = 0
                    chunk_count = 0
                    
                    # [advice from AI] ë™ê¸°í™” ëª¨ë“œì— ë”°ë¼ ì „ì†¡ ì†ë„ ì¡°ì ˆ
                    if sync_mode:
                        # ì‹¤ì‹œê°„ ëª¨ë“œ: 1x ì†ë„ (ë¼ì´ë¸ŒëŠ” ë¯¸ë˜ ì˜¤ë””ì˜¤ê°€ ì—†ìŒ!)
                        # verbosity=partialë¡œ ë¶€ë¶„ ê²°ê³¼ ì¦‰ì‹œ ì¶œë ¥
                        PREFETCH_CHUNKS = 12  # 3ì´ˆ í”„ë¦¬ë²„í¼
                        CHUNK_DELAY = 0.25    # 1x ì†ë„ (0.25ì´ˆ ì²­í¬ë¥¼ 0.25ì´ˆ ê°„ê²©ìœ¼ë¡œ)
                    else:
                        # âš¡ íŒŒì¼ ëª¨ë“œ: sleep ì—†ì´ ìµœëŒ€í•œ ë¹ ë¥´ê²Œ!
                        PREFETCH_CHUNKS = 9999  # ë¬´ì œí•œ í”„ë¦¬ë²„í¼
                        CHUNK_DELAY = 0.0       # sleep ì—†ìŒ!
                    
                    try:
                        while True:
                            chunk = await process.stdout.read(chunk_size)
                            if not chunk:
                                break
                            
                            await ws.send(chunk)
                            total_bytes += len(chunk)
                            chunk_count += 1
                            
                            # [advice from AI] ì „ì†¡ ì†ë„ ì¡°ì ˆ
                            if chunk_count <= PREFETCH_CHUNKS:
                                await asyncio.sleep(0.01)  # í”„ë¦¬ë²„í¼: ë¹ ë¥´ê²Œ
                            else:
                                await asyncio.sleep(CHUNK_DELAY)  # ì‹¤ì‹œê°„: 1x ì†ë„
                            
                            if chunk_count % 16 == 0:  # ë¡œê·¸
                                current_time = start_offset + (total_bytes / self.config['byterate'])
                                mode = "í”„ë¦¬ë²„í¼" if chunk_count <= PREFETCH_CHUNKS else "ì‹¤ì‹œê°„"
                                print(f"[HAIV-STT] ğŸ“¤ [{mode}] ìŠ¤íŠ¸ë¦¬ë°: {current_time:.1f}ì´ˆ")
                        
                        # ë§ˆì§€ë§‰ EOS ì „ì†¡ (ëª¨ë“  ì˜¤ë””ì˜¤ ì „ì†¡ ì™„ë£Œ í›„ 1ë²ˆë§Œ!)
                        await ws.send("EOS")
                        seconds = total_bytes / self.config['byterate']
                        print(f"[HAIV-STT] ğŸ“¤ EOS ì „ì†¡ (ì´ {seconds:.1f}ì´ˆ ì˜¤ë””ì˜¤)")
                        
                    except Exception as e:
                        print(f"[HAIV-STT] âŒ ì „ì†¡ ì˜¤ë¥˜: {e}")
                    finally:
                        send_done.set()
                        process.terminate()
                
                async def receive_results():
                    """HAIV ê²°ê³¼ ì‹¤ì‹œê°„ ìˆ˜ì‹ """
                    import time
                    start_wall_time = time.time()  # ì‹¤ì œ ì‹œì‘ ì‹œê°„
                    print(f"[HAIV-STT] ğŸ“¥ ìˆ˜ì‹  íƒœìŠ¤í¬ ì‹œì‘!")
                    msg_count = 0
                    try:
                        async for message in ws:
                            msg_count += 1
                            
                            # Progress ë©”ì‹œì§€
                            if isinstance(message, str) and message.startswith("Progress:"):
                                print(f"[HAIV-STT] ğŸ“Š Progress: {message}")
                                continue
                            
                            # ë©”ì‹œì§€ íƒ€ì… ë¡œê·¸
                            if isinstance(message, bytes):
                                print(f"[HAIV-STT] ğŸ“¦ ë°”ì´ë„ˆë¦¬ ìˆ˜ì‹ : {len(message)} bytes")
                                continue
                            
                            print(f"[HAIV-STT] ğŸ“¨ ë©”ì‹œì§€ #{msg_count}: {message[:200] if len(message) > 200 else message}")
                            
                            # JSON ê²°ê³¼ íŒŒì‹±
                            try:
                                response = json.loads(message)
                            except json.JSONDecodeError as e:
                                print(f"[HAIV-STT] âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                                continue
                            
                            # ê²°ê³¼ ì²˜ë¦¬
                            if 'status' in response and 'result' in response:
                                result = response.get('result', {})
                                
                                if result.get('final'):
                                    hypotheses = result.get('hypotheses', [])
                                    if hypotheses:
                                        transcript = hypotheses[0].get('transcript', '')
                                        
                                        if transcript.strip():
                                            seg_start = response.get('segment-start', 0)
                                            seg_length = response.get('segment-length', 0)
                                            
                                            # [advice from AI] ì²˜ë¦¬ ì†ë„ ì¸¡ì •: ì‹¤ì œ ê²½ê³¼ì‹œê°„ vs ì˜¤ë””ì˜¤ íƒ€ì„ìŠ¤íƒ¬í”„
                                            elapsed = time.time() - start_wall_time
                                            audio_time = seg_start + seg_length
                                            throughput = audio_time / elapsed if elapsed > 0 else 0
                                            print(f"[HAIV-STT] â±ï¸ ì²˜ë¦¬ì†ë„: ì‹¤ì‹œê°„ {elapsed:.1f}s â†’ ì˜¤ë””ì˜¤ {audio_time:.1f}s ({throughput:.1f}x)")
                                            
                                            # [advice from AI] íƒ€ì„ìŠ¤íƒ¬í”„ëŠ” HAIVê°€ ë°˜í™˜í•œ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                                            actual_start = start_offset + seg_start
                                            actual_end = start_offset + seg_start + seg_length
                                            
                                            # [advice from AI] HAIV ëª¨ë¸ì€ í™”ì ë¶„ë¦¬ ì—†ìŒ - speakerëŠ” í•­ìƒ None
                                            self.segment_id += 1
                                            subtitle = RealtimeSubtitle(
                                                id=self.segment_id,
                                                start_time=actual_start,
                                                end_time=actual_end,
                                                text=transcript,
                                                speaker=None,
                                                is_final=True
                                            )
                                            
                                            await results_queue.put(subtitle)
                                            print(f"[HAIV-STT] ğŸ¤ [{actual_start:.1f}s] {transcript}")
                            
                            # EOS ì‘ë‹µ
                            if isinstance(response, dict) and response.get("EOS"):
                                print(f"[HAIV-STT] ğŸ“¥ EOS ìˆ˜ì‹  ì™„ë£Œ")
                                break
                                
                    except websockets.ConnectionClosed as e:
                        print(f"[HAIV-STT] ì—°ê²° ì¢…ë£Œ: {e}")
                    except Exception as e:
                        print(f"[HAIV-STT] ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
                    finally:
                        await results_queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸
                
                # ì†¡ì‹ /ìˆ˜ì‹  ë³‘ë ¬ ì‹¤í–‰
                send_task = asyncio.create_task(stream_audio_to_haiv())
                recv_task = asyncio.create_task(receive_results())
                
                # ê²°ê³¼ ì‹¤ì‹œê°„ yield
                while True:
                    subtitle = await results_queue.get()
                    if subtitle is None:
                        break
                    yield subtitle
                
                # íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
                await asyncio.gather(send_task, recv_task, return_exceptions=True)
                
        except Exception as e:
            print(f"[HAIV-STT] âŒ ì—°ê²° ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        
        print(f"[HAIV-STT] ğŸ ì™„ë£Œ: ì´ {self.segment_id}ê°œ ìë§‰")


# [advice from AI] ê°„í¸ í•¨ìˆ˜
async def process_video_realtime(
    input_path: str,
    enable_diarization: bool = True,
    start_offset: float = 0.0,
    sync_mode: bool = False
) -> AsyncGenerator[RealtimeSubtitle, None]:
    """
    ì˜ìƒì„ ì‹¤ì‹œê°„ STTë¡œ ì²˜ë¦¬
    
    Args:
        input_path: ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        enable_diarization: í™”ì ë¶„ë¦¬ (HAIVëŠ” ë¯¸ì§€ì›)
        start_offset: ì‹œì‘ ìœ„ì¹˜ (ì´ˆ) - ì˜ìƒ ì¬ìƒê³¼ ë™ê¸°í™”
        sync_mode: Trueë©´ ì˜ìƒ ì¬ìƒ ì†ë„(1x)ì— ë§ì¶° ì²˜ë¦¬
    """
    stt = HAIVStreamingSTT()
    async for subtitle in stt.process_video(
        input_path, 
        enable_diarization,
        start_offset=start_offset,
        sync_mode=sync_mode
    ):
        yield subtitle
