# [advice from AI] Whisper ê¸°ë°˜ STT í´ë¼ì´ì–¸íŠ¸ (WSTT API - í¬íŠ¸ 6470)
# í™”ì ë¶„ë¦¬ ì§€ì›, ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°

import os
import asyncio
import json
from typing import AsyncGenerator, Optional
from dataclasses import dataclass
import websockets

from .realtime_stt import RealtimeSubtitle


@dataclass
class WhisperConfig:
    """Whisper STT ì„¤ì • (STT-Full-Service API)"""
    host: str = "localhost"
    port: int = 6470
    language: str = "ko"
    sample_rate: int = 16000
    model: str = "KOREAN_16K"  # KOREAN_8K, KOREAN_16K, KOREAN_32K


class WhisperStreamingSTT:
    """
    STT-Full-Service í´ë¼ì´ì–¸íŠ¸ (í¬íŠ¸ 6470)
    
    API ìŠ¤í™:
    - WebSocket: ws://<HOST>:6470/client/ws/speech?model=KOREAN_16K&lang=ko
    - ì˜¤ë””ì˜¤: PCM int16, mono
    - ì¢…ë£Œ: "EOS" ë¬¸ìì—´ ì „ì†¡
    - ì‘ë‹µ: {"text": "...", "final": true}
    - í™”ì ë³€ê²½: í…ìŠ¤íŠ¸ì— ì¤„ë°”ê¿ˆ(\n) ì‚½ì…
    """
    
    def __init__(self, config: Optional[WhisperConfig] = None):
        self.config = config or WhisperConfig(
            host=os.getenv("WHISPER_HOST", "localhost"),
            port=int(os.getenv("WHISPER_PORT", "6470")),
        )
        self.segment_id = 0
        self.websocket = None
        self.current_audio_time = 0.0  # í˜„ì¬ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë””ì˜¤ ì‹œê°„
    
    def get_ws_uri(self) -> str:
        """WebSocket URI ìƒì„± (ìƒˆ API ìŠ¤í™)"""
        return (
            f"ws://{self.config.host}:{self.config.port}/client/ws/speech"
            f"?model={self.config.model}"
            f"&lang={self.config.language}"
        )
    
    async def process_audio_stream(
        self,
        input_path: str,
        enable_diarization: bool = True,
        start_offset: float = 0.0,
        sync_mode: bool = False
    ) -> AsyncGenerator[RealtimeSubtitle, None]:
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ìë§‰ ìƒì„±
        
        Args:
            input_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ (MP4, WAV ë“±)
            enable_diarization: í™”ì ë¶„ë¦¬ í™œì„±í™”
            start_offset: ì‹œì‘ ìœ„ì¹˜ (ì´ˆ) - ì˜ìƒ ì¬ìƒê³¼ ë™ê¸°í™”
            sync_mode: Trueë©´ ì˜ìƒ ì¬ìƒ ì†ë„(1x)ì— ë§ì¶° ì²˜ë¦¬
        
        Yields:
            RealtimeSubtitle: ì‹¤ì‹œê°„ ìë§‰
        """
        self.start_offset = start_offset  # ì €ì¥
        uri = self.get_ws_uri()
        
        print(f"[WHISPER-STT] ========================================")
        print(f"[WHISPER-STT] ğŸš€ Whisper STT ì‹œì‘")
        print(f"[WHISPER-STT] URI: {uri}")
        print(f"[WHISPER-STT] ì…ë ¥: {input_path}")
        print(f"[WHISPER-STT] â±ï¸ ì‹œì‘ ìœ„ì¹˜: {start_offset}ì´ˆ")
        print(f"[WHISPER-STT] ğŸ”„ ë™ê¸°í™” ëª¨ë“œ: {sync_mode}")
        print(f"[WHISPER-STT] í™”ìë¶„ë¦¬: {enable_diarization}")
        print(f"[WHISPER-STT] ========================================")
        
        results_queue = asyncio.Queue()
        send_done = asyncio.Event()
        
        try:
            print(f"[WHISPER-STT] ğŸ”Œ WebSocket ì—°ê²° ì‹œë„: {uri}")
            # [advice from AI] ì—°ê²° íƒ€ì„ì•„ì›ƒ 10ì´ˆ (open_timeout ì‚¬ìš©)
            async with websockets.connect(
                uri, 
                ping_interval=30, 
                ping_timeout=60, 
                close_timeout=10,
                open_timeout=10  # ì—°ê²° íƒ€ì„ì•„ì›ƒ
            ) as ws:
                print(f"[WHISPER-STT] âœ… WebSocket ì—°ê²° ì„±ê³µ!")
                
                async def stream_audio_to_whisper():
                    """FFmpegë¡œ ì˜¤ë””ì˜¤ ì¶”ì¶œí•˜ì—¬ Whisperë¡œ ì „ì†¡"""
                    ffmpeg_cmd = ["ffmpeg"]
                    
                    # [advice from AI] ì‹œì‘ ìœ„ì¹˜ ì§€ì • (ì˜ìƒ ì¬ìƒê³¼ ë™ê¸°í™”)
                    if start_offset > 0:
                        ffmpeg_cmd.extend(["-ss", str(start_offset)])
                    
                    ffmpeg_cmd.extend([
                        "-i", input_path,
                        "-vn",
                        "-acodec", "pcm_s16le",
                        "-ar", str(self.config.sample_rate),
                        "-ac", "1",
                        "-f", "s16le",  # Raw PCM
                        "-loglevel", "error",
                        "pipe:1"
                    ])
                    
                    print(f"[WHISPER-STT] ğŸ¬ FFmpeg ì‹œì‘ (offset: {start_offset}ì´ˆ)")
                    
                    process = await asyncio.create_subprocess_exec(
                        *ffmpeg_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    
                    # [advice from AI] ì²­í¬ í¬ê¸°: 8000 bytes = 0.25ì´ˆ @ 16kHz
                    chunk_size = 8000
                    total_bytes = 0
                    chunk_count = 0
                    self.current_audio_time = start_offset  # ì‹œì‘ ìœ„ì¹˜ë¶€í„°
                    
                    # [advice from AI] ë™ê¸°í™” ëª¨ë“œì— ë”°ë¼ ì „ì†¡ ì†ë„ ì¡°ì ˆ
                    if sync_mode:
                        # ì‹¤ì‹œê°„ ëª¨ë“œ: 1.5x ì†ë„ë¡œ ë¹ ë¥´ê²Œ ì „ì†¡ (2ì´ˆ ì§€ì—° ëª©í‘œ)
                        PREFETCH_CHUNKS = 16  # 4ì´ˆ í”„ë¦¬ë²„í¼
                        CHUNK_DELAY = 0.167   # 1.5x ì†ë„ (0.25ì´ˆ ì²­í¬ë¥¼ 0.167ì´ˆë§ˆë‹¤)
                    else:
                        # íŒŒì¼ ëª¨ë“œ: ìµœëŒ€ ì†ë„ë¡œ ì²˜ë¦¬
                        PREFETCH_CHUNKS = 40  # 10ì´ˆ í”„ë¦¬ë²„í¼
                        CHUNK_DELAY = 0.05    # 5x ì†ë„
                    
                    try:
                        while True:
                            chunk = await process.stdout.read(chunk_size)
                            if not chunk:
                                break
                            
                            await ws.send(chunk)
                            total_bytes += len(chunk)
                            chunk_count += 1
                            
                            # [advice from AI] í˜„ì¬ ì˜¤ë””ì˜¤ ì‹œê°„ ì—…ë°ì´íŠ¸
                            self.current_audio_time = start_offset + (total_bytes / (self.config.sample_rate * 2))
                            
                            # [advice from AI] ì „ì†¡ ì†ë„ ì¡°ì ˆ
                            if chunk_count <= PREFETCH_CHUNKS:
                                await asyncio.sleep(0.01)  # í”„ë¦¬ë²„í¼: ë¹ ë¥´ê²Œ
                            else:
                                await asyncio.sleep(CHUNK_DELAY)  # ì‹¤ì‹œê°„: 1x ì†ë„
                            
                            if chunk_count % 16 == 0:
                                seconds = self.current_audio_time
                                mode = "í”„ë¦¬ë²„í¼" if chunk_count <= PREFETCH_CHUNKS else "ì‹¤ì‹œê°„"
                                print(f"[WHISPER-STT] ğŸ“¤ [{mode}] ìŠ¤íŠ¸ë¦¬ë°: {seconds:.1f}ì´ˆ")
                        
                        # ë§ˆì§€ë§‰ EOS ì „ì†¡ (ëª¨ë“  ì˜¤ë””ì˜¤ ì „ì†¡ ì™„ë£Œ í›„ 1ë²ˆë§Œ!)
                        await ws.send("EOS")
                        seconds = total_bytes / (self.config.sample_rate * 2)
                        print(f"[WHISPER-STT] ğŸ“¤ EOS ì „ì†¡ (ì´ {seconds:.1f}ì´ˆ ì˜¤ë””ì˜¤)")
                        
                    except Exception as e:
                        print(f"[WHISPER-STT] âŒ ì „ì†¡ ì˜¤ë¥˜: {e}")
                    finally:
                        send_done.set()
                        process.terminate()
                
                async def receive_results():
                    """STT-Full-Service ê²°ê³¼ ìˆ˜ì‹  (ì‹¤ì‹œê°„ ì„¸ê·¸ë¨¼íŠ¸ ìŠ¤íŠ¸ë¦¬ë°)"""
                    import time
                    start_wall_time = time.time()  # ì‹¤ì œ ì‹œì‘ ì‹œê°„
                    print(f"[WHISPER-STT] ğŸ“¥ ìˆ˜ì‹  íƒœìŠ¤í¬ ì‹œì‘!")
                    msg_count = 0
                    current_speaker = 1
                    
                    try:
                        async for message in ws:
                            msg_count += 1
                            
                            # [advice from AI] ë””ë²„ê¹…: ëª¨ë“  ë©”ì‹œì§€ ì¶œë ¥
                            print(f"[WHISPER-STT] ğŸ“¨ RAW ë©”ì‹œì§€ #{msg_count}: {str(message)[:200]}")
                            
                            try:
                                response = json.loads(message)
                                msg_type = response.get("type", "")
                                is_final = response.get("final", False)
                                
                                # [advice from AI] ë””ë²„ê¹…: íŒŒì‹±ëœ ë©”ì‹œì§€ íƒ€ì…
                                print(f"[WHISPER-STT] ğŸ“‹ íŒŒì‹± ê²°ê³¼: type={msg_type}, final={is_final}, keys={list(response.keys())}")
                                
                                # [advice from AI] ìƒˆ API: typeìœ¼ë¡œ ë©”ì‹œì§€ êµ¬ë¶„
                                # type: "segment" â†’ ì‹¤ì‹œê°„ ì¤‘ê°„ ê²°ê³¼ (ë°œí™”ë§ˆë‹¤)
                                # type: "final" â†’ ìµœì¢… ê²°ê³¼ (EOS í›„)
                                
                                if msg_type == "segment":
                                    # âš¡ ì‹¤ì‹œê°„ ì„¸ê·¸ë¨¼íŠ¸! (HAIVì™€ ë™ì¼í•œ êµ¬ì¡°)
                                    text = response.get("text", "").strip()
                                    if not text:
                                        continue
                                    
                                    self.segment_id += 1
                                    
                                    seg_start = response.get("start", 0)
                                    seg_end = response.get("end", seg_start + 3)
                                    # [advice from AI] íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ìµœì†Œ 3ì´ˆë¡œ ë³´ì •
                                    if seg_end - seg_start < 1.0:
                                        seg_end = seg_start + 3.0
                                    actual_start = start_offset + seg_start
                                    actual_end = start_offset + seg_end
                                    
                                    # ì²˜ë¦¬ ì†ë„ ì¸¡ì •
                                    elapsed = time.time() - start_wall_time
                                    throughput = seg_end / elapsed if elapsed > 0 else 0
                                    print(f"[WHISPER-STT] â±ï¸ ì²˜ë¦¬ì†ë„: ì‹¤ì‹œê°„ {elapsed:.1f}s â†’ ì˜¤ë””ì˜¤ {seg_end:.1f}s ({throughput:.1f}x)")
                                    
                                    # í™”ì ë³€ê²½ ì²˜ë¦¬
                                    if response.get("speaker_changed", False):
                                        current_speaker = 2 if current_speaker == 1 else 1
                                    
                                    speaker_str = f"í™”ì{current_speaker}" if enable_diarization else None
                                    
                                    # [advice from AI] Whisper segment ê²°ê³¼ë„ ìµœì¢… ê²°ê³¼ë¡œ ì²˜ë¦¬
                                    # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìºì‹œ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘í•˜ë ¤ë©´ is_final=True í•„ìš”
                                    subtitle = RealtimeSubtitle(
                                        id=self.segment_id,
                                        start_time=actual_start,
                                        end_time=actual_end,
                                        text=text,
                                        speaker=speaker_str,
                                        is_final=True  # í•­ìƒ Trueë¡œ ì„¤ì • (ìºì‹œì— ì €ì¥ë¨)
                                    )
                                    
                                    await results_queue.put(subtitle)
                                    print(f"[WHISPER-STT] ğŸ¤ [{actual_start:.1f}s~{actual_end:.1f}s] {speaker_str or ''}: {text[:40]}...")
                                
                                elif msg_type == "final" or is_final:
                                    # ìµœì¢… ê²°ê³¼ (EOS í›„) - segments ë°°ì—´ ì²˜ë¦¬
                                    segments = response.get("segments", [])
                                    
                                    if segments:
                                        for seg in segments:
                                            text = seg.get("text", "").strip()
                                            if not text:
                                                continue
                                            
                                            self.segment_id += 1
                                            
                                            seg_start = seg.get("start", 0)
                                            seg_end = seg.get("end", seg_start + 3)
                                            # [advice from AI] íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ìµœì†Œ 3ì´ˆë¡œ ë³´ì •
                                            if seg_end - seg_start < 1.0:
                                                seg_end = seg_start + 3.0
                                            actual_start = start_offset + seg_start
                                            actual_end = start_offset + seg_end
                                            
                                            if seg.get("speaker_changed", False):
                                                current_speaker = 2 if current_speaker == 1 else 1
                                            
                                            speaker_str = f"í™”ì{current_speaker}" if enable_diarization else None
                                            
                                            subtitle = RealtimeSubtitle(
                                                id=self.segment_id,
                                                start_time=actual_start,
                                                end_time=actual_end,
                                                text=text,
                                                speaker=speaker_str,
                                                is_final=True
                                            )
                                            
                                            await results_queue.put(subtitle)
                                            print(f"[WHISPER-STT] ğŸ¤ [FINAL] [{actual_start:.1f}s~{actual_end:.1f}s] {text[:40]}...")
                                    else:
                                        # segments ì—†ìœ¼ë©´ textë¡œ í´ë°±
                                        text = response.get("text", "").strip()
                                        if text:
                                            for line in text.split('\n'):
                                                line = line.strip()
                                                if not line:
                                                    continue
                                                
                                                self.segment_id += 1
                                                rel_start = max(0, self.current_audio_time - 3.0)
                                                rel_end = rel_start + 3
                                                
                                                subtitle = RealtimeSubtitle(
                                                    id=self.segment_id,
                                                    start_time=rel_start,
                                                    end_time=rel_end,
                                                    text=line,
                                                    speaker=None,
                                                    is_final=True
                                                )
                                                
                                                await results_queue.put(subtitle)
                                                print(f"[WHISPER-STT] ğŸ¤ [í´ë°±] [{rel_start:.1f}s] {line[:40]}...")
                                    
                                    print(f"[WHISPER-STT] âœ… ìµœì¢… ê²°ê³¼ ìˆ˜ì‹  ì™„ë£Œ!")
                                
                            except json.JSONDecodeError:
                                print(f"[WHISPER-STT] âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {message[:100]}")
                    
                    except websockets.ConnectionClosed as e:
                        print(f"[WHISPER-STT] ì—°ê²° ì¢…ë£Œ: {e}")
                    except Exception as e:
                        print(f"[WHISPER-STT] ìˆ˜ì‹  ì˜¤ë¥˜: {e}")
                    finally:
                        await results_queue.put(None)  # ì¢…ë£Œ ì‹ í˜¸
                
                # ì†¡ì‹ /ìˆ˜ì‹  ë³‘ë ¬ ì‹¤í–‰
                send_task = asyncio.create_task(stream_audio_to_whisper())
                recv_task = asyncio.create_task(receive_results())
                
                # ê²°ê³¼ ì‹¤ì‹œê°„ yield
                while True:
                    subtitle = await results_queue.get()
                    if subtitle is None:
                        break
                    yield subtitle
                
                # íƒœìŠ¤í¬ ì •ë¦¬
                await send_task
                recv_task.cancel()
                
                print(f"[WHISPER-STT] âœ… ì²˜ë¦¬ ì™„ë£Œ! ì´ {self.segment_id}ê°œ ìë§‰")
        
        except asyncio.TimeoutError:
            print(f"[WHISPER-STT] âŒ ì—°ê²° íƒ€ì„ì•„ì›ƒ! Whisper ì„œë²„({self.config['host']})ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        except websockets.exceptions.WebSocketException as e:
            print(f"[WHISPER-STT] âŒ WebSocket ì˜¤ë¥˜: {e}")
        except ConnectionRefusedError:
            print(f"[WHISPER-STT] âŒ ì—°ê²° ê±°ë¶€! Whisper ì„œë²„({self.config['host']})ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
        except Exception as e:
            print(f"[WHISPER-STT] âŒ ì˜¤ë¥˜: {type(e).__name__}: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # ìƒíƒœ ì´ˆê¸°í™”
            if hasattr(self, 'base_time'):
                delattr(self, 'base_time')


# [advice from AI] í¸ì˜ í•¨ìˆ˜
async def process_video_with_whisper(
    input_path: str,
    enable_diarization: bool = True,
    start_offset: float = 0.0,
    sync_mode: bool = False
) -> AsyncGenerator[RealtimeSubtitle, None]:
    """
    Whisper STTë¡œ ì˜ìƒ ì²˜ë¦¬
    
    Args:
        input_path: ì…ë ¥ íŒŒì¼ ê²½ë¡œ
        enable_diarization: í™”ì ë¶„ë¦¬ í™œì„±í™”
        start_offset: ì‹œì‘ ìœ„ì¹˜ (ì´ˆ) - ì˜ìƒ ì¬ìƒê³¼ ë™ê¸°í™”
        sync_mode: Trueë©´ ì˜ìƒ ì¬ìƒ ì†ë„(1x)ì— ë§ì¶° ì²˜ë¦¬
    
    Yields:
        RealtimeSubtitle: ì‹¤ì‹œê°„ ìë§‰
    """
    client = WhisperStreamingSTT()
    async for subtitle in client.process_audio_stream(
        input_path, 
        enable_diarization, 
        start_offset=start_offset, 
        sync_mode=sync_mode
    ):
        yield subtitle
