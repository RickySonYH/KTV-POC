"""
[advice from AI] í›„ì²˜ë¦¬ ëª¨ë“ˆ
í• ë£¨ì‹œë„¤ì´ì…˜ í•„í„°ë§ + ì‚¬ì „ ë§¤ì¹­ + ìŒì•… ê°ì§€ (ì›ë³¸ whisper_server.pyì—ì„œ ë§ˆì´ê·¸ë ˆì´ì…˜)
"""

import re
import logging
from typing import List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)


# =============================================================================
# [advice from AI] ìŒì•…/ë…¸ë˜ ê°ì§€
# =============================================================================

class AudioContentType(Enum):
    """ì˜¤ë””ì˜¤ ì½˜í…ì¸  íƒ€ì…"""
    SPEECH = "speech"       # ìŒì„±
    MUSIC = "music"         # ìŒì•… (ë°°ê²½ìŒì•…)
    SINGING = "singing"     # ë…¸ë˜ (ê°€ì‚¬)
    UNCLEAR = "unclear"     # ë¶ˆë¶„ëª…


@dataclass
class MusicDetectionResult:
    """ìŒì•… ê°ì§€ ê²°ê³¼"""
    is_music: bool
    content_type: AudioContentType
    confidence: float
    replacement_text: str


# ìŒì•… ê°ì§€ íŒ¨í„´
MUSIC_PATTERNS = [
    # ìŒí‘œ ê¸°í˜¸
    r'[â™ªâ™«ğŸµğŸ¶ğŸ¤ğŸ¼]+',
    
    # ì˜ì–´ ìŒì•… í‘œí˜„
    r'\[music\]',
    r'\[music playing\]',
    r'\(music\)',
    r'\(music playing\)',
    r'\[singing\]',
    r'\(singing\)',
    
    # í•œêµ­ì–´ ìŒì•… í‘œí˜„
    r'\[ìŒì•…\]',
    r'\(ìŒì•…\)',
    r'\[ë…¸ë˜\]',
    r'\(ë…¸ë˜\)',
    r'\[ë°°ê²½ìŒì•…\]',
]

# [advice from AI] ì• êµ­ê°€ ê°€ì‚¬ íŒ¨í„´ (êµ­ë¯¼ì˜ë¡€ ì‹œ ìŒì•… ê°ì§€ìš©)
ANTHEM_LYRICS = [
    # ì• êµ­ê°€ 1ì ˆ
    r"ë™í•´\s*ë¬¼ê³¼\s*ë°±ë‘ì‚°ì´",
    r"ë§ˆë¥´ê³ \s*ë‹³ë„ë¡",
    r"í•˜ëŠë‹˜ì´\s*ë³´ìš°í•˜ì‚¬",
    r"ìš°ë¦¬ë‚˜ë¼\s*ë§Œì„¸",
    r"ë¬´ê¶í™”\s*ì‚¼ì²œë¦¬",
    r"í™”ë ¤\s*ê°•ì‚°",
    r"ëŒ€í•œ\s*ì‚¬ëŒ",
    r"ëŒ€í•œìœ¼ë¡œ",
    r"ê¸¸ì´\s*ë³´ì „í•˜ì„¸",
    # ì• êµ­ê°€ 2ì ˆ
    r"ë‚¨ì‚°\s*ìœ„ì—\s*ì €\s*ì†Œë‚˜ë¬´",
    r"ì² ê°‘ì„\s*ë‘ë¥¸\s*ë“¯",
    r"ë°”ëŒ\s*ì„œë¦¬\s*ë¶ˆë³€í•¨ì€",
    r"ìš°ë¦¬\s*ê¸°ìƒì¼ì„¸",
    # ì• êµ­ê°€ 3ì ˆ
    r"ê°€ì„\s*í•˜ëŠ˜\s*ê³µí™œí•œë°",
    r"ë†’ê³ \s*êµ¬ë¦„\s*ì—†ì´",
    r"ë°ì€\s*ë‹¬ì€\s*ìš°ë¦¬\s*ê°€ìŠ´",
    r"ì¼í¸ë‹¨ì‹¬ì¼ì„¸",
    # ì• êµ­ê°€ 4ì ˆ
    r"ì´\s*ê¸°ìƒê³¼\s*ì´\s*ë§˜ìœ¼ë¡œ",
    r"ì¶©ì„±ì„\s*ë‹¤í•˜ì—¬",
    r"ê´´ë¡œìš°ë‚˜\s*ì¦ê±°ìš°ë‚˜",
    r"ë‚˜ë¼\s*ì‚¬ë‘í•˜ì„¸",
]

COMPILED_ANTHEM_PATTERNS = [re.compile(p, re.IGNORECASE) for p in ANTHEM_LYRICS]

COMPILED_MUSIC_PATTERNS = [re.compile(p, re.IGNORECASE) for p in MUSIC_PATTERNS]

# ìŒì•…/ë…¸ë˜ ê°€ì‚¬ë¡œ ì˜ì‹¬ë˜ëŠ” íŒ¨í„´ (ë°˜ë³µ, ì§§ì€ ì–´ì ˆ)
LYRIC_PATTERNS = [
    # ë¼ë¼ë¼, ë‚˜ë‚˜ë‚˜ ë“±ì˜ ë°˜ë³µ
    r'^(ë¼|ë‚˜|ë‹¤|ë°”|ë§ˆ|íŒŒ|íƒ€|í•˜|ì•„|ì´|ìš°|ì˜¤)+\s*(ë¼|ë‚˜|ë‹¤|ë°”|ë§ˆ|íŒŒ|íƒ€|í•˜|ì•„|ì´|ìš°|ì˜¤)+$',
    # ì˜ì–´ ìŠ¤ìº£
    r'^(la|na|da|ba|sha|do|re|mi|fa|so|si|yeah|oh|ah)+\s*',
    # í—ˆë°
    r'^(ìŒ|í |í›”|í¥|ì‘)+\s*(ìŒ|í |í›”|í¥|ì‘)*$',
]

COMPILED_LYRIC_PATTERNS = [re.compile(p, re.IGNORECASE) for p in LYRIC_PATTERNS]


def detect_music(
    text: str, 
    no_speech_prob: float = 0.0,
    avg_logprob: float = 0.0
) -> MusicDetectionResult:
    """
    [advice from AI] ìŒì•…/ë…¸ë˜ ê°ì§€
    
    Args:
        text: STT ê²°ê³¼ í…ìŠ¤íŠ¸
        no_speech_prob: ë¬´ìŒ í™•ë¥  (Whisper ì¶œë ¥)
        avg_logprob: í‰ê·  ë¡œê·¸ í™•ë¥  (ì‹ ë¢°ë„)
    
    Returns:
        MusicDetectionResult: ìŒì•… ê°ì§€ ê²°ê³¼
    """
    if not text:
        return MusicDetectionResult(
            is_music=False,
            content_type=AudioContentType.SPEECH,
            confidence=0.0,
            replacement_text=""
        )
    
    text_lower = text.strip().lower()
    confidence = 0.0
    content_type = AudioContentType.SPEECH
    
    # 1. ëª…ì‹œì  ìŒì•… íŒ¨í„´ ì²´í¬ (ìŒí‘œ ê¸°í˜¸, [music] ë“±)
    for pattern in COMPILED_MUSIC_PATTERNS:
        if pattern.search(text):
            return MusicDetectionResult(
                is_music=True,
                content_type=AudioContentType.MUSIC,
                confidence=0.95,
                replacement_text="[â™ª]"
            )
    
    # 2. ê°€ì‚¬/ìŠ¤ìº£ íŒ¨í„´ ì²´í¬
    for pattern in COMPILED_LYRIC_PATTERNS:
        if pattern.match(text_lower):
            return MusicDetectionResult(
                is_music=True,
                content_type=AudioContentType.SINGING,
                confidence=0.8,
                replacement_text="[â™ª ë…¸ë˜]"
            )
    
    # [advice from AI] 2.5. ì• êµ­ê°€ ê°€ì‚¬ íŒ¨í„´ ì²´í¬ (êµ­ë¯¼ì˜ë¡€ ì‹œ)
    for pattern in COMPILED_ANTHEM_PATTERNS:
        if pattern.search(text):
            return MusicDetectionResult(
                is_music=True,
                content_type=AudioContentType.SINGING,
                confidence=0.9,
                replacement_text="[â™ª ì• êµ­ê°€]"
            )
    
    # 3. íœ´ë¦¬ìŠ¤í‹± ì²´í¬: ë†’ì€ ë¬´ìŒ í™•ë¥  + ë‚®ì€ ì‹ ë¢°ë„ = ìŒì•…ì¼ ê°€ëŠ¥ì„±
    if no_speech_prob > 0.7 and avg_logprob < -0.9:
        confidence = (no_speech_prob + (1.0 - abs(avg_logprob))) / 2
        if confidence > 0.6:
            return MusicDetectionResult(
                is_music=True,
                content_type=AudioContentType.MUSIC,
                confidence=confidence,
                replacement_text="[â™ª]"
            )
    
    # 4. ìŒì•… ì•„ë‹˜
    return MusicDetectionResult(
        is_music=False,
        content_type=AudioContentType.SPEECH,
        confidence=0.0,
        replacement_text=""
    )


# =============================================================================
# [advice from AI] ë¹„ì†ì–´/ë¯¼ê°ì–´ í•„í„° (ë°©ì†¡ ì‚¬ê³  ë°©ì§€)
# =============================================================================

# [advice from AI] ë¹„ì†ì–´ íŒ¨í„´ (ë§ˆìŠ¤í‚¹ ì²˜ë¦¬) - GPT-4.1 ì—„ì„ 
PROFANITY_PATTERNS = [
    # ========== ê¸°ë³¸ ìš•ì„¤ ==========
    r"ì”¨ë°œ", r"ì‹œë°œ", r"ì”¨bal", r"ã……ã…‚", r"ã…†ã…‚",
    r"ê°œìƒˆë¼", r"ê°œìƒˆ", r"ê°œìƒ‰", r"ã„±ã……ã„²",
    r"ë³‘ì‹ ", r"ã…‚ã……", r"ë¸…ì‹ ",
    r"ì§€ë„", r"ã…ˆã„¹", r"ì§€ë„í•œë‹¤",
    r"ì¢†", r"ã…ˆã…‡", r"ì¢†ê°™ë‹¤", r"ì¢†ë°¥", r"ì¢†ë§", r"ì¢†ë„", r"ì¢†ë‚˜", r"ì¢†ê°™ì´",
    r"ë‹ˆë¯¸", r"ëŠê¸ˆë§ˆ", r"ëŠê¸ˆ",
    r"ì— ì°½", r"ì• ë¯¸", r"ì• ë¹„",
    r"ìƒˆë¼", r"ã……ã„²",
    r"êº¼ì ¸", r"ë‹¥ì³", r"ì£½ì–´",
    # ========== ë¹„í•˜ í‘œí˜„ ==========
    r"ì¥ì• ì¸", r"ì •ì‹ ë³‘ì", r"ë¯¸ì¹œë†ˆ", r"ë¯¸ì¹œë…„",
    r"ì°ë”°", r"ë£¨ì €", r"ë³‘ì",
    r"ì •ì‹ ë‚˜ê°„", r"ë˜ë¼ì´", r"ë©ì²­ì´", r"ê¼´í†µ",
    r"ìŒë†ˆ", r"ìŒë…„", r"ì–‘ì•„ì¹˜",
    # ========== ì •ì¹˜ ê´€ë ¨ ë¹„ì†ì–´ (GPT-4.1 ì¶”ê°€) ==========
    r"ê°œXX", r"ì“°ë ˆê¸°", r"ê¼´ê°’",
    r"ì£½ì—¬ë²„ë¦°ë‹¤", r"í›„ë ¤ì¹œë‹¤",
    r"ì”¨ë°©ìƒˆ", r"ê°œë§ì‹ ", r"ê°œíŒ",
    r"ê°œì†Œë¦¬", r"ê°œë»¥", r"ê°œê°™ì´", r"ê°œì§€ë„", r"ê°œë¼ì§€",
    r"ìª½íŒ”ë¦°ë‹¤", r"ë¹¡ì¹œë‹¤", r"ë¹¡ëŒ€ê°€ë¦¬", r"ì—¼ë³‘",
    r"ì£½ì¼ë†ˆ", r"ë”ëŸ¬ìš´ ë†ˆ",
    r"Xê°™ë‹¤", r"Xë°œ", r"Xì‹ ", r"Xë†ˆ", r"Xë…„",
    r"ì •ì¹˜ê¹¡íŒ¨", r"ì •ì¹˜ëª¨ë¦¬ë°°", r"ì •ì¹˜ì“°ë ˆê¸°",
    r"ì •ì¹˜ì‚¬ê¸°ê¾¼", r"ì •ì¹˜ê¹¡íŒ¨ë“¤", r"ì •ì¹˜ì–‘ì•„ì¹˜", r"ì •ì¹˜ê°œì…ì§ˆ",
]

# [advice from AI] ë¯¼ê° ì •ë³´ íŒ¨í„´ (ë§ˆìŠ¤í‚¹ ì²˜ë¦¬) - GPT-4.1 ì—„ì„ 
SENSITIVE_PATTERNS = [
    # ========== ê¸°ë³¸ ê°œì¸ì •ë³´ ==========
    (r"\d{6}[-\s]?\d{7}", "[ì£¼ë¯¼ë²ˆí˜¸]"),                    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
    (r"\d{3}[-\s]?\d{4}[-\s]?\d{4}", "[ì „í™”ë²ˆí˜¸]"),         # ì „í™”ë²ˆí˜¸
    (r"\d{2,3}[-\s]?\d{3,4}[-\s]?\d{4}", "[ì „í™”ë²ˆí˜¸]"),     # ì „í™”ë²ˆí˜¸ ë³€í˜•
    (r"\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}", "[ì¹´ë“œë²ˆí˜¸]"),  # ì¹´ë“œë²ˆí˜¸
    (r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", "[ì´ë©”ì¼]"),  # ì´ë©”ì¼
    (r"\d{3}[-\s]?\d{2}[-\s]?\d{5}", "[ì‚¬ì—…ìë²ˆí˜¸]"),       # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸
    # ========== GPT-4.1 ì¶”ê°€ íŒ¨í„´ ==========
    (r"\d{2,4}-\d{2,4}-\d{2,4}-\d{2,4}", "[ê³„ì¢Œë²ˆí˜¸]"),     # ê³„ì¢Œë²ˆí˜¸
    (r"\d{16,19}", "[ì¹´ë“œë²ˆí˜¸]"),                           # ì¹´ë“œë²ˆí˜¸ (ì—°ì†)
    (r"\d{2,3}[ê°€-í£]{1}\d{4}", "[ì°¨ëŸ‰ë²ˆí˜¸]"),              # ì°¨ëŸ‰ë²ˆí˜¸
    (r"M[0-9]{8}", "[ì—¬ê¶Œë²ˆí˜¸]"),                           # ì—¬ê¶Œë²ˆí˜¸
    (r"[A-Z]{2}[0-9]{7}", "[ì—¬ê¶Œë²ˆí˜¸]"),                    # ì—¬ê¶Œë²ˆí˜¸ ë³€í˜•
    (r"\d{2}-\d{2}-\d{6}-\d{2}", "[ìš´ì „ë©´í—ˆ]"),             # ìš´ì „ë©´í—ˆë²ˆí˜¸
    # ========== ê°œì¸ì •ë³´ ì–¸ê¸‰ íŒ¨í„´ ==========
    (r"[ê°€-í£]{2,4}\s*ì”¨ì˜\s*ì£¼ì†ŒëŠ”", "[ê°œì¸ì£¼ì†Œ]"),
    (r"[ê°€-í£]{2,4}\s*ì˜\s*íœ´ëŒ€í°ë²ˆí˜¸ëŠ”", "[íœ´ëŒ€ì „í™”]"),
    (r"[ê°€-í£]{2,4}\s*ì˜\s*ê³„ì¢Œë²ˆí˜¸ëŠ”", "[ê³„ì¢Œë²ˆí˜¸]"),
    (r"[ê°€-í£]{2,4}\s*ì˜\s*ë¹„ë°€ë²ˆí˜¸ëŠ”", "[ë¹„ë°€ë²ˆí˜¸]"),
    (r"[ê°€-í£]{2,4}\s*ì˜\s*ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ëŠ”", "[ì£¼ë¯¼ë²ˆí˜¸]"),
    (r"[ê°€-í£]{2,4}\s*ì˜\s*ì¹´ë“œë²ˆí˜¸ëŠ”", "[ì¹´ë“œë²ˆí˜¸]"),
]

# ì»´íŒŒì¼ëœ ë¹„ì†ì–´ íŒ¨í„´
COMPILED_PROFANITY = [re.compile(p, re.IGNORECASE) for p in PROFANITY_PATTERNS]


def filter_profanity(text: str, replacement: str = "***") -> tuple:
    """
    [advice from AI] ë¹„ì†ì–´ í•„í„°ë§
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        replacement: ëŒ€ì²´ ë¬¸ìì—´
    
    Returns:
        (í•„í„°ë§ëœ í…ìŠ¤íŠ¸, í•„í„°ë§ëœ ë‹¨ì–´ ìˆ˜)
    """
    if not text:
        return text, 0
    
    result = text
    count = 0
    
    for pattern in COMPILED_PROFANITY:
        matches = pattern.findall(result)
        if matches:
            count += len(matches)
            result = pattern.sub(replacement, result)
    
    return result, count


def filter_sensitive_info(text: str) -> tuple:
    """
    [advice from AI] ë¯¼ê° ì •ë³´ í•„í„°ë§ (ê°œì¸ì •ë³´ ë³´í˜¸)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
    
    Returns:
        (í•„í„°ë§ëœ í…ìŠ¤íŠ¸, í•„í„°ë§ëœ í•­ëª© ìˆ˜)
    """
    if not text:
        return text, 0
    
    result = text
    count = 0
    
    for pattern, replacement in SENSITIVE_PATTERNS:
        matches = re.findall(pattern, result)
        if matches:
            count += len(matches)
            result = re.sub(pattern, replacement, result)
    
    return result, count


def apply_broadcast_safety_filter(text: str) -> str:
    """
    [advice from AI] ë°©ì†¡ ì•ˆì „ í•„í„° (ë¹„ì†ì–´ + ë¯¼ê°ì •ë³´)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
    
    Returns:
        í•„í„°ë§ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return text
    
    # 1. ë¹„ì†ì–´ í•„í„°ë§
    result, profanity_count = filter_profanity(text)
    
    # 2. ë¯¼ê° ì •ë³´ í•„í„°ë§
    result, sensitive_count = filter_sensitive_info(result)
    
    if profanity_count > 0 or sensitive_count > 0:
        logger.warning(
            f"ğŸš¨ ë°©ì†¡ ì•ˆì „ í•„í„° ì ìš©: ë¹„ì†ì–´ {profanity_count}ê°œ, ë¯¼ê°ì •ë³´ {sensitive_count}ê°œ"
        )
    
    return result


def replace_music_with_label(text: str) -> str:
    """
    [advice from AI] í…ìŠ¤íŠ¸ì—ì„œ ìŒì•… íŒ¨í„´ì„ ë ˆì´ë¸”ë¡œ ëŒ€ì²´
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
    
    Returns:
        ìŒì•… íŒ¨í„´ì´ [â™ª]ë¡œ ëŒ€ì²´ëœ í…ìŠ¤íŠ¸
    """
    result = text
    
    # ìŒí‘œ ê¸°í˜¸ â†’ [â™ª]
    result = re.sub(r'[â™ªâ™«ğŸµğŸ¶ğŸ¤ğŸ¼]+', '[â™ª]', result)
    
    # ì˜ì–´ ìŒì•… í‘œí˜„ ì •ê·œí™”
    result = re.sub(r'\[?music\]?|\(music\)|\[music playing\]|\(music playing\)', '[â™ª]', result, flags=re.IGNORECASE)
    result = re.sub(r'\[?singing\]?|\(singing\)', '[â™ª ë…¸ë˜]', result, flags=re.IGNORECASE)
    
    # ì—°ì†ëœ [â™ª] í•©ì¹˜ê¸°
    result = re.sub(r'(\[â™ª\]\s*)+', '[â™ª] ', result)
    
    return result.strip()


# =============================================================================
# [advice from AI] 1ë‹¨ê³„: í• ë£¨ì‹œë„¤ì´ì…˜ í•„í„°
# =============================================================================

# [advice from AI] ì•Œë ¤ì§„ í• ë£¨ì‹œë„¤ì´ì…˜ íŒ¨í„´ (ì •ê·œì‹) - GPT-4.1 ì—„ì„ 
HALLUCINATION_PATTERNS = [
    # ========== ì˜ì–´ í• ë£¨ì‹œë„¤ì´ì…˜ ==========
    r"^thank you( for watching)?\.?$",
    r"^thanks for watching\.?$",
    r"^please subscribe\.?$",
    r"^like and subscribe\.?$",
    r"^see you next time\.?$",
    r"^bye\.?$",
    r"^goodbye\.?$",
    r"^(Hello|Hi|Thank you|Subscribe|Like|Please subscribe|See you next time)[.!]?$",
    r"^[a-zA-Z]{2,}( [a-zA-Z]{2,}){0,4}[.!]?$",  # ì§§ì€ ì˜ì–´ ë¬¸ì¥
    
    # ========== í•œêµ­ì–´ í• ë£¨ì‹œë„¤ì´ì…˜ ==========
    r"^êµ¬ë….*ì¢‹ì•„ìš”.*ëˆŒëŸ¬.*$",
    r"^ì‹œì²­í•´\s*ì£¼ì…”ì„œ\s*ê°ì‚¬í•©ë‹ˆë‹¤\.?$",
    r"^ê°ì‚¬í•©ë‹ˆë‹¤\.?$",
    r"^ë‹¤ìŒì—\s*ë´ìš”\.?$",
    r"^ì•ˆë…•íˆ\s*ê³„ì„¸ìš”\.?$",
    r"^êµ¬ë…(ê³¼)? ì¢‹ì•„ìš”( ë¶€íƒë“œë¦½ë‹ˆë‹¤)?$",
    r"^ì¢‹ì•„ìš”(ì™€)? êµ¬ë…( ë¶€íƒë“œë¦½ë‹ˆë‹¤)?$",
    r"^ì±„ë„ì„ êµ¬ë…í•´ ì£¼ì„¸ìš”\.?$",
    r"^ë‹¤ìŒì— ë˜ ë§Œë‚˜ìš”\.?$",
    r"^ì•ˆë…•í•˜ì„¸ìš”\.?$",
    r"^í—¬ë¡œìš°(\.|\!)?$",
    
    # ========== ì¤‘êµ­ì–´/ì¼ë³¸ì–´ í• ë£¨ì‹œë„¤ì´ì…˜ ==========
    r"^è°¢è°¢.*$",
    r"^ã‚ã‚ŠãŒã¨ã†.*$",
    r"^[\u4e00-\u9fff]{2,}$",  # ì¤‘êµ­ì–´ ë¬¸ìë§Œ
    r"^[\u3040-\u30ff]{2,}$",  # ì¼ë³¸ì–´ ë¬¸ìë§Œ
    r"^(è°¢è°¢|ä½ å¥½|å†è§|ã“ã‚“ã«ã¡ã¯|ã‚ã‚ŠãŒã¨ã†|ã“ã‚“ã°ã‚“ã¯)$",
    
    # ========== íŠ¹ìˆ˜ ë¬¸ì/ê¸°í˜¸ ==========
    r"^[\s\.\,\!\?\-\~\â™ª\â™«\ğŸµ\ğŸ¶\â€¦]+$",
    r"^\.{2,}$",  # ë§ˆì¹¨í‘œë§Œ ë°˜ë³µ
    r"^\s*$",     # ê³µë°±ë§Œ
    
    # ========== ìë§‰ ê´€ë ¨ ==========
    r"^ìë§‰.*$",
    r"^subtitle.*$",
    r"^caption.*$",
    
    # ========== ë¬´ìŒ/ë°°ê²½ìŒ (GPT-4.1 ì¶”ê°€) ==========
    r"^ìŒì„± ì—†ìŒ$",
    r"^ë¬´ìŒ$",
    r"^ë°•ìˆ˜( ì†Œë¦¬)?$",
    r"^í™˜í˜¸( ì†Œë¦¬)?$",
    r"^ìŒì•…( ì†Œë¦¬)?$",
    r"^í…ŒìŠ¤íŠ¸(ì…ë‹ˆë‹¤)?$",
    r"^(ë§ˆì´í¬ í…ŒìŠ¤íŠ¸)+$",
    
    # ========== ë°˜ë³µ íŒ¨í„´ (GPT-4.1 ì¶”ê°€) ==========
    r"^(ë„¤|ì˜ˆ) (ë„¤|ì˜ˆ) (ë„¤|ì˜ˆ)\.?$",
    r"^(ìŒ|ì–´|ìŒìŒ|ì–´ì–´)+$",
    r"^(ë„¤ë„¤ë„¤|ì˜ˆì˜ˆì˜ˆ|ë„¤ë„¤|ì˜ˆì˜ˆ)+$",
    r"^(ì•„ì•„ì•„|ì–´ì–´ì–´|ìŒìŒìŒ)+$",
    
    # ========== êµ­íšŒ/íšŒì˜ ê´€ë ¨ (GPT-4.1 ì¶”ê°€) ==========
    r"^(ë„¤|ì˜ˆ)\.?$",
    r"^(ë„¤|ì˜ˆ),? ì•Œê² ìŠµë‹ˆë‹¤\.?$",
    r"^(ë„¤|ì˜ˆ),? ê°ì‚¬í•©ë‹ˆë‹¤\.?$",
    r"^(ë„¤|ì˜ˆ),? ì´ìƒì…ë‹ˆë‹¤\.?$",
    r"^ì´ìƒì…ë‹ˆë‹¤\.?$",
    r"^(ì´|ê·¸|ì €)ê²ƒì€(ìš”)?$",
    r"^ì´ìƒìœ¼ë¡œ ë§ˆì¹˜ê² ìŠµë‹ˆë‹¤\.?$",
    
    # ========== ì—°ê²°/ì¤€ë¹„ ìƒíƒœ (GPT-4.1 ì¶”ê°€) ==========
    r"^(ë„¤|ì˜ˆ),? ì ì‹œë§Œìš”\.?$",
    r"^(ë„¤|ì˜ˆ),? ì ê¹ë§Œìš”\.?$",
    r"^(ë„¤|ì˜ˆ),? ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤\.?$",
    r"^(ë„¤|ì˜ˆ),? ì¤€ë¹„ëìŠµë‹ˆë‹¤\.?$",
    r"^(ë„¤|ì˜ˆ),? ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤\.?$",
    r"^(ë„¤|ì˜ˆ),? ì—°ê²°ì´ ë˜ì—ˆìŠµë‹ˆë‹¤\.?$",
    r"^(ë„¤|ì˜ˆ),? ì—°ê²° ì¤‘ì…ë‹ˆë‹¤\.?$",
    r"^(ë„¤|ì˜ˆ),? ì—°ê²°ì´ ëŠê²¼ìŠµë‹ˆë‹¤\.?$",
]

# [advice from AI] ì»´íŒŒì¼ëœ íŒ¨í„´ - ë™ì  ì—…ë°ì´íŠ¸ ì§€ì›
_compiled_patterns_cache = None
_patterns_version = 0

def _get_compiled_patterns():
    """ëŸ°íƒ€ì„ì— ì¶”ê°€ëœ íŒ¨í„´ë„ í¬í•¨í•˜ì—¬ ì»´íŒŒì¼"""
    global _compiled_patterns_cache, _patterns_version
    current_version = len(HALLUCINATION_PATTERNS)
    
    if _compiled_patterns_cache is None or _patterns_version != current_version:
        _compiled_patterns_cache = [re.compile(p, re.IGNORECASE) for p in HALLUCINATION_PATTERNS]
        _patterns_version = current_version
        logger.info(f"ğŸ”„ í• ë£¨ì‹œë„¤ì´ì…˜ íŒ¨í„´ ì¬ì»´íŒŒì¼: {current_version}ê°œ")
    
    return _compiled_patterns_cache

# í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€
COMPILED_PATTERNS = [re.compile(p, re.IGNORECASE) for p in HALLUCINATION_PATTERNS]


def is_hallucination(text: str) -> bool:
    """
    í• ë£¨ì‹œë„¤ì´ì…˜ ì—¬ë¶€ í™•ì¸
    
    Args:
        text: ê²€ì‚¬í•  í…ìŠ¤íŠ¸
    
    Returns:
        True if hallucination, False otherwise
    """
    if not text:
        return True
    
    text = text.strip()
    
    # 1. ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ (1~2ê¸€ì)
    if len(text) <= 2:
        logger.debug(f"Filtered (too short): {text}")
        return True
    
    # [advice from AI] 2. ì•Œë ¤ì§„ í• ë£¨ì‹œë„¤ì´ì…˜ íŒ¨í„´ - ë™ì  ì—…ë°ì´íŠ¸ ì§€ì›!
    for pattern in _get_compiled_patterns():
        if pattern.match(text):
            logger.info(f"ğŸš« [í• ë£¨ì‹œë„¤ì´ì…˜ í•„í„°] ê±¸ë¦¼: {text}")
            return True
    
    # 3. ë™ì¼ ë‹¨ì–´/ë¬¸êµ¬ ë°˜ë³µ (3íšŒ ì´ìƒ)
    words = text.split()
    if len(words) >= 3:
        for i in range(len(words) - 2):
            if words[i] == words[i+1] == words[i+2]:
                logger.debug(f"Filtered (repeated words): {text}")
                return True
    
    # 4. ì „ì²´ í…ìŠ¤íŠ¸ ë°˜ë³µ íŒ¨í„´ (ì˜ˆ: "ì•ˆë…• ì•ˆë…• ì•ˆë…•")
    if len(words) >= 2:
        unique_words = set(words)
        if len(unique_words) == 1:
            logger.debug(f"Filtered (all same words): {text}")
            return True
    
    return False


def clean_text(text: str, preserve_music_labels: bool = True) -> str:
    """
    í…ìŠ¤íŠ¸ ì •ë¦¬
    
    Args:
        text: ì •ë¦¬í•  í…ìŠ¤íŠ¸
        preserve_music_labels: ìŒì•… ë ˆì´ë¸” ìœ ì§€ ì—¬ë¶€
    
    Returns:
        ì •ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    
    # ì—°ì† ê³µë°±ì„ í•˜ë‚˜ë¡œ
    text = re.sub(r'\s+', ' ', text)
    
    # [advice from AI] ìŒì•… ì²˜ë¦¬: ì œê±° ëŒ€ì‹  ë ˆì´ë¸”ë¡œ ë³€í™˜
    if preserve_music_labels:
        text = replace_music_with_label(text)
    else:
        # ìŒí‘œ ê¸°í˜¸ ì œê±° (ê¸°ì¡´ ë°©ì‹)
        text = re.sub(r'[â™ªâ™«ğŸµğŸ¶]+', '', text)
    
    # ì•ë’¤ ë§ˆì¹¨í‘œ/ì‰¼í‘œ ì •ë¦¬
    text = text.strip('.,!? ')
    
    return text


# =============================================================================
# [advice from AI] 2ë‹¨ê³„: ì‚¬ì „ ë§¤ì¹­ (ìˆ«ì/ì•½ì–´ ë³€í™˜)
# =============================================================================

# ì•½ì–´ ë³€í™˜ ì‚¬ì „ (ìŒì„± â†’ í…ìŠ¤íŠ¸)
ABBREVIATION_DICT = {
    # ============ IT/ê¸°ìˆ  ê´€ë ¨ ============
    "ì•„ì´ì— ì—í”„": "IMF",
    "ì—ì´ì•„ì´": "AI",
    "ì¼€ì´í”¼ì•„ì´": "KPI",
    "ë¹„í”¼ì—ìŠ¤": "BPS",
    "ì´í”¼ì—ìŠ¤": "EPS",
    "ë””ë¹„": "DB",
    "ìœ ì•„ì´": "UI",
    "ìœ ì—‘ìŠ¤": "UX",
    "ì—ì´í”¼ì•„ì´": "API",
    "ì—ìŠ¤ë””ì¼€ì´": "SDK",
    "ì”¨ë””ì—”": "CDN",
    "ë¸Œì´í”¼ì—”": "VPN",
    "ì•„ì´í”¼": "IP",
    "í‹°ì”¨í”¼": "TCP",
    "ìœ ë””í”¼": "UDP",
    "ì—ì´ì¹˜í‹°í‹°í”¼": "HTTP",
    "ì—ì´ì¹˜í‹°í‹°í”¼ì—ìŠ¤": "HTTPS",
    "ì œì´ì—ìŠ¤ì˜¤ì—”": "JSON",
    "ì—‘ìŠ¤ì— ì—˜": "XML",
    "ì”¨ì—ìŠ¤ì—ìŠ¤": "CSS",
    "ì—ì´ì¹˜í‹°ì— ì—˜": "HTML",
    "ì”¨í”¼ìœ ": "CPU",
    "ì§€í”¼ìœ ": "GPU",
    "ë¨": "RAM",
    "ì—ìŠ¤ì—ìŠ¤ë””": "SSD",
    "ì—ì´ì¹˜ë””ë””": "HDD",
    "ì—˜ì—˜ì— ": "LLM",
    "ì§€í”¼í‹°": "GPT",
    "ì—”ì—˜í”¼": "NLP",
    "ì— ì—˜": "ML",
    "ë””ì—˜": "DL",
    "ì—ìŠ¤í‹°í‹°": "STT",
    "í‹°í‹°ì—ìŠ¤": "TTS",
    "ì˜¤ì”¨ì•Œ": "OCR",
    
    # ============ ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ ============
    "ë¹„íˆ¬ë¹„": "B2B",
    "ë¹„íˆ¬ì”¨": "B2C",
    "ì‹œíˆ¬ì”¨": "C2C",
    "ì˜¤íˆ¬ì˜¤": "O2O",
    "ì•Œì•¤ë””": "R&D",
    "ì— ì•¤ì—ì´": "M&A",
    "ì•„ì´í”¼ì˜¤": "IPO",
    "í”¼ì•Œ": "PR",
    "ì—ì´ì¹˜ì•Œ": "HR",
    "ì”¨ì´ì˜¤": "CEO",
    "ì”¨ì—í”„ì˜¤": "CFO",
    "ì”¨í‹°ì˜¤": "CTO",
    "ì”¨ì˜¤ì˜¤": "COO",
    "ë¸Œì´í”¼": "VP",
    "ì§€ì— ": "GM",
    "í”¼ë””": "PD",
    "í”¼ì— ": "PM",
    "ì˜¤ì¼€ì´ì•Œ": "OKR",
    "ì—ìŠ¤ì˜¤í”¼": "SOP",
    "ì•„ë¥´ì˜¤ì•„ì´": "ROI",
    "í”¼ì•¤ì—˜": "P&L",
    
    # ============ ê¸ˆìœµ ê´€ë ¨ ============
    "í¼ì„¼íŠ¸": "%",
    "í”„ë¡œ": "%",
    "ë‹¬ëŸ¬": "$",
    "ìœ ì—ìŠ¤ë””": "USD",
    "ì¼€ì´ì•Œë”ë¸”ìœ ": "KRW",
    "ì œì´í”¼ì™€ì´": "JPY",
    "ì”¨ì—”ì™€ì´": "CNY",
    "ìœ ë¡œ": "EUR",
    
    # ============ íšŒì˜/Zoom ê´€ë ¨ ============
    "ì¤Œ": "Zoom",
    "ì¤Œ íšŒì˜": "Zoom íšŒì˜",
    "í™”ìƒíšŒì˜": "í™”ìƒíšŒì˜",
    "ë¯¸íŒ…": "ë¯¸íŒ…",
    "ì½œ": "ì½œ",
    "ì»¨í¼ëŸ°ìŠ¤": "ì»¨í¼ëŸ°ìŠ¤",
    "ì›¨ë¹„ë‚˜": "ì›¨ë¹„ë‚˜",
    "ë¸Œë ˆì´í¬ì•„ì›ƒ": "ë¸Œë ˆì´í¬ì•„ì›ƒ",
    "ìŠ¤í¬ë¦°ì‰ì–´": "í™”ë©´ê³µìœ ",
    "ë®¤íŠ¸": "ìŒì†Œê±°",
    "ì–¸ë®¤íŠ¸": "ìŒì†Œê±° í•´ì œ",
    
    # ============ ê¸°íƒ€ ============
    "ì˜¤ì¼€ì´": "OK",
    "ì—”ì§€": "NG",
    "í‹°ë¹„": "TV",
    "í”¼ì”¨": "PC",
    "ìœ ì—ìŠ¤ë¹„": "USB",
    "ì™€ì´íŒŒì´": "WiFi",
    "ë¸”ë£¨íˆ¬ìŠ¤": "Bluetooth",
    "íì•Œ": "QR",
    "ì´ë©”ì¼": "ì´ë©”ì¼",
    "ìœ ì•Œì—˜": "URL",
    
    # ============ ì˜ì–´ ë°œìŒ â†’ ì•½ì–´ ============
    "R and D": "R&D",
    "r and d": "R&D",
    "R & D": "R&D",
    "M and A": "M&A",
    "m and a": "M&A",
    "P and L": "P&L",
    "fifty percent": "50%",
    "twenty percent": "20%",
    "thirty percent": "30%",
    "one hundred percent": "100%",
    
    # ============ êµ­ì œê¸°êµ¬/ì •ì¹˜ ì•½ì–´ (GPT-4.1 ì¶”ê°€) ============
    "ì˜¤ì´ì‹œë””": "OECD",
    "ë”ë¸”ìœ í‹°ì˜¤": "WTO",
    "ì—í”„í‹°ì—ì´": "FTA",
    "ì•Œì”¨ì´í”¼": "RCEP",
    "í‹°í”¼í”¼": "TPP",
    "ì—ìŠ¤ë””ì§€ì—ìŠ¤": "SDGs",
    "ì—ì´ì•„ì´ì•„ì´ë¹„": "AIIB",
    "ì—ì´ë””ë¹„": "ADB",
    "ì—ì´í™": "APEC",
    "ì”¨ì˜¤í”¼": "COP",
    "ì—”ë””ì”¨": "NDC",
    "ì§€ë””í”¼": "GDP",
    "ì§€ì—”í”¼": "GNP",
    
    # ============ ì •ë¶€ê¸°ê´€ ì˜ë¬¸ ì•½ì–´ (GPT-4.1 ì¶”ê°€) ============
    "ëª¨ì—í”„": "MOEF",      # ê¸°íšì¬ì •ë¶€
    "ëª¨ì´ìŠ¤": "MOIS",      # í–‰ì •ì•ˆì „ë¶€
    "ëª¨íŒŒ": "MOFA",        # ì™¸êµë¶€
    "ëª¨ìœ ": "MOU",         # í†µì¼ë¶€
    "ëª¨ì œì´": "MOJ",       # ë²•ë¬´ë¶€
    "ì— ì—”ë””": "MND",       # êµ­ë°©ë¶€
    "ëª¨íˆíŠ¸": "MOLIT",     # êµ­í† êµí†µë¶€
    "ëª¨ì—ì´ì¹˜ë”ë¸”ìœ ": "MOHW",  # ë³´ê±´ë³µì§€ë¶€
    "ì¼€ì´ë””ì•„ì´": "KDI",    # í•œêµ­ê°œë°œì—°êµ¬ì›
    "ì—”ì•„ì´ì—ìŠ¤": "NIS",    # êµ­ê°€ì •ë³´ì›
    "ë¹„ì—ì´ì•„ì´": "BAI",    # ê°ì‚¬ì›
    "ì¼€ì´ì—í”„í‹°ì”¨": "KFTC", # ê³µì •ê±°ë˜ìœ„ì›íšŒ
    "ì—í”„ì—ìŠ¤ì—ìŠ¤": "FSS",  # ê¸ˆìœµê°ë…ì›
}

# =============================================================================
# [advice from AI] êµ­íšŒ/êµ­ë¬´íšŒì˜ ì „ë¬¸ ìš©ì–´ ì‚¬ì „
# =============================================================================

# ì˜¤ì¸ì‹ êµì • ì‚¬ì „ (ìì£¼ ì˜ëª» ì¸ì‹ë˜ëŠ” ìš©ì–´)
GOVERNMENT_CORRECTION_DICT = {
    # ============ íšŒì˜ ìš©ì–´ ì˜¤ì¸ì‹ êµì • ============
    "êµ­ë¯¼ì˜ë¢°": "êµ­ë¯¼ì˜ë¡€",
    "êµ­ë¯¼ ì˜ë¢°": "êµ­ë¯¼ì˜ë¡€",
    "êµ­ë¯¼ì´ë¡€": "êµ­ë¯¼ì˜ë¡€",
    "ê³µëª¨íšŒì˜": "êµ­ë¬´íšŒì˜",
    "êµ­ëª¨íšŒì˜": "êµ­ë¬´íšŒì˜",
    "êµ­ë¬´ íšŒì˜": "êµ­ë¬´íšŒì˜",
    "ì„±ë ¹": "ì˜ì¥",  # ë¬¸ë§¥ìƒ "ì˜ì¥ê»˜ì„œ"
    "ì„±ë ¹ê»˜ì„œ": "ì˜ì¥ê»˜ì„œ",
    "ê°œì˜": "ê°œì˜",  # íšŒì˜ ì‹œì‘
    "íì˜": "ííšŒ",
    "í˜íšŒ": "ííšŒ",
    
    # ============ ì§ì±…ëª… ============
    "ëŒ€í†µì˜": "ëŒ€í†µë ¹",
    "ëŒ€í‰ë ¹": "ëŒ€í†µë ¹",
    "êµ­ë¬´ì´ë‹ˆ": "êµ­ë¬´ì´ë¦¬",
    "êµ­ë¬´ ì´ë¦¬": "êµ­ë¬´ì´ë¦¬",
    "ë¶€ì´ë‹ˆ": "ë¶€ì´ë¦¬",
    "ì¥ê´€ë‹˜": "ì¥ê´€",
    "ì°¨ê´€ë‹˜": "ì°¨ê´€",
    "ì²­ì¥ë‹˜": "ì²­ì¥",
    
    # ============ ì •ë¶€ ê¸°ê´€ëª… ============
    "ê¸°íšŒì¬ì •ë¶€": "ê¸°íšì¬ì •ë¶€",
    "ê¸°íš ì¬ì •ë¶€": "ê¸°íšì¬ì •ë¶€",
    "ì™¸êµë¶€": "ì™¸êµë¶€",
    "êµ­ë°©ë¶€": "êµ­ë°©ë¶€",
    "í–‰ì •ì•ˆì „ë¶€": "í–‰ì •ì•ˆì „ë¶€",
    "í–‰ì•ˆë¶€": "í–‰ì •ì•ˆì „ë¶€",
    "ë¬¸ì²´ë¶€": "ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€",
    "ë¬¸í™”ì²´ìœ¡ ê´€ê´‘ë¶€": "ë¬¸í™”ì²´ìœ¡ê´€ê´‘ë¶€",
    "ë†ì‹í’ˆë¶€": "ë†ë¦¼ì¶•ì‚°ì‹í’ˆë¶€",
    "ì‚°ì—…ë¶€": "ì‚°ì—…í†µìƒìì›ë¶€",
    "ì‚°ìë¶€": "ì‚°ì—…í†µìƒìì›ë¶€",
    "ë³µì§€ë¶€": "ë³´ê±´ë³µì§€ë¶€",
    "í™˜ê²½ë¶€": "í™˜ê²½ë¶€",
    "ê³ ìš©ë¶€": "ê³ ìš©ë…¸ë™ë¶€",
    "ì—¬ê°€ë¶€": "ì—¬ì„±ê°€ì¡±ë¶€",
    "êµ­í† ë¶€": "êµ­í† êµí†µë¶€",
    "í•´ìˆ˜ë¶€": "í•´ì–‘ìˆ˜ì‚°ë¶€",
    "ì¤‘ê¸°ë¶€": "ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ë¶€",
    "ê³¼ê¸°ë¶€": "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€",
    "ê³¼ê¸°ì •í†µë¶€": "ê³¼í•™ê¸°ìˆ ì •ë³´í†µì‹ ë¶€",
    "ë²•ë¬´ë¶€": "ë²•ë¬´ë¶€",
    "êµìœ¡ë¶€": "êµìœ¡ë¶€",
    "í†µì¼ë¶€": "í†µì¼ë¶€",
    
    # ============ êµ­íšŒ ìš©ì–´ ============
    "ë³¸íšŒì˜": "ë³¸íšŒì˜",
    "ìƒì„ìœ„": "ìƒì„ìœ„ì›íšŒ",
    "ìƒì„ ìœ„ì›íšŒ": "ìƒì„ìœ„ì›íšŒ",
    "íŠ¹ìœ„": "íŠ¹ë³„ìœ„ì›íšŒ",
    "íŠ¹ë³„ ìœ„ì›íšŒ": "íŠ¹ë³„ìœ„ì›íšŒ",
    "ì˜ˆê²°ìœ„": "ì˜ˆì‚°ê²°ì‚°íŠ¹ë³„ìœ„ì›íšŒ",
    "ë²•ì‚¬ìœ„": "ë²•ì œì‚¬ë²•ìœ„ì›íšŒ",
    "ì •ë¬´ìœ„": "ì •ë¬´ìœ„ì›íšŒ",
    "ê¸°ì¬ìœ„": "ê¸°íšì¬ì •ìœ„ì›íšŒ",
    "êµ­ë°©ìœ„": "êµ­ë°©ìœ„ì›íšŒ",
    "í–‰ì•ˆìœ„": "í–‰ì •ì•ˆì „ìœ„ì›íšŒ",
    "ë¬¸ì²´ìœ„": "ë¬¸í™”ì²´ìœ¡ê´€ê´‘ìœ„ì›íšŒ",
    "ë†í•´ìˆ˜ìœ„": "ë†ë¦¼ì¶•ì‚°ì‹í’ˆí•´ì–‘ìˆ˜ì‚°ìœ„ì›íšŒ",
    "ì‚°ììœ„": "ì‚°ì—…í†µìƒìì›ì¤‘ì†Œë²¤ì²˜ê¸°ì—…ìœ„ì›íšŒ",
    "ë³µì§€ìœ„": "ë³´ê±´ë³µì§€ìœ„ì›íšŒ",
    "í™˜ë…¸ìœ„": "í™˜ê²½ë…¸ë™ìœ„ì›íšŒ",
    "êµ­í† ìœ„": "êµ­í† êµí†µìœ„ì›íšŒ",
    "êµìœ¡ìœ„": "êµìœ¡ìœ„ì›íšŒ",
    "ê³¼ë°©ìœ„": "ê³¼í•™ê¸°ìˆ ì •ë³´ë°©ì†¡í†µì‹ ìœ„ì›íšŒ",
    "ì™¸í†µìœ„": "ì™¸êµí†µì¼ìœ„ì›íšŒ",
    "ì—¬ê°€ìœ„": "ì—¬ì„±ê°€ì¡±ìœ„ì›íšŒ",
    "ì •ë³´ìœ„": "ì •ë³´ìœ„ì›íšŒ",
    "ìœ¤ë¦¬ìœ„": "ìœ¤ë¦¬íŠ¹ë³„ìœ„ì›íšŒ",
    
    # ============ ë²•ë¥ /í–‰ì • ìš©ì–´ ============
    "ì˜ì•ˆ": "ì˜ì•ˆ",
    "ë²•ë¥ ì•ˆ": "ë²•ë¥ ì•ˆ",
    "ë²•ë¥  ì•ˆ": "ë²•ë¥ ì•ˆ",
    "ì‹œí–‰ë ¹": "ì‹œí–‰ë ¹",
    "ì‹œí–‰ ë ¹": "ì‹œí–‰ë ¹",
    "ëŒ€í†µë ¹ë ¹": "ëŒ€í†µë ¹ë ¹",
    "ëŒ€í†µë ¹ ë ¹": "ëŒ€í†µë ¹ë ¹",
    "ë™ì˜ì•ˆ": "ë™ì˜ì•ˆ",
    "ë™ì˜ ì•ˆ": "ë™ì˜ì•ˆ",
    "ê²°ì˜ì•ˆ": "ê²°ì˜ì•ˆ",
    "ê²°ì˜ ì•ˆ": "ê²°ì˜ì•ˆ",
    "ê±´ì˜ì•ˆ": "ê±´ì˜ì•ˆ",
    "ì˜ˆì‚°ì•ˆ": "ì˜ˆì‚°ì•ˆ",
    "ì˜ˆì‚° ì•ˆ": "ì˜ˆì‚°ì•ˆ",
    "ì¶”ê²½": "ì¶”ê°€ê²½ì •ì˜ˆì‚°",
    "ì¶”ê²½ì•ˆ": "ì¶”ê°€ê²½ì •ì˜ˆì‚°ì•ˆ",
    "ë³¸ì˜ˆì‚°": "ë³¸ì˜ˆì‚°",
    
    # ============ íšŒì˜ ì§„í–‰ ìš©ì–´ (GPT-4.1 ë³´ê°•) ============
    "ê°€ê²°": "ê°€ê²°",
    "ë¶€ê²°": "ë¶€ê²°",
    "ì¬ì ": "ì¬ì ",
    "ì¶œì„": "ì¶œì„",
    "ì°¬ì„±": "ì°¬ì„±",
    "ë°˜ëŒ€": "ë°˜ëŒ€",
    "ê¸°ê¶Œ": "ê¸°ê¶Œ",
    "ì˜ê²°": "ì˜ê²°",
    "ì˜ê²° ì •ì¡±ìˆ˜": "ì˜ê²°ì •ì¡±ìˆ˜",
    "ê³¼ë°˜ìˆ˜": "ê³¼ë°˜ìˆ˜",
    "ì‚¼ë¶„ì˜ì´": "3ë¶„ì˜ 2",
    "3ë¶„ì˜ ì´": "3ë¶„ì˜ 2",
    "ì´ì˜ì—†ìŒ": "ì´ì˜ ì—†ìŒ",
    "ì´ì˜ ì—†ìŒ": "ì´ì˜ ì—†ìŒ",
    "ë§Œì¥ì¼ì¹˜": "ë§Œì¥ì¼ì¹˜",
    "í‘œê²°": "í‘œê²°",
    "ê¸°ëª…íˆ¬í‘œ": "ê¸°ëª…íˆ¬í‘œ",
    "ë¬´ê¸°ëª…íˆ¬í‘œ": "ë¬´ê¸°ëª…íˆ¬í‘œ",
    # GPT-4.1 ì¶”ê°€
    "ì˜ì‚¬ì¼ì •": "ì˜ì‚¬ì¼ì •",
    "ì˜ì‚¬ì§„í–‰ë°œì–¸": "ì˜ì‚¬ì§„í–‰ë°œì–¸",
    "ì •íšŒ": "ì •íšŒ",
    "ì‚°íšŒ": "ì‚°íšŒ",
    "ì†ê°œ": "ì†ê°œ",
    "ê°œíšŒ": "ê°œíšŒ",
    "ìƒì •": "ìƒì •",
    "ì‹¬ì‚¬": "ì‹¬ì‚¬",
    "ì†Œìœ„ì›íšŒ": "ì†Œìœ„ì›íšŒ",
    "ê°„ì‚¬": "ê°„ì‚¬",
    "ìœ„ì›ì¥": "ìœ„ì›ì¥",
    "ì§ˆì˜": "ì§ˆì˜",
    "ë‹µë³€": "ë‹µë³€",
    "ìë£Œì œì¶œ": "ìë£Œì œì¶œ",
    "ì˜ì‚¬ë´‰": "ì˜ì‚¬ë´‰",
    "ì •ì¡±ìˆ˜": "ì •ì¡±ìˆ˜",
    "ìœ„ì›ì •ìˆ˜": "ìœ„ì›ì •ìˆ˜",
    "ìœ„ì›ì •ì¡±ìˆ˜": "ìœ„ì›ì •ì¡±ìˆ˜",
    "ì²­ì›": "ì²­ì›",
    "êµ­ì •ì¡°ì‚¬": "êµ­ì •ì¡°ì‚¬",
    "ìš´ì˜ìœ„ì›íšŒ": "ìš´ì˜ìœ„ì›íšŒ",
    
    # ============ ê¸°íƒ€ ì •ë¶€ ìš©ì–´ ============
    "ì •ì±…": "ì •ì±…",
    "ì‹œì±…": "ì‹œì±…",
    "í˜„ì•ˆ": "í˜„ì•ˆ",
    "ì•ˆê±´": "ì•ˆê±´",
    "ë³´ê³ ": "ë³´ê³ ",
    "ì‹¬ì˜": "ì‹¬ì˜",
    "ì˜ê²°": "ì˜ê²°",
    "ìŠ¹ì¸": "ìŠ¹ì¸",
    "í—ˆê°€": "í—ˆê°€",
    "ì¸ê°€": "ì¸ê°€",
    "êµ­ì •ê°ì‚¬": "êµ­ì •ê°ì‚¬",
    "êµ­ì • ê°ì‚¬": "êµ­ì •ê°ì‚¬",
    "êµ­ê°": "êµ­ì •ê°ì‚¬",
    "ì²­ë¬¸íšŒ": "ì²­ë¬¸íšŒ",
    "ì²­ë¬¸ íšŒ": "ì²­ë¬¸íšŒ",
    "ì¸ì‚¬ì²­ë¬¸íšŒ": "ì¸ì‚¬ì²­ë¬¸íšŒ",
    "ëŒ€ì •ë¶€ì§ˆë¬¸": "ëŒ€ì •ë¶€ì§ˆë¬¸",
    "ëŒ€ì •ë¶€ ì§ˆë¬¸": "ëŒ€ì •ë¶€ì§ˆë¬¸",
}

# [advice from AI] ê³ ìœ ëª…ì‚¬ ì‚¬ì „ (ì¸ëª…/ê¸°ê´€ëª…/ì§€ëª…)
# [advice from AI] ê³ ìœ ëª…ì‚¬ ì‚¬ì „ - GPT-4.1 ì—„ì„  (êµ­íšŒ/ì •ì¹˜/ì˜ì •í™œë™)
PROPER_NOUN_DICT = {
    # ============ ì—­ëŒ€ ëŒ€í†µë ¹ ============
    "ì´ì¬ëª…": "ì´ì¬ëª…",
    "ì´ ì¬ëª…": "ì´ì¬ëª…",
    "ìœ¤ì„ì—´": "ìœ¤ì„ì—´",
    "ìœ¤ ì„ì—´": "ìœ¤ì„ì—´",
    "ë¬¸ì¬ì¸": "ë¬¸ì¬ì¸",
    "ë°•ê·¼í˜œ": "ë°•ê·¼í˜œ",
    "ì´ëª…ë°•": "ì´ëª…ë°•",
    "ë…¸ë¬´í˜„": "ë…¸ë¬´í˜„",
    "ê¹€ëŒ€ì¤‘": "ê¹€ëŒ€ì¤‘",
    "ê¹€ì˜ì‚¼": "ê¹€ì˜ì‚¼",
    "ì „ë‘í™˜": "ì „ë‘í™˜",
    "ë…¸íƒœìš°": "ë…¸íƒœìš°",
    
    # ============ êµ­ë¬´ì´ë¦¬/ì£¼ìš” ì •ì¹˜ì¸ (GPT-4.1 ì¶”ê°€) ============
    "í•œë•ìˆ˜": "í•œë•ìˆ˜",
    "ì´ë‚™ì—°": "ì´ë‚™ì—°",
    "ì •ì„¸ê· ": "ì •ì„¸ê· ",
    "ê¹€ê¸°í˜„": "ê¹€ê¸°í˜„",
    "ì´ì¤€ì„": "ì´ì¤€ì„",
    "í™ì¤€í‘œ": "í™ì¤€í‘œ",
    "ìœ ìŠ¹ë¯¼": "ìœ ìŠ¹ë¯¼",
    "ì•ˆì² ìˆ˜": "ì•ˆì² ìˆ˜",
    "ì‹¬ìƒì •": "ì‹¬ìƒì •",
    "ì´ì •ë¯¸": "ì´ì •ë¯¸",
    "ì¡°êµ­": "ì¡°êµ­",
    "ì¶”ë¯¸ì• ": "ì¶”ë¯¸ì• ",
    "ë°•ìš©ì§„": "ë°•ìš©ì§„",
    "ë‚˜ê²½ì›": "ë‚˜ê²½ì›",
    "ì˜¤ì„¸í›ˆ": "ì˜¤ì„¸í›ˆ",
    "ë°•ì˜ì„ ": "ë°•ì˜ì„ ",
    "ê¹€ë™ì—°": "ê¹€ë™ì—°",
    "ê¹€ì§„í‘œ": "ê¹€ì§„í‘œ",
    
    # ============ ì •ë‹¹ (GPT-4.1 ì¶”ê°€) ============
    "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ë”ë¯¼ì£¼": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "ë¯¼ì£¼ë‹¹": "ë”ë¶ˆì–´ë¯¼ì£¼ë‹¹",
    "êµ­ë¯¼ì˜í˜": "êµ­ë¯¼ì˜í˜",
    "êµ­í˜": "êµ­ë¯¼ì˜í˜",
    "ì¡°êµ­í˜ì‹ ë‹¹": "ì¡°êµ­í˜ì‹ ë‹¹",
    "ì¡°êµ­ í˜ì‹ ë‹¹": "ì¡°êµ­í˜ì‹ ë‹¹",
    "ê°œí˜ì‹ ë‹¹": "ê°œí˜ì‹ ë‹¹",
    "ì§„ë³´ë‹¹": "ì§„ë³´ë‹¹",
    "ì •ì˜ë‹¹": "ì •ì˜ë‹¹",
    "êµ­ë¯¼ì˜ë‹¹": "êµ­ë¯¼ì˜ë‹¹",
    "ë…¹ìƒ‰ë‹¹": "ë…¹ìƒ‰ë‹¹",
    "ê¸°ë³¸ì†Œë“ë‹¹": "ê¸°ë³¸ì†Œë“ë‹¹",
    "ì‹œëŒ€ì „í™˜": "ì‹œëŒ€ì „í™˜",
    "ë…¸ë™ë‹¹": "ë…¸ë™ë‹¹",
    "ìƒˆë¡œìš´ë¯¸ë˜": "ìƒˆë¡œìš´ë¯¸ë˜",
    
    # ============ ì£¼ìš” ê¸°ê´€ ============
    "ì²­ì™€ëŒ€": "ì²­ì™€ëŒ€",
    "ì²­ì•„ëŒ€": "ì²­ì™€ëŒ€",
    "ëŒ€í†µë ¹ì‹¤": "ëŒ€í†µë ¹ì‹¤",
    "ëŒ€í†µë ¹ ì‹¤": "ëŒ€í†µë ¹ì‹¤",
    "ìš©ì‚°ì²­ì‚¬": "ìš©ì‚°ì²­ì‚¬",
    "êµ­íšŒì˜ì‚¬ë‹¹": "êµ­íšŒì˜ì‚¬ë‹¹",
    "êµ­íšŒ ì˜ì‚¬ë‹¹": "êµ­íšŒì˜ì‚¬ë‹¹",
    "í—Œë²•ì¬íŒì†Œ": "í—Œë²•ì¬íŒì†Œ",
    "í—Œì¬": "í—Œë²•ì¬íŒì†Œ",
    "ëŒ€ë²•ì›": "ëŒ€ë²•ì›",
    "ê°ì‚¬ì›": "ê°ì‚¬ì›",
    "êµ­ì •ì›": "êµ­ê°€ì •ë³´ì›",
    "êµ­ê°€ì •ë³´ì›": "êµ­ê°€ì •ë³´ì›",
    "ê²½ì°°ì²­": "ê²½ì°°ì²­",
    "ê²€ì°°ì²­": "ê²€ì°°ì²­",
    "ëŒ€ê²€ì°°ì²­": "ëŒ€ê²€ì°°ì²­",
    "êµ­ì„¸ì²­": "êµ­ì„¸ì²­",
    "ê´€ì„¸ì²­": "ê´€ì„¸ì²­",
    "íŠ¹í—ˆì²­": "íŠ¹í—ˆì²­",
    "ê¸°ìƒì²­": "ê¸°ìƒì²­",
    "ì†Œë°©ì²­": "ì†Œë°©ì²­",
    "ì‚°ë¦¼ì²­": "ì‚°ë¦¼ì²­",
    "ì¡°ë‹¬ì²­": "ì¡°ë‹¬ì²­",
    "í†µê³„ì²­": "í†µê³„ì²­",
    "ë³‘ë¬´ì²­": "ë³‘ë¬´ì²­",
    "ë°©ìœ„ì‚¬ì—…ì²­": "ë°©ìœ„ì‚¬ì—…ì²­",
    "í–‰ì •ì•ˆì „ë¶€": "í–‰ì •ì•ˆì „ë¶€",
    
    # ============ ì§€ì—­/ì§€ëª… ============
    "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸íŠ¹ë³„ì‹œ",
    "ì„œìš¸ì‹œ": "ì„œìš¸ì‹œ",
    "ë¶€ì‚°ê´‘ì—­ì‹œ": "ë¶€ì‚°ê´‘ì—­ì‹œ",
    "ë¶€ì‚°ì‹œ": "ë¶€ì‚°ì‹œ",
    "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
    "ëŒ€êµ¬ì‹œ": "ëŒ€êµ¬ì‹œ",
    "ì¸ì²œê´‘ì—­ì‹œ": "ì¸ì²œê´‘ì—­ì‹œ",
    "ì¸ì²œì‹œ": "ì¸ì²œì‹œ",
    "ê´‘ì£¼ê´‘ì—­ì‹œ": "ê´‘ì£¼ê´‘ì—­ì‹œ",
    "ê´‘ì£¼ì‹œ": "ê´‘ì£¼ì‹œ",
    "ëŒ€ì „ê´‘ì—­ì‹œ": "ëŒ€ì „ê´‘ì—­ì‹œ",
    "ëŒ€ì „ì‹œ": "ëŒ€ì „ì‹œ",
    "ìš¸ì‚°ê´‘ì—­ì‹œ": "ìš¸ì‚°ê´‘ì—­ì‹œ",
    "ìš¸ì‚°ì‹œ": "ìš¸ì‚°ì‹œ",
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
    "ì„¸ì¢…ì‹œ": "ì„¸ì¢…ì‹œ",
    "ê²½ê¸°ë„": "ê²½ê¸°ë„",
    "ê°•ì›ë„": "ê°•ì›ë„",
    "ì¶©ì²­ë¶ë„": "ì¶©ì²­ë¶ë„",
    "ì¶©ë¶": "ì¶©ì²­ë¶ë„",
    "ì¶©ì²­ë‚¨ë„": "ì¶©ì²­ë‚¨ë„",
    "ì¶©ë‚¨": "ì¶©ì²­ë‚¨ë„",
    "ì „ë¼ë¶ë„": "ì „ë¼ë¶ë„",
    "ì „ë¶": "ì „ë¼ë¶ë„",
    "ì „ë¼ë‚¨ë„": "ì „ë¼ë‚¨ë„",
    "ì „ë‚¨": "ì „ë¼ë‚¨ë„",
    "ê²½ìƒë¶ë„": "ê²½ìƒë¶ë„",
    "ê²½ë¶": "ê²½ìƒë¶ë„",
    "ê²½ìƒë‚¨ë„": "ê²½ìƒë‚¨ë„",
    "ê²½ë‚¨": "ê²½ìƒë‚¨ë„",
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„": "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
    "ì œì£¼ë„": "ì œì£¼ë„",
    
    # ============ êµ­ì œê¸°êµ¬ ì˜¤ì¸ì‹ ============
    "ìœ ì—”": "UN",
    "ìœ ì•¤": "UN",
    "ë‚˜í† ": "NATO",
    "ë‚˜ë˜": "NATO",
    "ì•„ì„¸ì•ˆ": "ASEAN",
    "ì˜¤í™": "OPEC",
    "ì§€íˆ¬ì‹­": "G20",
    "ì§€ì´ì‹­": "G20",
    "ì§€ì„¸ë¸": "G7",
    "ì§€ì¹ ": "G7",
    "ì•„ì´ì— ì—í”„": "IMF",
    "ì„¸ê³„ì€í–‰": "ì„¸ê³„ì€í–‰",
    "ì›”ë“œë±…í¬": "ì„¸ê³„ì€í–‰",
    "ì„¸ê³„ë³´ê±´ê¸°êµ¬": "WHO",
    "ë”ë¸”ìœ ì—ì´ì¹˜ì˜¤": "WHO",
    
    # ============ ë°•ìˆ˜/ì¡ìŒ ì˜¤ì¸ì‹ ============
    "ë°•ìˆ˜": "[ë°•ìˆ˜]",
    "í™˜í˜¸": "[í™˜í˜¸]",
    "ì›…ì„±ì›…ì„±": "[ì›…ì„±]",
    "ì›…ì„±ê±°ë¦¼": "[ì›…ì„±]",
}

# ìˆ«ì íŒ¨í„´ ë³€í™˜ (ì •ê·œì‹ìœ¼ë¡œ ì²˜ë¦¬)
NUMBER_PATTERNS = [
    # ê¸ˆì•¡ íŒ¨í„´
    (r"(\d+)\s*ë°±ë§Œ\s*ì›", lambda m: f"{int(m.group(1)) * 1000000:,}ì›"),
    (r"(\d+)\s*ì²œë§Œ\s*ì›", lambda m: f"{int(m.group(1)) * 10000000:,}ì›"),
    (r"(\d+)\s*ì–µ\s*ì›", lambda m: f"{int(m.group(1)) * 100000000:,}ì›"),
    (r"(\d+)\s*ì¡°\s*ì›", lambda m: f"{int(m.group(1)) * 1000000000000:,}ì›"),
    (r"ë°±ë§Œ\s*ì›", "1,000,000ì›"),
    (r"ì²œë§Œ\s*ì›", "10,000,000ì›"),
    (r"ì¼ì–µ\s*ì›", "100,000,000ì›"),
    (r"ì‹­ì–µ\s*ì›", "1,000,000,000ì›"),
    (r"ë°±ì–µ\s*ì›", "10,000,000,000ì›"),
    (r"ì²œì–µ\s*ì›", "100,000,000,000ì›"),
    (r"ì¼ì¡°\s*ì›", "1,000,000,000,000ì›"),
    
    # í¼ì„¼íŠ¸ íŒ¨í„´
    (r"(\d+)\s*í¼ì„¼íŠ¸", r"\1%"),
    (r"(\d+)\s*í”„ë¡œ", r"\1%"),
]


def apply_dictionary_mapping(text: str, apply_government_dict: bool = True) -> str:
    """
    ì‚¬ì „ ë§¤ì¹­ ì ìš©
    
    - ì•½ì–´ ë³€í™˜ (ì•„ì´ì— ì—í”„ â†’ IMF)
    - ìˆ«ì ë³€í™˜ (ë°±ë§Œì› â†’ 1,000,000ì›)
    - êµ­íšŒ/êµ­ë¬´íšŒì˜ ìš©ì–´ êµì • (êµ­ë¯¼ì˜ë¢° â†’ êµ­ë¯¼ì˜ë¡€)
    - ê³ ìœ ëª…ì‚¬ êµì • (ì¸ëª…/ê¸°ê´€ëª…/ì§€ëª…)
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        apply_government_dict: ì •ë¶€ ìš©ì–´ ì‚¬ì „ ì ìš© ì—¬ë¶€
    
    Returns:
        ë³€í™˜ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return text
    
    result = text
    
    # [advice from AI] 0. êµ­íšŒ/êµ­ë¬´íšŒì˜ ì˜¤ì¸ì‹ êµì • (ë¨¼ì € ì ìš©)
    if apply_government_dict:
        for wrong, correct in GOVERNMENT_CORRECTION_DICT.items():
            pattern = re.compile(re.escape(wrong), re.IGNORECASE)
            result = pattern.sub(correct, result)
    
    # [advice from AI] 0.5. ê³ ìœ ëª…ì‚¬ ì‚¬ì „ ì ìš© (ì¸ëª…/ê¸°ê´€ëª…/ì§€ëª…)
    for wrong, correct in PROPER_NOUN_DICT.items():
        pattern = re.compile(re.escape(wrong), re.IGNORECASE)
        result = pattern.sub(correct, result)
    
    # 1. ì•½ì–´ ë³€í™˜ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    for korean, english in ABBREVIATION_DICT.items():
        pattern = re.compile(re.escape(korean), re.IGNORECASE)
        result = pattern.sub(english, result)
    
    # 2. ìˆ«ì íŒ¨í„´ ë³€í™˜
    for pattern, replacement in NUMBER_PATTERNS:
        if callable(replacement):
            result = re.sub(pattern, replacement, result)
        else:
            result = re.sub(pattern, replacement, result)
    
    return result


# =============================================================================
# [advice from AI] 3ë‹¨ê³„: ì„¸ê·¸ë¨¼íŠ¸ í•„í„°ë§
# =============================================================================

def filter_segments(
    segments: List[dict],
    min_confidence: float = -0.8,
    max_no_speech_prob: float = 0.95,
    detect_music_enabled: bool = True,
) -> List[dict]:
    """
    ì„¸ê·¸ë¨¼íŠ¸ í•„í„°ë§
    
    - í• ë£¨ì‹œë„¤ì´ì…˜ ì œê±°
    - ì €ì‹ ë¢°ë„ ì œê±°
    - ìŒì•… ê°ì§€ ë° ë ˆì´ë¸”ë§
    - í…ìŠ¤íŠ¸ ì •ë¦¬ ë° ì‚¬ì „ ë§¤ì¹­ ì ìš©
    
    Args:
        segments: ì›ë³¸ ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡
        min_confidence: ìµœì†Œ ì‹ ë¢°ë„ (avg_logprob ê¸°ì¤€)
        max_no_speech_prob: ìµœëŒ€ ë¬´ìŒ í™•ë¥ 
        detect_music_enabled: ìŒì•… ê°ì§€ í™œì„±í™” ì—¬ë¶€
    
    Returns:
        í•„í„°ë§ëœ ì„¸ê·¸ë¨¼íŠ¸ ëª©ë¡
    """
    filtered = []
    
    for seg in segments:
        raw_text = seg.get("text", "")
        avg_logprob = seg.get("avg_logprob", 0)
        no_speech_prob = seg.get("no_speech_prob", 0)
        
        # [advice from AI] ìŒì•… ê°ì§€ (í•„í„°ë§ ì „ì— ë¨¼ì € ì²´í¬)
        if detect_music_enabled:
            music_result = detect_music(raw_text, no_speech_prob, avg_logprob)
            if music_result.is_music:
                logger.info(
                    f"ğŸµ Music detected: '{raw_text}' -> '{music_result.replacement_text}' "
                    f"(type={music_result.content_type.value}, conf={music_result.confidence:.2f})"
                )
                filtered.append({
                    **seg,
                    "text": music_result.replacement_text,
                    "is_music": True,
                    "music_type": music_result.content_type.value,
                    "confidence": music_result.confidence,
                })
                continue
        
        text = clean_text(raw_text)
        
        # 1. ë¹ˆ í…ìŠ¤íŠ¸ ìŠ¤í‚µ
        if not text:
            continue
        
        # 2. í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬
        if is_hallucination(text):
            logger.info(f"Hallucination filtered: '{raw_text}' (logprob: {avg_logprob:.2f})")
            continue
        
        # 3. ì‹ ë¢°ë„ ì²´í¬
        if avg_logprob < min_confidence:
            logger.info(f"Low confidence filtered: '{text}' (logprob: {avg_logprob:.2f})")
            continue
        
        # 4. ë¬´ìŒ í™•ë¥  ì²´í¬
        if no_speech_prob > max_no_speech_prob:
            logger.info(f"No speech filtered: '{text}' (no_speech: {no_speech_prob:.2f})")
            continue
        
        # 5. ì‚¬ì „ ë§¤ì¹­ ì ìš©
        text = apply_dictionary_mapping(text)
        
        # í•„í„°ë§ í†µê³¼
        filtered.append({
            **seg,
            "text": text,
            "is_music": False,
            "confidence": 1.0 + avg_logprob,  # ì •ê·œí™”ëœ ì‹ ë¢°ë„ (0~1 ë²”ìœ„ë¡œ ë³€í™˜)
        })
    
    return filtered


def postprocess_text(text: str, detect_speaker_change: bool = False) -> str:
    """
    í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ (ë‹¨ì¼ í…ìŠ¤íŠ¸ìš©)
    
    Args:
        text: í›„ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
        detect_speaker_change: í™”ì ë³€ê²½ íŒ¨í„´ ê°ì§€ ì—¬ë¶€ (ê¸°ë³¸: False)
    
    Returns:
        í›„ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
    """
    if not text:
        return ""
    
    # 1. í…ìŠ¤íŠ¸ ì •ë¦¬
    text = clean_text(text)
    
    # 2. í• ë£¨ì‹œë„¤ì´ì…˜ ì²´í¬
    if is_hallucination(text):
        return ""
    
    # 3. ì‚¬ì „ ë§¤ì¹­
    text = apply_dictionary_mapping(text)
    
    # [advice from AI] 4. ë°©ì†¡ ì•ˆì „ í•„í„° (ë¹„ì†ì–´ + ë¯¼ê°ì •ë³´)
    text = apply_broadcast_safety_filter(text)
    
    # [advice from AI] 5. í™”ì ë³€ê²½ íŒ¨í„´ ê°ì§€ ë° ì¤„ë°”ê¿ˆ ì‚½ì…
    if detect_speaker_change:
        text = detect_and_insert_speaker_breaks(text)
    
    return text


# =============================================================================
# [advice from AI] í™”ì ë³€ê²½ ì¶”ì • íŒ¨í„´ - ì„¸ê·¸ë¨¼íŠ¸ ë‚´ í™”ì ë³€ê²½ ê°ì§€
# =============================================================================

# ì‘ë‹µ/ë™ì˜ ì‹œì‘ íŒ¨í„´ (í™”ì ë³€ê²½ ê°€ëŠ¥ì„± ë†’ìŒ)
SPEAKER_CHANGE_RESPONSE_PATTERNS = [
    # ë™ì˜/ì‘ë‹µ ì‹œì‘
    (r'(\S)\s+(ë„¤,\s*)', r'\1\n\2'),           # "ë³´ì£  ë„¤," â†’ "ë³´ì£ \në„¤,"
    (r'(\S)\s+(ì˜ˆ,\s*)', r'\1\n\2'),           # "ë³´ì£  ì˜ˆ," â†’ "ë³´ì£ \nì˜ˆ,"
    (r'(\S)\s+(ë„¤\s+)', r'\1\n\2'),            # "ë³´ì£  ë„¤ " â†’ "ë³´ì£ \në„¤ "
    (r'(\S)\s+(ì˜ˆ\s+)', r'\1\n\2'),            # "ë³´ì£  ì˜ˆ " â†’ "ë³´ì£ \nì˜ˆ "
    (r'(\S)\s+(ì•„ë‹ˆìš”,?\s*)', r'\1\n\2'),      # "ë³´ì£  ì•„ë‹ˆìš”" â†’ "ë³´ì£ \nì•„ë‹ˆìš”"
    (r'(\S)\s+(ì•„ë‡¨,?\s*)', r'\1\n\2'),        # "ë³´ì£  ì•„ë‡¨" â†’ "ë³´ì£ \nì•„ë‡¨"
    
    # ì§ˆë¬¸ í›„ ì‘ë‹µ (ë¬¼ìŒí‘œ ë’¤)
    (r'(\?)\s*([ê°€-í£])', r'\1\n\2'),          # "ë­¡ë‹ˆê¹Œ? ë„¤" â†’ "ë­¡ë‹ˆê¹Œ?\në„¤"
    
    # ê°ì‚¬/ì¸ì‚¬ ì‹œì‘
    (r'(\S)\s+(ê°ì‚¬í•©ë‹ˆë‹¤)', r'\1\n\2'),       # "ë³´ì£  ê°ì‚¬í•©ë‹ˆë‹¤" â†’ "ë³´ì£ \nê°ì‚¬í•©ë‹ˆë‹¤"
    (r'(\S)\s+(ì•Œê² ìŠµë‹ˆë‹¤)', r'\1\n\2'),       # "ë³´ì£  ì•Œê² ìŠµë‹ˆë‹¤" â†’ "ë³´ì£ \nì•Œê² ìŠµë‹ˆë‹¤"
    (r'(\S)\s+(ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤)', r'\1\n\2'), # "ë³´ì£  ë§ì”€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
    (r'(\S)\s+(ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤)', r'\1\n\2'), # "ë³´ì£  ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
    
    # êµ­íšŒ/êµ­ë¬´íšŒì˜ íŠ¹í™” - ë°œì–¸ê¶Œ ì „í™˜
    (r'(\S)\s+(ìœ„ì›ì¥ë‹˜)', r'\1\n\2'),         # "ë³´ì£  ìœ„ì›ì¥ë‹˜"
    (r'(\S)\s+(ì˜ì›ë‹˜)', r'\1\n\2'),           # "ë³´ì£  ì˜ì›ë‹˜"
    (r'(\S)\s+(ì´ë¦¬ë‹˜)', r'\1\n\2'),           # "ë³´ì£  ì´ë¦¬ë‹˜"
    (r'(\S)\s+(ì¥ê´€ë‹˜)', r'\1\n\2'),           # "ë³´ì£  ì¥ê´€ë‹˜"
    (r'(\S)\s+(ì¡´ê²½í•˜ëŠ”)', r'\1\n\2'),         # "ë³´ì£  ì¡´ê²½í•˜ëŠ”"
    
    # ë§ì”€ ì „í™˜
    (r'(ì…ë‹ˆë‹¤)\s+(ê·¸ë¦¬ê³ )', r'\1\n\2'),       # "ì…ë‹ˆë‹¤ ê·¸ë¦¬ê³ " â†’ "ì…ë‹ˆë‹¤\nê·¸ë¦¬ê³ "
    (r'(ìŠµë‹ˆë‹¤)\s+(ê·¸ëŸ°ë°)', r'\1\n\2'),       # "ìŠµë‹ˆë‹¤ ê·¸ëŸ°ë°" â†’ "ìŠµë‹ˆë‹¤\nê·¸ëŸ°ë°"
    (r'(í•©ë‹ˆë‹¤)\s+(ë‹¤ìŒìœ¼ë¡œ)', r'\1\n\2'),     # "í•©ë‹ˆë‹¤ ë‹¤ìŒìœ¼ë¡œ" â†’ "í•©ë‹ˆë‹¤\në‹¤ìŒìœ¼ë¡œ"
]

COMPILED_SPEAKER_CHANGE_PATTERNS = [
    (re.compile(pattern), replacement) 
    for pattern, replacement in SPEAKER_CHANGE_RESPONSE_PATTERNS
]


def detect_and_insert_speaker_breaks(text: str) -> str:
    """
    [advice from AI] ì„¸ê·¸ë¨¼íŠ¸ ë‚´ í™”ì ë³€ê²½ ì¶”ì • ë° ì¤„ë°”ê¿ˆ ì‚½ì…
    
    êµ­íšŒ/êµ­ë¬´íšŒì˜ íŠ¹ì„±ìƒ ì‘ë‹µ ì‹œì‘ íŒ¨í„´("ë„¤,", "ì˜ˆ,", "ì•Œê² ìŠµë‹ˆë‹¤" ë“±)ì„ 
    ê°ì§€í•˜ì—¬ í™”ì ë³€ê²½ìœ¼ë¡œ ì¶”ì •í•˜ê³  ì¤„ë°”ê¿ˆ ì‚½ì…
    
    Args:
        text: ì…ë ¥ í…ìŠ¤íŠ¸
    
    Returns:
        í™”ì ë³€ê²½ ìœ„ì¹˜ì— ì¤„ë°”ê¿ˆì´ ì‚½ì…ëœ í…ìŠ¤íŠ¸
    """
    if not text or len(text) < 5:
        return text
    
    result = text
    
    for pattern, replacement in COMPILED_SPEAKER_CHANGE_PATTERNS:
        result = pattern.sub(replacement, result)
    
    # ì—°ì† ì¤„ë°”ê¿ˆ ì •ë¦¬
    result = re.sub(r'\n+', '\n', result)
    
    # ì¤„ë°”ê¿ˆ ì•ë’¤ ê³µë°± ì •ë¦¬
    result = re.sub(r'\s*\n\s*', '\n', result)
    
    if result != text:
        logger.debug(f"[í™”ìë³€ê²½ì¶”ì •] '{text[:50]}...' â†’ '{result[:50]}...'")
    
    return result


# =============================================================================
# [advice from AI] ìë§‰ ìµœì í™” - ê¸´ ë¬¸ì¥ ë¶„ë¦¬
# =============================================================================

# ìë§‰ ë¶„ë¦¬ ê¸°ì¤€ì  (ìš°ì„ ìˆœìœ„ ìˆœ)
SUBTITLE_BREAK_PATTERNS = [
    # 1. ë¬¸ì¥ ì¢…ê²°
    (r'([.?!ã€‚ï¼Ÿï¼])\s*', r'\1\n'),
    # 2. ì‰¼í‘œ + ì ‘ì†ì‚¬/ë¶€ì‚¬
    (r',\s*(ê·¸ë¦¬ê³ |ê·¸ëŸ°ë°|ê·¸ëŸ¬ë‚˜|í•˜ì§€ë§Œ|ë˜í•œ|ê·¸ë˜ì„œ|ë”°ë¼ì„œ|ê·¸ëŸ¬ë©´|ê·¸ëŸ¬ë¯€ë¡œ)\s*', r',\n\1 '),
    # 3. ì ‘ì†ì‚¬ ì•
    (r'\s+(ê·¸ë¦¬ê³ |ê·¸ëŸ°ë°|ê·¸ëŸ¬ë‚˜|í•˜ì§€ë§Œ|ë˜í•œ|ê·¸ë˜ì„œ|ë”°ë¼ì„œ|ê·¸ëŸ¬ë©´|ê·¸ëŸ¬ë¯€ë¡œ)\s+', r'\n\1 '),
    # 4. "ë„¤," "ì˜ˆ," ë“± ì‘ë‹µ í›„
    (r'(ë„¤,|ì˜ˆ,|ì•„ë‹ˆìš”,|ì•„ë‡¨,)\s*', r'\1\n'),
]


def split_for_subtitle(
    text: str,
    max_length: int = 40,
    min_length: int = 10,
) -> List[str]:
    """
    [advice from AI] ìë§‰ìš© ë¬¸ì¥ ë¶„ë¦¬
    
    ê¸´ ë¬¸ì¥ì„ ìë§‰ì— ì í•©í•œ ê¸¸ì´ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        max_length: ìµœëŒ€ ìë§‰ ê¸¸ì´ (ê¸°ë³¸ 40ì)
        min_length: ìµœì†Œ ìë§‰ ê¸¸ì´ (ê¸°ë³¸ 10ì)
    
    Returns:
        ë¶„ë¦¬ëœ ìë§‰ ë¦¬ìŠ¤íŠ¸
    
    Example:
        ì…ë ¥: "ì œ2íšŒëŠ” ë§¤ë…„ íšŸìˆ˜ë¥¼ ë¶™ì´ëŠ”ê°€ ë³´ì£  ë„¤, ë§¤ë…„ 1íšŒë¶€í„° íšŸìˆ˜ë¥¼ ë¶™ì…ë‹ˆë‹¤ ë„¤, ì œ2íšŒ êµ­ë¬´íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤"
        ì¶œë ¥: [
            "ì œ2íšŒëŠ” ë§¤ë…„ íšŸìˆ˜ë¥¼ ë¶™ì´ëŠ”ê°€ ë³´ì£ ",
            "ë„¤, ë§¤ë…„ 1íšŒë¶€í„° íšŸìˆ˜ë¥¼ ë¶™ì…ë‹ˆë‹¤",
            "ë„¤, ì œ2íšŒ êµ­ë¬´íšŒì˜ë¥¼ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤"
        ]
    """
    if not text:
        return []
    
    text = text.strip()
    
    # ì´ë¯¸ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if len(text) <= max_length:
        return [text]
    
    lines = []
    remaining = text
    
    while remaining:
        remaining = remaining.strip()
        
        if not remaining:
            break
        
        # ì´ë¯¸ ì§§ìœ¼ë©´ ì¶”ê°€í•˜ê³  ì¢…ë£Œ
        if len(remaining) <= max_length:
            lines.append(remaining)
            break
        
        # ìµœì  ë¶„ë¦¬ì  ì°¾ê¸°
        best_split = -1
        
        # 1. max_length ì´ë‚´ì—ì„œ ë¶„ë¦¬ì  ì°¾ê¸°
        search_text = remaining[:max_length + 20]  # ì•½ê°„ ì—¬ìœ  ìˆê²Œ íƒìƒ‰
        
        # ìš°ì„ ìˆœìœ„ 1: ë¬¸ì¥ ë¶€í˜¸ (. ? !)
        for punct in ['. ', '? ', '! ', 'ã€‚', 'ï¼Ÿ', 'ï¼']:
            idx = search_text.rfind(punct)
            if idx > min_length and idx <= max_length:
                best_split = idx + len(punct)
                break
        
        # ìš°ì„ ìˆœìœ„ 2: "ë„¤," "ì˜ˆ," ë“± ì‘ë‹µ í›„
        if best_split == -1:
            for marker in ['ë„¤, ', 'ì˜ˆ, ', 'ë„¤,', 'ì˜ˆ,']:
                idx = search_text.find(marker, min_length)
                if idx > 0 and idx <= max_length:
                    best_split = idx + len(marker)
                    break
        
        # ìš°ì„ ìˆœìœ„ 3: ì ‘ì†ì‚¬ ì•
        if best_split == -1:
            for conj in [' ê·¸ë¦¬ê³  ', ' ê·¸ëŸ°ë° ', ' ê·¸ëŸ¬ë‚˜ ', ' í•˜ì§€ë§Œ ', ' ë˜í•œ ', ' ê·¸ë˜ì„œ ']:
                idx = search_text.find(conj, min_length)
                if idx > 0 and idx <= max_length:
                    best_split = idx
                    break
        
        # ìš°ì„ ìˆœìœ„ 4: ì‰¼í‘œ ë’¤
        if best_split == -1:
            idx = search_text.rfind(', ', min_length, max_length)
            if idx > 0:
                best_split = idx + 2
        
        # ìš°ì„ ìˆœìœ„ 5: ê³µë°±ì—ì„œ ìë¥´ê¸° (ìµœí›„ì˜ ìˆ˜ë‹¨)
        if best_split == -1:
            idx = search_text.rfind(' ', min_length, max_length)
            if idx > 0:
                best_split = idx + 1
        
        # ë¶„ë¦¬ì ì„ ì°¾ì§€ ëª»í•˜ë©´ ê°•ì œë¡œ ìë¥´ê¸°
        if best_split == -1:
            best_split = max_length
        
        # ë¶„ë¦¬
        line = remaining[:best_split].strip()
        remaining = remaining[best_split:].strip()
        
        if line:
            lines.append(line)
    
    # ë„ˆë¬´ ì§§ì€ ì¤„ì€ ì´ì „ ì¤„ê³¼ í•©ì¹˜ê¸°
    merged = []
    for line in lines:
        if merged and len(line) < min_length and len(merged[-1]) + len(line) + 1 <= max_length:
            merged[-1] = merged[-1] + ' ' + line
        else:
            merged.append(line)
    
    return merged


def format_subtitle_text(text: str, max_length: int = 40) -> str:
    """
    [advice from AI] ìë§‰ í¬ë§·íŒ… (ì¤„ë°”ê¿ˆ í¬í•¨)
    
    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸
        max_length: ìµœëŒ€ ìë§‰ ê¸¸ì´
    
    Returns:
        ì¤„ë°”ê¿ˆì´ í¬í•¨ëœ ìë§‰ í…ìŠ¤íŠ¸
    """
    lines = split_for_subtitle(text, max_length)
    return '\n'.join(lines)
