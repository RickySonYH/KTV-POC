# [advice from AI] pyannote.audio ì‹¤ì‹œê°„ í™”ìë¶„ë¦¬ WebSocket ì„œë¹„ìŠ¤
# WhisperLiveKitê³¼ ë³„ë„ë¡œ ë™ì‘, PCM ì˜¤ë””ì˜¤ë¥¼ ë°›ì•„ í™”ì ë²ˆí˜¸ë§Œ ë°˜í™˜

import asyncio
import logging
import os
import re
import threading
from typing import Optional

import numpy as np
import torch
# [advice from AI] PyTorch 2.6+: weights_only=True ê¸°ë³¸ê°’ â†’ pyannote í˜¸í™˜ì„ ìœ„í•´ ì „ì—­ íŒ¨ì¹˜
_original_torch_load = torch.load
def _patched_torch_load(*args, **kwargs):
    kwargs['weights_only'] = False
    return _original_torch_load(*args, **kwargs)
torch.load = _patched_torch_load
# lightning_fabricë„ íŒ¨ì¹˜
try:
    import lightning_fabric.utilities.cloud_io as _lio
    _lio_original = _lio.torch.load
    _lio.torch.load = _patched_torch_load
except Exception:
    pass

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="pyannote Speaker Diarization Service")

# [advice from AI] HuggingFace í† í°
HF_TOKEN = os.environ.get("HF_TOKEN", "")

# [advice from AI] ê¸€ë¡œë²Œ íŒŒì´í”„ë¼ì¸ (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ ë¡œë“œ)
pipeline = None
SAMPLE_RATE = 16000


def load_pipeline():
    """pyannote.audio íŒŒì´í”„ë¼ì¸ ë¡œë“œ - ì—¬ëŸ¬ ì¸ì¦ ë°©ì‹ ì‹œë„"""
    global pipeline
    from pyannote.audio import Pipeline
    
    logger.info("[DIAR] pyannote.audio íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘...")
    
    # [advice from AI] huggingface_hub ë²„ì „ë³„ í˜¸í™˜: ì—¬ëŸ¬ ë°©ì‹ ì‹œë„
    for method in ['token', 'use_auth_token', 'env']:
        try:
            if method == 'token':
                pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", token=HF_TOKEN)
            elif method == 'use_auth_token':
                pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1", use_auth_token=HF_TOKEN)
            else:
                import os as _os
                _os.environ["HF_TOKEN"] = HF_TOKEN
                _os.environ["HUGGING_FACE_HUB_TOKEN"] = HF_TOKEN
                pipeline = Pipeline.from_pretrained("pyannote/speaker-diarization-3.1")
            
            device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
            pipeline.to(device)
            logger.info(f"[DIAR] âœ… íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì™„ë£Œ (method={method}, device={device})")
            return
        except TypeError as e:
            logger.warning(f"[DIAR] method={method} ì‹¤íŒ¨: {e}, ë‹¤ìŒ ì‹œë„...")
            continue
        except Exception as e:
            logger.error(f"[DIAR] âŒ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            pipeline = None
            return
    
    logger.error("[DIAR] âŒ ëª¨ë“  ì¸ì¦ ë°©ì‹ ì‹¤íŒ¨")
    pipeline = None


@app.on_event("startup")
async def startup():
    load_pipeline()


@app.get("/health")
async def health():
    return JSONResponse({
        "status": "ok" if pipeline else "no_model",
        "model": "pyannote/speaker-diarization-3.1",
        "gpu": torch.cuda.is_available()
    })


class StreamingDiarizer:
    """[advice from AI] ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í™”ìë¶„ë¦¬ - ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹"""
    
    def __init__(self, sample_rate: int = 16000, window_sec: float = 5.0, step_sec: float = 1.0):
        self.sample_rate = sample_rate
        self.window_sec = window_sec      # ë¶„ì„ ìœˆë„ìš° (5ì´ˆ)
        self.step_sec = step_sec          # ë¶„ì„ ì£¼ê¸° (1ì´ˆë§ˆë‹¤)
        self.step_size = int(step_sec * sample_rate)
        self.window_size = int(window_sec * sample_rate)
        self.all_audio = np.array([], dtype=np.float32)
        self.buffer_since_last = np.array([], dtype=np.float32)
        self.current_speaker = -1
        self.lock = threading.Lock()
    
    def add_audio(self, pcm_data: np.ndarray):
        with self.lock:
            self.all_audio = np.concatenate([self.all_audio, pcm_data])
            self.buffer_since_last = np.concatenate([self.buffer_since_last, pcm_data])
    
    async def process(self) -> Optional[int]:
        """[advice from AI] step_size ì´ìƒ ìŒ“ì´ë©´ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ í™”ìë¶„ë¦¬"""
        if pipeline is None:
            return None
        
        with self.lock:
            if len(self.buffer_since_last) < self.step_size:
                return None
            
            # ìµœê·¼ window_sec ë¶„ëŸ‰ë§Œ ë¶„ì„
            audio = self.all_audio[-self.window_size:] if len(self.all_audio) > self.window_size else self.all_audio
            self.buffer_since_last = np.array([], dtype=np.float32)
        
        if len(audio) < self.sample_rate:  # ìµœì†Œ 1ì´ˆ
            return None
        
        try:
            waveform = torch.tensor(audio, dtype=torch.float32).unsqueeze(0)
            audio_input = {"waveform": waveform, "sample_rate": self.sample_rate}
            
            # [advice from AI] pyannote í™”ìë¶„ë¦¬ ì‹¤í–‰
            diarization = pipeline(audio_input)
            
            # ë§ˆì§€ë§‰ í™”ì ì¶”ì¶œ (ê°€ì¥ ìµœê·¼ ë°œí™”ì)
            last_speaker = -1
            last_end = 0.0
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                if turn.end >= last_end:
                    last_end = turn.end
                    match = re.search(r'(\d+)', speaker)
                    if match:
                        last_speaker = int(match.group())
            
            if last_speaker >= 0 and last_speaker != self.current_speaker:
                old = self.current_speaker
                self.current_speaker = last_speaker
                logger.info(f"[DIAR] ğŸ”„ í™”ì ë³€ê²½: {old} â†’ {last_speaker}")
                return last_speaker
            
            return None
            
        except Exception as e:
            logger.warning(f"[DIAR] ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None


@app.websocket("/diarize")
async def websocket_diarize(websocket: WebSocket):
    """[advice from AI] PCM ì˜¤ë””ì˜¤ë¥¼ ë°›ì•„ ì‹¤ì‹œê°„ í™”ì ë²ˆí˜¸ ë°˜í™˜"""
    await websocket.accept()
    logger.info("[DIAR] WebSocket ì—°ê²°ë¨")
    
    diarizer = StreamingDiarizer(window_sec=5.0, step_sec=1.0)
    running = True
    
    async def process_loop():
        while running:
            try:
                result = await diarizer.process()
                if result is not None:
                    await websocket.send_json({
                        "type": "speaker_change",
                        "speaker": result
                    })
                    logger.info(f"[DIAR] ğŸ“¤ í™”ì ë³€ê²½ ì „ì†¡: {result}")
                await asyncio.sleep(0.3)
            except Exception:
                break
    
    process_task = asyncio.create_task(process_loop())
    
    try:
        while True:
            data = await websocket.receive_bytes()
            pcm_int16 = np.frombuffer(data, dtype=np.int16)
            pcm_float = pcm_int16.astype(np.float32) / 32768.0
            diarizer.add_audio(pcm_float)
    except WebSocketDisconnect:
        logger.info("[DIAR] WebSocket ì—°ê²° í•´ì œ")
    except Exception as e:
        logger.error(f"[DIAR] WebSocket ì˜¤ë¥˜: {e}")
    finally:
        running = False
        process_task.cancel()
