# KTV-POC 자막 시스템 개선안

> **작성일**: 2026-02-05  
> **버전**: v1.1  
> **목적**: 실시간 자막과 자막 파일 생성의 역할 분리를 통한 시스템 최적화

---

## 1. 개요

### 1.1 현재 문제점

- 실시간 자막과 자막 목록 생성이 동일한 소스를 사용하여 동기화 문제 발생
- 긴 문장 처리 시 자막 표시 시간 조정 미흡
- 졸업(graduation) 로직의 복잡성으로 인한 텍스트 누락/중복 이슈

### 1.2 개선 방향

**역할 분리 원칙**: 실시간 피드백과 정확한 자막 생성을 독립적으로 운영

| 구분 | 소스 | 목적 | 특징 |
|------|------|------|------|
| **실시간 자막 (화면)** | WhisperLiveKit | 사용자가 "말을 놓치지 않게" | 빠른 응답, UX 중심 |
| **자막 목록 & 파일** | FastWhisper | 정확한 타임스탬프 + 텍스트 | 자막 파일(.srt) 생성 기반 |

---

## 2. 시스템 아키텍처

### 2.1 전체 흐름도

```
                    ┌─────────────────┐
                    │   오디오 입력    │
                    └────────┬────────┘
                             │
              ┌──────────────┴──────────────┐
              ▼                              ▼
    ┌─────────────────┐            ┌─────────────────┐
    │  WhisperLiveKit │            │   FastWhisper   │
    │   (실시간 버퍼)  │            │  (최종 확정)    │
    └────────┬────────┘            └────────┬────────┘
             │                              │
             ▼                              ▼
    ┌─────────────────┐            ┌─────────────────┐
    │  실시간 자막     │            │   자막 처리기    │
    │  (화면 2줄)     │            │ (긴 문장 분할)  │
    └─────────────────┘            └────────┬────────┘
                                            │
                                            ▼
                                   ┌─────────────────┐
                                   │   자막 목록      │
                                   │ (타임스탬프 정렬)│
                                   └────────┬────────┘
                                            │
                                            ▼
                                   ┌─────────────────┐
                                   │  자막 파일 생성   │
                                   │  (.SRT / .VTT)  │
                                   └─────────────────┘
```

### 2.2 데이터 흐름

1. **오디오 입력** → 두 개의 STT 엔진으로 동시 전달
2. **WhisperLiveKit** → 실시간 버퍼 텍스트 → 화면 자막 표시
3. **FastWhisper** → 확정 문장 + 타임스탬프 → 자막 목록 → SRT/VTT 파일

---

## 3. 실시간 자막 (WhisperLiveKit 기반)

### 3.1 목적

- 화면에서 **"말하는 내용을 실시간으로 따라가는 느낌"** 제공
- 사용자가 현재 진행 중인 대화를 놓치지 않도록 함

### 3.2 화면 구성

```
┌─────────────────────────────────────────────┐
│  [상단 줄] 이전에 말한 내용...               │  ← 버퍼에서 밀려난 텍스트
│  [하단 줄] 지금 말하고 있는 내용...          │  ← 현재 버퍼 텍스트
└─────────────────────────────────────────────┘
```

### 3.3 구현 방식

- WhisperLiveKit JSON 응답의 `buffer` + `line` 활용
- 2줄 표시로 자연스러운 흐름 유지
- **핵심 원칙**: "대략 맞으면 OK" - 말을 놓치지 않는 것이 최우선

### 3.4 처리 로직

```typescript
// WhisperLiveKit 응답 처리
interface WhisperLiveKitResponse {
  buffer: string;      // 현재 처리 중인 텍스트
  line: string;        // 이전 확정 라인
  speaker?: string;    // 화자 정보
}

// 화면 표시 상태
interface RealtimeSubtitleState {
  topLine: string;     // 상단 줄 (이전 텍스트)
  bottomLine: string;  // 하단 줄 (현재 버퍼)
}
```

---

## 4. 자막 목록 (FastWhisper 기반)

### 4.1 목적

- **정확한 타임스탬프**와 **확정된 텍스트**로 자막 파일 생성 기반 마련
- 회의 기록, 검색, 요약 등 후처리 기능의 데이터 소스

### 4.2 화면 구성

```
┌─────────────────────────────────────────────────────────────┐
│ 자막 목록                                                    │
├─────────────────────────────────────────────────────────────┤
│ 00:00:05 ~ 00:00:08  [화자1] 안녕하세요, 오늘 회의를 시작... │
│ 00:00:09 ~ 00:00:15  [화자2] 네, 먼저 지난 주 진행 상황부... │
│ 00:00:16 ~ 00:00:25  [화자1] 지난 주에는 프론트엔드 개발이... │
│ ...                                                          │
└─────────────────────────────────────────────────────────────┘
```

### 4.3 데이터 구조

```typescript
interface SubtitleSegment {
  id: string;          // 고유 ID
  start: number;       // 시작 시간 (초)
  end: number;         // 종료 시간 (초)
  text: string;        // 자막 텍스트
  speaker?: string;    // 화자 정보
  speakerColor?: string; // 화자별 색상
}

interface SubtitleList {
  segments: SubtitleSegment[];
  totalDuration: number;
  speakerCount: number;
}
```

---

## 5. 긴 문장 분할 처리

### 5.1 문제 상황

회의 특성상 한 문장이 매우 길게 나올 수 있음 → 자막으로 부적합

**예시**:
```
FastWhisper 결과:
00:00:05 ~ 00:00:45 "그래서 저희가 이번 프로젝트에서 고려해야 할 점은 
첫째로 시스템 안정성이고 둘째로는 사용자 경험이며 셋째로는 확장성인데 
이 세 가지를 모두 만족시키려면 아키텍처 설계부터 다시 검토해야 할 것 같습니다"
```

40초짜리 자막 1개 → **화면에 너무 오래 표시되어 가독성 저하**

### 5.2 분할 설정

```typescript
const SUBTITLE_CONFIG = {
  maxDuration: 8,        // 자막 1개당 최대 8초
  maxCharsPerLine: 40,   // 한 줄 최대 40자 (한글 기준)
  maxLinesPerSubtitle: 2 // 자막당 최대 2줄
};
```

### 5.3 분할 기준

1. **문장 부호 기준**
   - 마침표(.), 물음표(?), 느낌표(!)
   - 쉼표(,) 위치
   - 접속사: "그리고", "그래서", "하지만", "그런데", "따라서" 등

2. **시간 균등 분배**
   - 전체 음성 길이를 텍스트 비율로 나눔
   - 단어 단위로 시간 배분

3. **화자 변경**
   - 화자가 바뀌면 무조건 새 자막 시작

### 5.4 분할 결과 예시

**입력**:
```
00:00:05 ~ 00:00:45 "그래서 저희가 이번 프로젝트에서 고려해야 할 점은 
첫째로 시스템 안정성이고 둘째로는 사용자 경험이며 셋째로는 확장성인데 
이 세 가지를 모두 만족시키려면 아키텍처 설계부터 다시 검토해야 할 것 같습니다"
```

**출력**:
```
00:00:05 ~ 00:00:13  그래서 저희가 이번 프로젝트에서
                    고려해야 할 점은 첫째로 시스템 안정성이고

00:00:13 ~ 00:00:21  둘째로는 사용자 경험이며
                    셋째로는 확장성인데

00:00:21 ~ 00:00:29  이 세 가지를 모두 만족시키려면
                    아키텍처 설계부터 다시 검토해야 할 것 같습니다
```

### 5.5 분할 알고리즘

```typescript
function splitLongSubtitle(segment: SubtitleSegment): SubtitleSegment[] {
  const { start, end, text, speaker } = segment;
  const duration = end - start;
  
  // 분할 필요 없는 경우
  if (duration <= SUBTITLE_CONFIG.maxDuration && 
      text.length <= SUBTITLE_CONFIG.maxCharsPerLine * SUBTITLE_CONFIG.maxLinesPerSubtitle) {
    return [segment];
  }
  
  // 분할 지점 찾기
  const splitPoints = findSplitPoints(text);
  const segments: SubtitleSegment[] = [];
  
  // 시간 비례 배분하여 분할
  let currentStart = start;
  for (let i = 0; i < splitPoints.length; i++) {
    const textPortion = splitPoints[i];
    const portionRatio = textPortion.length / text.length;
    const portionDuration = duration * portionRatio;
    
    segments.push({
      id: `${segment.id}-${i}`,
      start: currentStart,
      end: currentStart + portionDuration,
      text: textPortion.trim(),
      speaker
    });
    
    currentStart += portionDuration;
  }
  
  return segments;
}
```

---

## 6. 자막 파일 생성 (SRT & VTT)

### 6.1 지원 포맷 비교

| 구분 | SRT | VTT (WebVTT) |
|------|-----|--------------|
| **확장자** | `.srt` | `.vtt` |
| **헤더** | 없음 | `WEBVTT` 필수 |
| **시간 구분자** | 쉼표 (`,`) | 마침표 (`.`) |
| **스타일링** | 미지원 | CSS 스타일 지원 |
| **용도** | 범용 (동영상 플레이어) | 웹 (HTML5 video) |

### 6.2 SRT 포맷

```
1
00:00:05,000 --> 00:00:08,500
[화자1] 안녕하세요, 오늘 회의를 시작하겠습니다.

2
00:00:09,200 --> 00:00:15,800
[화자2] 네, 먼저 지난 주 진행 상황부터
보고드리겠습니다.

3
00:00:16,100 --> 00:00:25,300
[화자1] 지난 주에는 프론트엔드 개발이
주요 이슈였습니다.
```

### 6.3 VTT (WebVTT) 포맷

```
WEBVTT

1
00:00:05.000 --> 00:00:08.500
<v 화자1>안녕하세요, 오늘 회의를 시작하겠습니다.

2
00:00:09.200 --> 00:00:15.800
<v 화자2>네, 먼저 지난 주 진행 상황부터
보고드리겠습니다.

3
00:00:16.100 --> 00:00:25.300
<v 화자1>지난 주에는 프론트엔드 개발이
주요 이슈였습니다.
```

### 6.4 VTT 스타일링 옵션 (선택적)

```
WEBVTT

STYLE
::cue(v[voice="화자1"]) { color: #4A90D9; }
::cue(v[voice="화자2"]) { color: #D94A4A; }

1
00:00:05.000 --> 00:00:08.500 align:start position:10%
<v 화자1>안녕하세요, 오늘 회의를 시작하겠습니다.
```

### 6.5 변환 함수

```typescript
// ===== SRT 생성 =====
function generateSRT(subtitles: SubtitleSegment[]): string {
  return subtitles.map((segment, index) => {
    const startTime = formatSRTTime(segment.start);
    const endTime = formatSRTTime(segment.end);
    const speakerPrefix = segment.speaker ? `[${segment.speaker}] ` : '';
    
    return `${index + 1}\n${startTime} --> ${endTime}\n${speakerPrefix}${segment.text}\n`;
  }).join('\n');
}

function formatSRTTime(seconds: number): string {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const millis = Math.floor((seconds % 1) * 1000);
  
  return `${pad(hours)}:${pad(minutes)}:${pad(secs)},${pad(millis, 3)}`;
}

// ===== VTT 생성 =====
function generateVTT(subtitles: SubtitleSegment[], includeStyle: boolean = false): string {
  let vtt = 'WEBVTT\n\n';
  
  // 스타일 블록 추가 (선택적)
  if (includeStyle) {
    const speakers = [...new Set(subtitles.map(s => s.speaker).filter(Boolean))];
    vtt += 'STYLE\n';
    speakers.forEach((speaker, index) => {
      const color = SPEAKER_COLORS[index % SPEAKER_COLORS.length];
      vtt += `::cue(v[voice="${speaker}"]) { color: ${color}; }\n`;
    });
    vtt += '\n';
  }
  
  // 자막 큐 추가
  vtt += subtitles.map((segment, index) => {
    const startTime = formatVTTTime(segment.start);
    const endTime = formatVTTTime(segment.end);
    const speakerTag = segment.speaker ? `<v ${segment.speaker}>` : '';
    
    return `${index + 1}\n${startTime} --> ${endTime}\n${speakerTag}${segment.text}\n`;
  }).join('\n');
  
  return vtt;
}

function formatVTTTime(seconds: number): string {
  const hours = Math.floor(seconds / 3600);
  const minutes = Math.floor((seconds % 3600) / 60);
  const secs = Math.floor(seconds % 60);
  const millis = Math.floor((seconds % 1) * 1000);
  
  return `${pad(hours)}:${pad(minutes)}:${pad(secs)}.${pad(millis, 3)}`;  // 마침표(.) 사용
}

// 공통 유틸
function pad(num: number, size: number = 2): string {
  return num.toString().padStart(size, '0');
}

const SPEAKER_COLORS = ['#4A90D9', '#D94A4A', '#4AD94A', '#D9D94A', '#9A4AD9'];
```

### 6.6 내보내기 UI

```typescript
interface ExportOptions {
  format: 'srt' | 'vtt';
  includeStyle: boolean;     // VTT 전용: CSS 스타일 포함 여부
  includeSpeaker: boolean;   // 화자 정보 포함 여부
}

// 다운로드 함수
function downloadSubtitle(subtitles: SubtitleSegment[], options: ExportOptions): void {
  const content = options.format === 'srt' 
    ? generateSRT(subtitles) 
    : generateVTT(subtitles, options.includeStyle);
  
  const blob = new Blob([content], { type: 'text/plain;charset=utf-8' });
  const filename = `subtitles_${Date.now()}.${options.format}`;
  
  // 다운로드 트리거
  const link = document.createElement('a');
  link.href = URL.createObjectURL(blob);
  link.download = filename;
  link.click();
}
```

---

## 7. 구현 계획

### 7.1 단계별 작업

| 단계 | 작업 | 설명 | 예상 소요 |
|------|------|------|----------|
| **1단계** | 실시간 자막 안정화 | WhisperLiveKit 기반 2줄 표시 로직 정리 | 1일 |
| **2단계** | FastWhisper 자막 목록 구현 | 타임스탬프 + 텍스트 누적 저장 | 1일 |
| **3단계** | 긴 문장 분할 로직 | 자막화에 적합한 길이로 분할 | 2일 |
| **4단계** | 화자별 스타일 적용 | 색상 구분 등 UI 개선 | 0.5일 |
| **5단계** | 자막 파일 내보내기 | 자막 목록 → SRT/VTT 변환 | 0.5일 |

### 7.2 파일 구조 (예상)

```
frontend/src/
├── components/
│   ├── RealtimeSubtitle.tsx      # 실시간 자막 컴포넌트 (WhisperLiveKit)
│   ├── SubtitleList.tsx          # 자막 목록 컴포넌트 (FastWhisper)
│   └── SubtitleExport.tsx        # SRT 내보내기 버튼
├── hooks/
│   ├── useRealtimeSubtitle.ts    # 실시간 자막 처리 훅
│   ├── useSubtitleList.ts        # 자막 목록 관리 훅
│   └── useSubtitleSplit.ts       # 긴 문장 분할 훅
├── utils/
│   ├── subtitleSplitter.ts       # 분할 알고리즘
│   ├── srtGenerator.ts           # SRT 생성기
│   ├── vttGenerator.ts           # VTT (WebVTT) 생성기
│   └── timeFormatter.ts          # 시간 포맷 유틸
└── types/
    └── subtitle.ts               # 자막 관련 타입 정의
```

---

## 8. 기대 효과

### 8.1 기술적 장점

1. **역할 분리 명확**: 실시간 피드백 ↔ 정확한 자막 생성이 독립적으로 동작
2. **복잡한 동기화 불필요**: 두 시스템이 서로 간섭하지 않음
3. **회의 특성 대응**: 긴 문장 분할로 실용적인 자막 생성 가능
4. **확장성**: 요약, 검색, 번역 등 추가 기능 연동 용이

### 8.2 사용자 경험 개선

- 실시간 자막으로 **"말이 빠지는 느낌"** 해소
- 정확한 타임스탬프로 **원하는 시점 검색** 용이
- 적절한 길이의 자막으로 **가독성 향상**

---

## 9. 참고 사항

### 9.1 WhisperLiveKit JSON 응답 예시

```json
{
  "type": "transcription",
  "buffer": "현재 말하고 있는 내용입니다",
  "line": "이전에 확정된 문장입니다",
  "speaker": "화자1",
  "timestamp": 12.5
}
```

### 9.2 FastWhisper 응답 예시

```json
{
  "segments": [
    {
      "start": 5.2,
      "end": 8.7,
      "text": "안녕하세요, 오늘 회의를 시작하겠습니다.",
      "speaker": "화자1"
    }
  ]
}
```

---

## 10. 변경 이력

| 버전 | 날짜 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| v1.0 | 2026-02-05 | 최초 작성 | AI Assistant |
| v1.1 | 2026-02-05 | VTT (WebVTT) 포맷 지원 추가 | AI Assistant |

---

> **문서 끝**
