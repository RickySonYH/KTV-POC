// [advice from AI] ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ + WhisperLiveKit ì‹¤ì‹œê°„ STT
// getDisplayMediaë¡œ ì‹œìŠ¤í…œ ìŠ¤í…Œë ˆì˜¤ ì¶œë ¥ì„ ìº¡ì²˜í•˜ì—¬ ì‹¤ì‹œê°„ ìë§‰ ìƒì„±

import { useState, useRef, useCallback, useEffect } from 'react';

export interface SystemAudioSubtitle {
  id: number;
  text: string;
  speaker?: string;
  startTime: number;
  endTime: number;
  isFinal: boolean;
}

// [advice from AI] ì‹¤ì‹œê°„ ë²„í¼ ì—…ë°ì´íŠ¸ (ì¤‘ê°„ ê²°ê³¼)
export interface BufferUpdate {
  text: string;
  speaker?: string;
}

interface UseSystemAudioSTTProps {
  onSubtitle: (subtitle: SystemAudioSubtitle) => void;
  onBufferUpdate?: (buffer: BufferUpdate) => void;  // ì‹¤ì‹œê°„ ì¤‘ê°„ ê²°ê³¼
  onStatusChange?: (status: 'idle' | 'connecting' | 'capturing' | 'error') => void;
  wsUrl?: string;
}

// [advice from AI] ë™ì  WebSocket URL ìƒì„± - HTTPS/nginx í”„ë¡ì‹œ ì§€ì›
const getWsUrl = () => {
  // HTTPSë¡œ ì ‘ì† ì‹œ wss:// + nginx í”„ë¡ì‹œ ê²½ë¡œ ì‚¬ìš©
  if (window.location.protocol === 'https:') {
    return `wss://${window.location.host}/asr`;
  }
  // localhost ì§ì ‘ ì ‘ì†
  if (window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1') {
    return 'ws://localhost:6470/asr';
  }
  // HTTP ì™¸ë¶€ ì ‘ì†
  return `ws://${window.location.hostname}:6470/asr`;
};

export function useSystemAudioSTT({ onSubtitle, onBufferUpdate, onStatusChange, wsUrl }: UseSystemAudioSTTProps) {
  const [isCapturing, setIsCapturing] = useState(false);
  const [status, setStatus] = useState<'idle' | 'connecting' | 'capturing' | 'error'>('idle');
  
  const wsRef = useRef<WebSocket | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const workletNodeRef = useRef<AudioWorkletNode | null>(null);
  const segmentIdRef = useRef(0);
  const lastLinesCountRef = useRef(0);
  const captureStartTimeRef = useRef(0);
  const lastSpeakerRef = useRef<number | undefined>(undefined);

  const updateStatus = useCallback((newStatus: 'idle' | 'connecting' | 'capturing' | 'error') => {
    setStatus(newStatus);
    onStatusChange?.(newStatus);
  }, [onStatusChange]);

  // [advice from AI] ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘
  const startCapture = useCallback(async () => {
    try {
      updateStatus('connecting');
      console.log('[SYSTEM-AUDIO] ğŸ¤ ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘...');

      // [advice from AI] HTTPS ë˜ëŠ” localhost í™˜ê²½ ì²´í¬
      const isSecure = window.location.protocol === 'https:' || 
                       window.location.hostname === 'localhost' ||
                       window.location.hostname === '127.0.0.1';
      
      if (!navigator.mediaDevices || !navigator.mediaDevices.getDisplayMedia) {
        throw new Error(
          isSecure 
            ? 'ì´ ë¸Œë¼ìš°ì €ëŠ” ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. Chrome ë˜ëŠ” Edgeë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.'
            : `ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ëŠ” HTTPS ë˜ëŠ” localhostì—ì„œë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n\ní˜„ì¬ ì ‘ì†: ${window.location.protocol}//${window.location.host}\n\ní•´ê²° ë°©ë²•:\n1. localhost:6430ìœ¼ë¡œ ì ‘ì†\n2. ë˜ëŠ” HTTPS ì„¤ì • í•„ìš”`
        );
      }

      // 1. getDisplayMediaë¡œ ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ (í™”ë©´ ê³µìœ  + ì˜¤ë””ì˜¤)
      const stream = await navigator.mediaDevices.getDisplayMedia({
        video: true,  // í™”ë©´ì€ í•„ìˆ˜ (í•˜ì§€ë§Œ ì‚¬ìš© ì•ˆ í•¨)
        audio: {
          echoCancellation: false,
          noiseSuppression: false,
          autoGainControl: false,
          sampleRate: 16000
        }
      });

      // ë¹„ë””ì˜¤ íŠ¸ë™ ì¤‘ì§€ (ì˜¤ë””ì˜¤ë§Œ í•„ìš”)
      stream.getVideoTracks().forEach(track => track.stop());
      
      const audioTracks = stream.getAudioTracks();
      if (audioTracks.length === 0) {
        throw new Error('ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨: ì˜¤ë””ì˜¤ íŠ¸ë™ ì—†ìŒ. "ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ ê³µìœ "ë¥¼ ì„ íƒí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.');
      }

      console.log('[SYSTEM-AUDIO] âœ… ì˜¤ë””ì˜¤ íŠ¸ë™:', audioTracks[0].label);
      streamRef.current = stream;

      // 2. WebSocket ì—°ê²°
      const url = wsUrl || getWsUrl();
      console.log('[SYSTEM-AUDIO] ğŸ”Œ WebSocket ì—°ê²°:', url);
      
      const ws = new WebSocket(url);
      wsRef.current = ws;

      ws.onopen = async () => {
        console.log('[SYSTEM-AUDIO] âœ… WebSocket ì—°ê²° ì„±ê³µ');
        
        // [advice from AI] PCM ì§ì ‘ ì „ì†¡ (--pcm-input ëª¨ë“œ - FFmpeg ë¶ˆí•„ìš”)
        // ë¸Œë¼ìš°ì € ê¸°ë³¸ ìƒ˜í”Œ ë ˆì´íŠ¸ ì‚¬ìš© í›„ 16kHzë¡œ ë‹¤ìš´ìƒ˜í”Œë§
        const audioContext = new AudioContext();
        audioContextRef.current = audioContext;
        
        const actualSampleRate = audioContext.sampleRate;
        const targetSampleRate = 16000;
        const resampleRatio = actualSampleRate / targetSampleRate;
        
        console.log(`[SYSTEM-AUDIO] ğŸ“¼ AudioContext: ${actualSampleRate}Hz â†’ ${targetSampleRate}Hz (ratio: ${resampleRatio.toFixed(2)})`);
        
        const source = audioContext.createMediaStreamSource(stream);
        
        // [advice from AI] ScriptProcessorNodeë¡œ PCM ë°ì´í„° ì¶”ì¶œ
        const bufferSize = 4096;
        const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
        
        let chunkCount = 0;
        
        // [advice from AI] ê°„ë‹¨í•œ ë‹¤ìš´ìƒ˜í”Œë§ í•¨ìˆ˜
        const downsample = (inputData: Float32Array, ratio: number): Float32Array => {
          if (ratio === 1) return inputData;
          const outputLength = Math.floor(inputData.length / ratio);
          const output = new Float32Array(outputLength);
          for (let i = 0; i < outputLength; i++) {
            output[i] = inputData[Math.floor(i * ratio)];
          }
          return output;
        };
        
        processor.onaudioprocess = (e) => {
          if (ws.readyState !== WebSocket.OPEN) return;
          
          const inputData = e.inputBuffer.getChannelData(0);
          
          // [advice from AI] ë‹¤ìš´ìƒ˜í”Œë§ (48kHz â†’ 16kHz ë“±)
          const resampledData = downsample(inputData, resampleRatio);
          
          // [advice from AI] Float32 â†’ Int16 ë³€í™˜
          const pcmData = new Int16Array(resampledData.length);
          for (let i = 0; i < resampledData.length; i++) {
            const s = Math.max(-1, Math.min(1, resampledData[i]));
            pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }
          
          chunkCount++;
          // 10ê°œë§ˆë‹¤ ë¡œê·¸ (ë””ë²„ê¹…)
          if (chunkCount % 10 === 0) {
            console.log(`[SYSTEM-AUDIO] ğŸ“¤ PCM ì²­í¬ ì „ì†¡: #${chunkCount}, í¬ê¸°: ${pcmData.byteLength}bytes`);
          }
          
          ws.send(pcmData.buffer);
        };
        
        // [advice from AI] ë¬´ìŒ ì¶œë ¥ ë…¸ë“œ ìƒì„± (ìŠ¤í”¼ì»¤ë¡œ ì†Œë¦¬ ì•ˆ ë‚˜ê°€ê²Œ)
        const gainNode = audioContext.createGain();
        gainNode.gain.value = 0;
        
        source.connect(processor);
        processor.connect(gainNode);
        gainNode.connect(audioContext.destination);
        
        // [advice from AI] processorë¥¼ refì— ì €ì¥ (ì •ë¦¬ìš©)
        (audioContext as any)._processor = processor;
        (audioContext as any)._source = source;
        (audioContext as any)._gain = gainNode;

        captureStartTimeRef.current = Date.now();
        lastLinesCountRef.current = 0;
        setIsCapturing(true);
        updateStatus('capturing');
        console.log('[SYSTEM-AUDIO] ğŸ™ï¸ ìº¡ì²˜ ì¤‘... (PCM ì§ì ‘ ì „ì†¡)');
      };

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          
          // [advice from AI] ë””ë²„ê¹…: ì„œë²„ ì‘ë‹µ í˜•ì‹ í™•ì¸
          // console.log('[SYSTEM-AUDIO] ğŸ“¥ ìˆ˜ì‹  ë°ì´í„°:', JSON.stringify(data).substring(0, 200));
          
          // config ë©”ì‹œì§€ ë¬´ì‹œ
          if (data.type === 'config') {
            console.log('[SYSTEM-AUDIO] âš™ï¸ ì„œë²„ ì„¤ì • ìˆ˜ì‹ ');
            return;
          }

          // ready_to_stop ì²˜ë¦¬
          if (data.type === 'ready_to_stop') {
            console.log('[SYSTEM-AUDIO] ğŸ ì²˜ë¦¬ ì™„ë£Œ');
            return;
          }

          // [advice from AI] WhisperLiveKit ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
          const lines = data.lines || [];
          const bufferText = data.buffer_transcription || data.buffer || '';
          const currentTime = (Date.now() - captureStartTimeRef.current) / 1000;

          // ìƒˆë¡œìš´ linesë§Œ ì²˜ë¦¬ (ìµœì¢… ê²°ê³¼)
          for (let i = lastLinesCountRef.current; i < lines.length; i++) {
            const line = lines[i];
            if (!line.text || line.speaker === -2) continue;  // ë¬´ìŒ ë¬´ì‹œ
            
            segmentIdRef.current += 1;
            const speaker = line.speaker > 0 ? `í™”ì${line.speaker}` : undefined;
            
            // [advice from AI] í™”ì ë³€ê²½ ê°ì§€
            lastSpeakerRef.current = line.speaker;
            
            // [advice from AI] startTime/endTimeì„ ìˆ«ìë¡œ ë³€í™˜ (ì•ˆì „í•˜ê²Œ)
            const startTime = typeof line.start === 'number' ? line.start : currentTime;
            const endTime = typeof line.end === 'number' ? line.end : (currentTime + 3);
            
            const subtitle: SystemAudioSubtitle = {
              id: segmentIdRef.current,
              text: line.text.trim(),
              speaker: speaker,
              startTime: startTime,
              endTime: endTime,
              isFinal: true
            };

            console.log(`[SYSTEM-AUDIO] âœ… ìµœì¢…: [${startTime.toFixed(1)}s] ${subtitle.text.substring(0, 40)}...`);
            onSubtitle(subtitle);
          }
          lastLinesCountRef.current = lines.length;

          // [advice from AI] ë²„í¼ í…ìŠ¤íŠ¸ (ì‹¤ì‹œê°„ ì¤‘ê°„ ê²°ê³¼) - ì¦‰ì‹œ í‘œì‹œ
          if (bufferText && bufferText.trim() && onBufferUpdate) {
            console.log(`[SYSTEM-AUDIO] ğŸ’¬ ë²„í¼: ${bufferText.substring(0, 40)}...`);
            const currentSpeaker = lastSpeakerRef.current;
            onBufferUpdate({
              text: bufferText.trim(),
              speaker: currentSpeaker && currentSpeaker > 0 ? `í™”ì${currentSpeaker}` : undefined
            });
          }

        } catch (e) {
          // [advice from AI] ìƒì„¸ ì˜¤ë¥˜ ë¡œê¹…
          console.error('[SYSTEM-AUDIO] ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', e, '\nì›ë³¸:', event.data.substring(0, 200));
        }
      };

      ws.onerror = (error) => {
        console.error('[SYSTEM-AUDIO] âŒ WebSocket ì˜¤ë¥˜:', error);
        updateStatus('error');
      };

      ws.onclose = () => {
        console.log('[SYSTEM-AUDIO] ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ');
        setIsCapturing(false);
        if (status === 'capturing') {
          updateStatus('idle');
        }
      };

    } catch (error) {
      console.error('[SYSTEM-AUDIO] âŒ ìº¡ì²˜ ì‹œì‘ ì˜¤ë¥˜:', error);
      updateStatus('error');
      
      // ì‚¬ìš©ì ì¹œí™”ì  ì˜¤ë¥˜ ë©”ì‹œì§€
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          alert('í™”ë©´ ê³µìœ  ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ì‹œìŠ¤í…œ ì˜¤ë””ì˜¤ë¥¼ ê³µìœ í•´ì£¼ì„¸ìš”.');
        } else {
          alert(`ì˜¤ë¥˜: ${error.message}`);
        }
      }
    }
  }, [onSubtitle, onBufferUpdate, updateStatus, wsUrl, status]);

  // [advice from AI] ìº¡ì²˜ ì¤‘ì§€ - refë¡œ ê´€ë¦¬í•˜ì—¬ ë¶ˆí•„ìš”í•œ ì¬ìƒì„± ë°©ì§€
  const stopCaptureRef = useRef<() => void>(() => {});
  
  stopCaptureRef.current = () => {
    // ì´ë¯¸ ì¤‘ì§€ëœ ìƒíƒœë©´ ë¬´ì‹œ
    if (!wsRef.current && !streamRef.current && !audioContextRef.current) {
      return;
    }
    
    console.log('[SYSTEM-AUDIO] ğŸ›‘ ìº¡ì²˜ ì¤‘ì§€');

    // WebSocket ì¢…ë£Œ (ë¹ˆ ë°ì´í„° ì „ì†¡í•˜ì—¬ ì„œë²„ì— ì¢…ë£Œ ì•Œë¦¼)
    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(new Blob([]));
      wsRef.current.close();
    }
    wsRef.current = null;

    // ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì¢…ë£Œ
    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
    }
    audioContextRef.current = null;

    // ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }
    streamRef.current = null;

    setIsCapturing(false);
    updateStatus('idle');
  };
  
  const stopCapture = useCallback(() => {
    stopCaptureRef.current();
  }, []);

  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬ (ì˜ì¡´ì„± ì—†ìŒ)
  useEffect(() => {
    return () => {
      stopCaptureRef.current();
    };
  }, []);

  return {
    isCapturing,
    status,
    startCapture,
    stopCapture
  };
}
