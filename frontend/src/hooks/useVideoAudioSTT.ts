// [advice from AI] ë¹„ë””ì˜¤ ìš”ì†Œì—ì„œ ì§ì ‘ ì˜¤ë””ì˜¤ ì¶”ì¶œ + WhisperLiveKit ì‹¤ì‹œê°„ STT
// getDisplayMedia ë¶ˆí•„ìš” - video.captureStream() ì‚¬ìš©

import { useState, useRef, useCallback, useEffect } from 'react';
// [advice from AI] í›„ì²˜ë¦¬ëŠ” App.tsxì—ì„œ ë¬¸ì¥ë³„ë¡œ ì ìš© (ì—¬ê¸°ì„œëŠ” ì›ë³¸ ì „ë‹¬)

export interface VideoAudioSubtitle {
  id: number;
  text: string;
  speaker?: string;
  startTime: number;
  endTime: number;
  isFinal: boolean;
}

// [advice from AI] lines í•­ëª© ì¸í„°í˜ì´ìŠ¤
export interface LineItem {
  text: string;
  speaker: number;
  start: string;
  end: string;
}

export interface BufferUpdate {
  text: string;
  speaker?: string;
  isNoAudio?: boolean;
  linesCount?: number;
  // [advice from AI] â˜… í™•ì • ì¸ë±ìŠ¤ ê¸°ë°˜ ì¡¸ì—…ì„ ìœ„í•´ lines ì „ì²´ ì „ë‹¬
  lines?: LineItem[];
}

interface UseVideoAudioSTTProps {
  getVideoElement: () => HTMLVideoElement | null;  // [advice from AI] í•¨ìˆ˜ë¡œ ë°›ì•„ì„œ ìœ ì—°í•˜ê²Œ
  onSubtitle: (subtitle: VideoAudioSubtitle) => void;
  onBufferUpdate?: (buffer: BufferUpdate) => void;
  onStatusChange?: (status: 'idle' | 'connecting' | 'capturing' | 'error') => void;
  wsUrl?: string;
}

// [advice from AI] ë™ì  WebSocket URL ìƒì„±
const getWsUrl = () => {
  if (window.location.protocol === 'https:') {
    return `wss://${window.location.host}/asr`;
  }
  if (window.location.hostname === 'localhost' || window.location.hostname === '127.0.0.1') {
    return 'ws://localhost:6470/asr';
  }
  return `ws://${window.location.hostname}:6470/asr`;
};

// [advice from AI] WhisperLiveKit ì‹œê°„ ë¬¸ìì—´ íŒŒì‹± ("0:00:05" â†’ 5.0)
const parseTimeString = (timeStr: string | number | undefined): number | null => {
  if (typeof timeStr === 'number') return timeStr;
  if (!timeStr || typeof timeStr !== 'string') return null;
  
  // "H:MM:SS" ë˜ëŠ” "HH:MM:SS" í˜•ì‹
  const parts = timeStr.split(':');
  if (parts.length === 3) {
    const [h, m, s] = parts.map(Number);
    return h * 3600 + m * 60 + s;
  }
  // "MM:SS" í˜•ì‹
  if (parts.length === 2) {
    const [m, s] = parts.map(Number);
    return m * 60 + s;
  }
  return null;
};

export function useVideoAudioSTT({ getVideoElement, onSubtitle, onBufferUpdate, onStatusChange, wsUrl }: UseVideoAudioSTTProps) {
  const [isCapturing, setIsCapturing] = useState(false);
  const [status, setStatus] = useState<'idle' | 'connecting' | 'capturing' | 'error'>('idle');
  
  const wsRef = useRef<WebSocket | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const videoElementRef = useRef<HTMLVideoElement | null>(null);  // [advice from AI] í˜„ì¬ ë¹„ë””ì˜¤ ìš”ì†Œ ì €ì¥
  // [advice from AI] ìœ ë‹ˆí¬ ID ìƒì„± - timestamp ê¸°ë°˜ + í° ì˜¤í”„ì…‹ìœ¼ë¡œ App.tsxì™€ ì¶©ëŒ ë°©ì§€
  const segmentIdRef = useRef(Date.now() + 1000000);
  const lastLinesCountRef = useRef(0);
  // [advice from AI] â˜… ì´ë¯¸ ì²˜ë¦¬í•œ lines í…ìŠ¤íŠ¸ ì¶”ì  (ì¤‘ë³µ ë°©ì§€) - ë¦¬ì…‹ ì‹œì—ë„ ê°™ì€ í…ìŠ¤íŠ¸ ë‹¤ì‹œ ì²˜ë¦¬ ì•ˆ í•¨
  const processedLinesSetRef = useRef<Set<string>>(new Set());
  // [advice from AI] ìº¡ì²˜ ì‹œì‘ ì‹œì ì˜ ë¹„ë””ì˜¤ ì‹œê°„ (íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°ìš©)
  const captureStartVideoTimeRef = useRef(0);
  const lastSpeakerRef = useRef<number | undefined>(undefined);
  
  // [advice from AI] â˜…â˜…â˜… WhisperLiveKit ìƒíƒœ ëª¨ë‹ˆí„°ë§ â˜…â˜…â˜…
  const lastMessageTimeRef = useRef<number>(0);        // ë§ˆì§€ë§‰ ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œê°„
  const healthCheckIntervalRef = useRef<number | null>(null);
  const reconnectAttemptsRef = useRef<number>(0);
  const MAX_RECONNECT_ATTEMPTS = 3;
  const MESSAGE_TIMEOUT_MS = 30000;  // 30ì´ˆ ë™ì•ˆ ë©”ì‹œì§€ ì—†ìœ¼ë©´ ë¬¸ì œë¡œ íŒë‹¨

  const updateStatus = useCallback((newStatus: 'idle' | 'connecting' | 'capturing' | 'error') => {
    setStatus(newStatus);
    onStatusChange?.(newStatus);
  }, [onStatusChange]);

  // [advice from AI] â˜… startCaptureRefë¥¼ ìœ„í•œ forward declaration
  const startCaptureRef = useRef<(() => Promise<void>) | null>(null);
  
  // [advice from AI] â˜…â˜…â˜… ìë™ ì¬ì—°ê²° í•¨ìˆ˜ â˜…â˜…â˜…
  const attemptReconnect = useCallback(async () => {
    const video = videoElementRef.current;
    if (!video) {
      console.error('[HEALTH] âŒ ë¹„ë””ì˜¤ ìš”ì†Œ ì—†ìŒ â†’ ì¬ì—°ê²° ë¶ˆê°€');
      return;
    }
    
    console.log('[HEALTH] ğŸ”„ WhisperLiveKit ì¬ì—°ê²° ì‹œë„...');
    
    // ê¸°ì¡´ WebSocket ì •ë¦¬
    if (wsRef.current) {
      try {
        wsRef.current.close();
      } catch (e) {
        // ignore
      }
      wsRef.current = null;
    }
    
    // ê¸°ì¡´ AudioContext ì •ë¦¬
    if (audioContextRef.current) {
      try {
        audioContextRef.current.close();
      } catch (e) {
        // ignore
      }
      audioContextRef.current = null;
    }
    
    // ì ì‹œ ëŒ€ê¸° í›„ ì¬ì—°ê²°
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    // startCapture ì¬í˜¸ì¶œ
    if (startCaptureRef.current) {
      startCaptureRef.current();
    }
  }, []);

  // [advice from AI] ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘
  const startCapture = useCallback(async () => {
    const video = getVideoElement();
    if (!video) {
      console.error('[VIDEO-STT] âŒ ë¹„ë””ì˜¤ ìš”ì†Œê°€ ì—†ìŠµë‹ˆë‹¤');
      alert('ë¨¼ì € ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.');
      return;
    }
    
    videoElementRef.current = video;  // ì €ì¥
    
    // [advice from AI] â˜…â˜…â˜… ì´ˆë°˜ í…ìŠ¤íŠ¸ ì†ì‹¤ ë°©ì§€ â˜…â˜…â˜…
    // ë¹„ë””ì˜¤ë¥¼ ì¼ì‹œ ì •ì§€í•˜ê³ , WebSocket + AudioContext ì¤€ë¹„ ì™„ë£Œ í›„ ì¬ìƒ
    const wasPlaying = !video.paused;
    const savedCurrentTime = video.currentTime;
    if (wasPlaying) {
      video.pause();
      console.log('[VIDEO-STT] â¸ï¸ ë¹„ë””ì˜¤ ì¼ì‹œ ì •ì§€ (ìº¡ì²˜ ì¤€ë¹„ ì¤‘...)');
    }

    try {
      updateStatus('connecting');
      console.log('[VIDEO-STT] ğŸ¤ ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘...');
      console.log('[VIDEO-STT] ğŸ“º ë¹„ë””ì˜¤ ì†ŒìŠ¤:', video.src?.substring(0, 80) || video.currentSrc?.substring(0, 80));
      
      // [advice from AI] video.captureStream()ìœ¼ë¡œ MediaStream ì–»ê¸°
      let stream: MediaStream;
      try {
        // @ts-ignore - captureStreamì€ í‘œì¤€ APIì§€ë§Œ íƒ€ì… ì •ì˜ì— ì—†ìŒ
        stream = video.captureStream ? video.captureStream() : video.mozCaptureStream?.();
      } catch (captureError) {
        console.error('[VIDEO-STT] âŒ captureStream ì˜¤ë¥˜:', captureError);
        throw new Error('ë¹„ë””ì˜¤ ìº¡ì²˜ ì‹¤íŒ¨: ì™¸ë¶€ URLì€ CORS ì •ì±…ìœ¼ë¡œ ì¸í•´ ìº¡ì²˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì§ì ‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.');
      }
      
      if (!stream) {
        throw new Error('ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ìº¡ì²˜ë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.');
      }

      const audioTracks = stream.getAudioTracks();
      console.log('[VIDEO-STT] ğŸ” ì˜¤ë””ì˜¤ íŠ¸ë™ ìˆ˜:', audioTracks.length);
      
      if (audioTracks.length === 0) {
        // [advice from AI] CORSë¡œ ì¸í•´ ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ
        console.warn('[VIDEO-STT] âš ï¸ ì˜¤ë””ì˜¤ íŠ¸ë™ ì—†ìŒ - CORS ë˜ëŠ” ë¯¸ë””ì–´ ë¡œë“œ ëŒ€ê¸° ì¤‘');
        throw new Error('ì˜¤ë””ì˜¤ íŠ¸ë™ì´ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ê°€ ì™„ì „íˆ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ CORS ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.');
      }

      console.log('[VIDEO-STT] âœ… ì˜¤ë””ì˜¤ íŠ¸ë™:', audioTracks[0].label || 'default');

      // WebSocket ì—°ê²°
      const url = wsUrl || getWsUrl();
      console.log('[VIDEO-STT] ğŸ”Œ WebSocket ì—°ê²°:', url);
      
      const ws = new WebSocket(url);
      wsRef.current = ws;

      ws.onopen = async () => {
        console.log('[VIDEO-STT] âœ… WebSocket ì—°ê²° ì„±ê³µ');
        
        // [advice from AI] AudioContext ìƒì„± - ë¹„ë””ì˜¤ì˜ ì˜¤ë””ì˜¤ë¥¼ ì²˜ë¦¬
        const audioContext = new AudioContext();
        audioContextRef.current = audioContext;
        
        const actualSampleRate = audioContext.sampleRate;
        const targetSampleRate = 16000;
        const resampleRatio = actualSampleRate / targetSampleRate;
        
        console.log(`[VIDEO-STT] ğŸ“¼ AudioContext: ${actualSampleRate}Hz â†’ ${targetSampleRate}Hz (ë¹„ìœ¨: ${resampleRatio.toFixed(2)})`);
        
        // [advice from AI] MediaStreamSource ì‚¬ìš© - CORS ë¬¸ì œ íšŒí”¼ + ì¬ì‚¬ìš© ê°€ëŠ¥
        // captureStream()ì—ì„œ ì–»ì€ ìŠ¤íŠ¸ë¦¼ ì§ì ‘ ì‚¬ìš©
        const source = audioContext.createMediaStreamSource(stream);
        
        // [advice from AI] â˜… Anti-aliasing í•„í„° ì¶”ê°€ (í• ë£¨ì‹œë„¤ì´ì…˜ ê°ì†Œ í•µì‹¬!)
        // ë‹¤ìš´ìƒ˜í”Œë§ ì „ì— ê³ ì£¼íŒŒë¥¼ ì œê±°í•´ì•¼ aliasing ë°©ì§€
        // Nyquist ì£¼íŒŒìˆ˜ (16kHz / 2 = 8kHz) ì´í•˜ë¡œ í•„í„°ë§
        const lowpassFilter = audioContext.createBiquadFilter();
        lowpassFilter.type = 'lowpass';
        lowpassFilter.frequency.value = 7500;  // 8kHzë³´ë‹¤ ì•½ê°„ ë‚®ê²Œ ì„¤ì • (ì•ˆì „ ë§ˆì§„)
        lowpassFilter.Q.value = 0.7;  // Butterworth íŠ¹ì„±
        
        // [advice from AI] â˜… 2ë‹¨ê³„ í•„í„° (ë” ê¸‰ê²©í•œ rolloff)
        const lowpassFilter2 = audioContext.createBiquadFilter();
        lowpassFilter2.type = 'lowpass';
        lowpassFilter2.frequency.value = 7500;
        lowpassFilter2.Q.value = 0.7;
        
        // [advice from AI] â˜… ë…¸ì´ì¦ˆ ê²Œì´íŠ¸ íš¨ê³¼ë¥¼ ìœ„í•œ ì»´í”„ë ˆì„œ (ë¬´ìŒ êµ¬ê°„ ë…¸ì´ì¦ˆ ê°ì†Œ)
        const compressor = audioContext.createDynamicsCompressor();
        compressor.threshold.value = -50;  // ì¡°ìš©í•œ ì†Œë¦¬ ê°ì‡„
        compressor.knee.value = 40;
        compressor.ratio.value = 12;
        compressor.attack.value = 0;
        compressor.release.value = 0.25;
        
        console.log('[VIDEO-STT] ğŸ”§ Anti-aliasing í•„í„° ì ìš©: 7500Hz lowpass (2ë‹¨ê³„) + ì»´í”„ë ˆì„œ');
        
        // [advice from AI] ë¶„ì„ìš© ë…¸ë“œ - ScriptProcessorë¡œ PCM ì¶”ì¶œ
        // ë²„í¼ í¬ê¸° ì¦ê°€: 4096 â†’ 8192 (ë” ì•ˆì •ì ì¸ ì²˜ë¦¬)
        const bufferSize = 8192;
        const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
        
        let chunkCount = 0;
        
        // [advice from AI] â˜… ê°œì„ ëœ ë‹¤ìš´ìƒ˜í”Œë§ í•¨ìˆ˜ - ì„ í˜• ë³´ê°„ë²• (Linear Interpolation)
        // ë‹¨ìˆœ ê°„ê²© ì„ íƒ ëŒ€ì‹  ì¸ì ‘ ìƒ˜í”Œ ê°„ ë³´ê°„ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ë³€í™˜
        const downsampleWithInterpolation = (inputData: Float32Array, ratio: number): Float32Array => {
          if (ratio <= 1) return inputData;
          const outputLength = Math.floor(inputData.length / ratio);
          const output = new Float32Array(outputLength);
          
          for (let i = 0; i < outputLength; i++) {
            const srcIndex = i * ratio;
            const srcIndexFloor = Math.floor(srcIndex);
            const srcIndexCeil = Math.min(srcIndexFloor + 1, inputData.length - 1);
            const fraction = srcIndex - srcIndexFloor;
            
            // ì„ í˜• ë³´ê°„: output = (1 - fraction) * floor + fraction * ceil
            output[i] = (1 - fraction) * inputData[srcIndexFloor] + fraction * inputData[srcIndexCeil];
          }
          return output;
        };
        
        // [advice from AI] â˜… ë¬´ìŒ ê°ì§€ìš© RMS ê³„ì‚°
        const calculateRMS = (data: Float32Array): number => {
          let sum = 0;
          for (let i = 0; i < data.length; i++) {
            sum += data[i] * data[i];
          }
          return Math.sqrt(sum / data.length);
        };
        
        // ë¬´ìŒ ì²­í¬ ì¹´ìš´í„° (ì—°ì† ë¬´ìŒ ê°ì§€)
        let silentChunkCount = 0;
        const SILENCE_THRESHOLD = 0.005;  // RMS ì„ê³„ê°’
        const MAX_SILENT_CHUNKS = 10;     // ì—°ì† ë¬´ìŒ í—ˆìš© ê°œìˆ˜
        
        processor.onaudioprocess = (e) => {
          if (ws.readyState !== WebSocket.OPEN) return;
          
          // [advice from AI] ë¹„ë””ì˜¤ê°€ ì¬ìƒ ì¤‘ì¼ ë•Œë§Œ ì „ì†¡
          if (video.paused || video.ended) return;
          
          const inputData = e.inputBuffer.getChannelData(0);
          
          // [advice from AI] â˜… ë¬´ìŒ ê°ì§€ - ì™„ì „ ë¬´ìŒì¼ ë•ŒëŠ” ì „ì†¡ ìŠ¤í‚µ (í• ë£¨ì‹œë„¤ì´ì…˜ ë°©ì§€)
          const rms = calculateRMS(inputData);
          if (rms < SILENCE_THRESHOLD) {
            silentChunkCount++;
            if (silentChunkCount > MAX_SILENT_CHUNKS) {
              // ì—°ì† ë¬´ìŒì´ë©´ ê°€ë”ë§Œ ì „ì†¡ (ì—°ê²° ìœ ì§€ìš©)
              if (silentChunkCount % 20 !== 0) {
                return;  // ëŒ€ë¶€ë¶„ì˜ ë¬´ìŒ ì²­í¬ ìŠ¤í‚µ
              }
            }
          } else {
            silentChunkCount = 0;  // ì†Œë¦¬ ê°ì§€ë˜ë©´ ë¦¬ì…‹
          }
          
          // [advice from AI] â˜… ê°œì„ ëœ ë‹¤ìš´ìƒ˜í”Œë§ ì ìš©
          const resampledData = downsampleWithInterpolation(inputData, resampleRatio);
          
          // Float32 â†’ Int16 ë³€í™˜ (í´ë¦¬í•‘ ë°©ì§€ í¬í•¨)
          const pcmData = new Int16Array(resampledData.length);
          for (let i = 0; i < resampledData.length; i++) {
            const s = Math.max(-1, Math.min(1, resampledData[i]));
            pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
          }
          
          chunkCount++;
          if (chunkCount % 10 === 0) {
            console.log(`[VIDEO-STT] ğŸ“¤ PCM ì²­í¬ ì „ì†¡: #${chunkCount}, ì‹œê°„: ${video.currentTime.toFixed(1)}s, RMS: ${rms.toFixed(4)}`);
          }
          
          ws.send(pcmData.buffer);
        };
        
        // [advice from AI] â˜… ì˜¤ë””ì˜¤ ì²´ì¸ ì—°ê²°: source â†’ lowpass1 â†’ lowpass2 â†’ compressor â†’ processor
        source.connect(lowpassFilter);
        lowpassFilter.connect(lowpassFilter2);
        lowpassFilter2.connect(compressor);
        compressor.connect(processor);
        processor.connect(audioContext.destination);
        
        // refì— ì €ì¥ (ì •ë¦¬ìš©)
        // refì— ì €ì¥ (ì •ë¦¬ìš©)
        (audioContext as any)._processor = processor;
        (audioContext as any)._source = source;
        (audioContext as any)._lowpassFilter = lowpassFilter;
        (audioContext as any)._lowpassFilter2 = lowpassFilter2;
        (audioContext as any)._compressor = compressor;

        // [advice from AI] ìº¡ì²˜ ì‹œì‘ ì‹œì ì˜ ë¹„ë””ì˜¤ ì‹œê°„ ì €ì¥ (íƒ€ì„ìŠ¤íƒ¬í”„ ê³„ì‚°ìš©)
        captureStartVideoTimeRef.current = video.currentTime || 0;
        lastLinesCountRef.current = 0;
        processedLinesSetRef.current.clear();  // [advice from AI] â˜… ì²˜ë¦¬ëœ lines ì¶”ì  ì´ˆê¸°í™”
        lastMessageTimeRef.current = Date.now();  // ì´ˆê¸° íƒ€ì„ìŠ¤íƒ¬í”„
        setIsCapturing(true);
        updateStatus('capturing');
        console.log(`[VIDEO-STT] ğŸ™ï¸ ìº¡ì²˜ ì‹œì‘! ë¹„ë””ì˜¤ ì‹œê°„: ${captureStartVideoTimeRef.current.toFixed(1)}s`);
        
        // [advice from AI] â˜…â˜…â˜… WhisperLiveKit í—¬ìŠ¤ì²´í¬ ì‹œì‘ â˜…â˜…â˜…
        if (healthCheckIntervalRef.current) {
          clearInterval(healthCheckIntervalRef.current);
        }
        healthCheckIntervalRef.current = window.setInterval(async () => {
          const now = Date.now();
          const timeSinceLastMessage = now - lastMessageTimeRef.current;
          
          // ë¹„ë””ì˜¤ê°€ ì¬ìƒ ì¤‘ì¼ ë•Œë§Œ ì²´í¬
          if (videoElementRef.current && !videoElementRef.current.paused) {
            if (timeSinceLastMessage > MESSAGE_TIMEOUT_MS) {
              console.warn(`[HEALTH] âš ï¸ ${(timeSinceLastMessage / 1000).toFixed(0)}ì´ˆ ë™ì•ˆ ë©”ì‹œì§€ ì—†ìŒ â†’ ì¬ì—°ê²° ì‹œë„`);
              
              if (reconnectAttemptsRef.current < MAX_RECONNECT_ATTEMPTS) {
                reconnectAttemptsRef.current++;
                console.log(`[HEALTH] ğŸ”„ ì¬ì—°ê²° ì‹œë„ ${reconnectAttemptsRef.current}/${MAX_RECONNECT_ATTEMPTS}`);
                
                // [advice from AI] â˜… ìë™ ì¬ì—°ê²° ì‹¤í–‰
                updateStatus('connecting');
                
                // ê¸°ì¡´ WebSocket ì •ë¦¬
                if (wsRef.current) {
                  try { wsRef.current.close(); } catch (_e) { /* ignore */ }
                  wsRef.current = null;
                }
                
                // ì ì‹œ ëŒ€ê¸° í›„ ì¬ì—°ê²°
                await new Promise(resolve => setTimeout(resolve, 500));
                
                if (startCaptureRef.current) {
                  startCaptureRef.current();
                }
              } else {
                console.error(`[HEALTH] âŒ ì¬ì—°ê²° ${MAX_RECONNECT_ATTEMPTS}íšŒ ì‹¤íŒ¨ â†’ ìˆ˜ë™ ì¬ì‹œì‘ í•„ìš”`);
                updateStatus('error');
                // í—¬ìŠ¤ì²´í¬ ì¤‘ì§€
                if (healthCheckIntervalRef.current) {
                  clearInterval(healthCheckIntervalRef.current);
                  healthCheckIntervalRef.current = null;
                }
              }
            }
          }
        }, 10000);  // 10ì´ˆë§ˆë‹¤ ì²´í¬
        
        // [advice from AI] â˜…â˜…â˜… ì´ˆë°˜ í…ìŠ¤íŠ¸ ì†ì‹¤ ë°©ì§€ - ì¤€ë¹„ ì™„ë£Œ í›„ ë¹„ë””ì˜¤ ì¬ìƒ â˜…â˜…â˜…
        if (wasPlaying) {
          // ë¹„ë””ì˜¤ í˜„ì¬ ìœ„ì¹˜ ë³µì› í›„ ì¬ìƒ
          video.currentTime = savedCurrentTime;
          video.play().then(() => {
            console.log(`[VIDEO-STT] â–¶ï¸ ë¹„ë””ì˜¤ ì¬ìƒ ì‹œì‘ (${savedCurrentTime.toFixed(1)}së¶€í„°)`);
          }).catch(err => {
            console.error('[VIDEO-STT] âŒ ë¹„ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', err);
          });
        }
      };

      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);
          
          // [advice from AI] â˜… ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œê°„ ì—…ë°ì´íŠ¸ (í—¬ìŠ¤ì²´í¬ìš©)
          lastMessageTimeRef.current = Date.now();
          reconnectAttemptsRef.current = 0;  // ì„±ê³µì ìœ¼ë¡œ ë©”ì‹œì§€ ë°›ìœ¼ë©´ ì¬ì‹œë„ ì¹´ìš´íŠ¸ ë¦¬ì…‹
          
          // [advice from AI] ì„¤ì •/ì¢…ë£Œ ë©”ì‹œì§€ëŠ” ë¬´ì‹œ
          if (data.type === 'config' || data.type === 'ready_to_stop') {
            return;
          }

          const lines = data.lines || [];
          const bufferText = data.buffer_transcription || data.buffer || '';
          const currentVideoTime = videoElementRef.current?.currentTime || 0;
          
          // [advice from AI] â˜… ì›ë³¸ ë°ì´í„° ë¡œê¹… (ë””ë²„ê¹…ìš©) - í™”ì ì •ë³´ í¬í•¨
          // [advice from AI] â˜… ì›ë³¸ ë°ì´í„° ë¡œê¹… - í™”ì ì •ë³´ ìƒì„¸ í™•ì¸
          if (lines.length > 0 || bufferText) {
            const lastLine = lines.length > 0 ? lines[lines.length - 1] : null;
            console.log(`[WHISPER-RAW] ğŸ“¨ ì›ë³¸:`, {
              lines_count: lines.length,
              buffer: bufferText ? bufferText.substring(0, 50) + '...' : '(empty)',
              last_line: lastLine?.text?.substring(0, 50) || '(none)',
              // â˜… speaker ì›ë³¸ê°’ í™•ì¸ (íƒ€ì… í¬í•¨)
              speaker_raw: lastLine?.speaker,
              speaker_type: typeof lastLine?.speaker
            });
          }

          // [advice from AI] WhisperLiveKitì´ linesë¥¼ ë¦¬ì…‹í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²´í¬
          // lines_countê°€ í˜„ì¬ ì €ì¥ëœ ê°’ë³´ë‹¤ ì‘ì•„ì§€ë©´ ë¦¬ì…‹ëœ ê²ƒ
          if (lines.length < lastLinesCountRef.current) {
            console.log(`[STT] ğŸ”„ lines ë¦¬ì…‹ ê°ì§€: ${lastLinesCountRef.current} â†’ ${lines.length}`);
            lastLinesCountRef.current = 0;
          }

          // ìƒˆë¡œìš´ lines ì²˜ë¦¬ (ìµœì¢… ê²°ê³¼)
          for (let i = lastLinesCountRef.current; i < lines.length; i++) {
            const line = lines[i];
            
            if (!line.text || line.speaker === -2) continue;
            
            const rawText = line.text.trim();
            if (!rawText) continue;
            
            // [advice from AI] â˜… ì´ë¯¸ ì²˜ë¦¬í•œ í…ìŠ¤íŠ¸ì¸ì§€ ì²´í¬ (ë¦¬ì…‹ í›„ ì¤‘ë³µ ë°©ì§€)
            // startTime + rawText ì¡°í•©ìœ¼ë¡œ ê³ ìœ  í‚¤ ìƒì„±
            const parsedStart = parseTimeString(line.start);
            const lineKey = `${parsedStart?.toFixed(1) || 'unknown'}_${rawText.substring(0, 30)}`;
            
            if (processedLinesSetRef.current.has(lineKey)) {
              console.log(`[STT] â­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ lines ìŠ¤í‚µ: "${rawText.substring(0, 30)}..."`);
              continue;
            }
            processedLinesSetRef.current.add(lineKey);
            
            segmentIdRef.current += 1;
            // [advice from AI] â˜… speaker >= 0ì´ë©´ ìœ íš¨ (0ë²ˆ í™”ìë„ í¬í•¨)
            const speaker = (line.speaker !== undefined && line.speaker !== null && line.speaker >= 0) 
              ? `í™”ì${line.speaker + 1}` 
              : undefined;
            lastSpeakerRef.current = line.speaker;
            console.log(`[STT] ğŸ¤ í™”ì: ${speaker || 'ì—†ìŒ'} (raw: ${line.speaker})`);
            
            const captureStartVideoTime = captureStartVideoTimeRef.current;
            const parsedEnd = parseTimeString(line.end);
            
            const startTime = parsedStart !== null 
              ? captureStartVideoTime + parsedStart 
              : currentVideoTime;
            const endTime = parsedEnd !== null 
              ? captureStartVideoTime + parsedEnd 
              : startTime + 3;
            
            const subtitle: VideoAudioSubtitle = {
              id: segmentIdRef.current,
              text: rawText,
              speaker: speaker,
              startTime: startTime,
              endTime: endTime,
              isFinal: true
            };

            // [advice from AI] ìµœì¢… ê²°ê³¼ë§Œ ë¡œê·¸
            console.log(`[STT] ğŸ“ "${rawText.substring(0, 40)}..." [${startTime.toFixed(1)}s~${endTime.toFixed(1)}s]`);
            onSubtitle(subtitle);
          }
          lastLinesCountRef.current = lines.length;

          // ë²„í¼ í…ìŠ¤íŠ¸ (ì‹¤ì‹œê°„ ì¤‘ê°„ ê²°ê³¼)
          const currentSpeaker = lastSpeakerRef.current;
          // [advice from AI] â˜… speaker >= 0ì´ë©´ ìœ íš¨ (0ë²ˆ í™”ìë„ í¬í•¨)
          const speakerStr = (currentSpeaker !== undefined && currentSpeaker !== null && currentSpeaker >= 0) 
            ? `í™”ì${currentSpeaker + 1}` 
            : undefined;
          
          // [advice from AI] â˜… í™”ì ë³€ê²½ ê°ì§€ë¥¼ ìœ„í•œ ë””ë²„ê·¸ ë¡œê·¸ (ë²„í¼ì— í™”ì ì •ë³´ ì „ë‹¬)
          if (bufferText && bufferText.trim()) {
            // ë§ˆì§€ë§‰ ìœ íš¨ í™”ìì™€ í˜„ì¬ raw í™”ì ë¹„êµ
            const lastLineRawSpeaker = lines.length > 0 ? lines[lines.length - 1]?.speaker : undefined;
            console.log(`[BUFFER-SPEAKER] ğŸ“¤ lastSpeakerRef=${currentSpeaker}, lastLineRaw=${lastLineRawSpeaker}, speakerStr=${speakerStr || 'null'}`);
          }
          
          // [advice from AI] â˜… í•­ìƒ lines ì „ì²´ ì „ë‹¬ (í™•ì • ì¸ë±ìŠ¤ ê¸°ë°˜ ì¡¸ì—…ìš©)
          if (onBufferUpdate) {
            onBufferUpdate({
              text: bufferText?.trim() || '',
              speaker: speakerStr,
              isNoAudio: data.status === 'no_audio_detected',
              linesCount: lines.length,
              lines: lines  // â˜… í•µì‹¬: lines ì „ì²´ ì „ë‹¬
            });
          }

        } catch (e) {
          console.error('[VIDEO-STT] ë©”ì‹œì§€ íŒŒì‹± ì˜¤ë¥˜:', e);
        }
      };

      ws.onerror = (error) => {
        console.error('[VIDEO-STT] âŒ WebSocket ì˜¤ë¥˜:', error);
        updateStatus('error');
      };

      ws.onclose = () => {
        console.log('[VIDEO-STT] ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ');
        setIsCapturing(false);
        if (status === 'capturing') {
          updateStatus('idle');
        }
      };

    } catch (error) {
      console.error('[VIDEO-STT] âŒ ìº¡ì²˜ ì‹œì‘ ì˜¤ë¥˜:', error);
      updateStatus('error');
      
      if (error instanceof Error) {
        alert(`ì˜¤ë¥˜: ${error.message}`);
      }
    }
  }, [getVideoElement, onSubtitle, onBufferUpdate, updateStatus, wsUrl, status]);

  // [advice from AI] â˜… startCaptureRefì— í•¨ìˆ˜ ì €ì¥ (ìë™ ì¬ì—°ê²°ì—ì„œ ì‚¬ìš©)
  startCaptureRef.current = startCapture;

  // ìº¡ì²˜ ì¤‘ì§€
  const stopCaptureRef = useRef<() => void>(() => {});
  
  stopCaptureRef.current = () => {
    if (!wsRef.current && !audioContextRef.current) {
      return;
    }
    
    console.log('[VIDEO-STT] ğŸ›‘ ìº¡ì²˜ ì¤‘ì§€');

    // [advice from AI] í—¬ìŠ¤ì²´í¬ ì¸í„°ë²Œ ì •ë¦¬
    if (healthCheckIntervalRef.current) {
      clearInterval(healthCheckIntervalRef.current);
      healthCheckIntervalRef.current = null;
    }
    reconnectAttemptsRef.current = 0;

    if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN) {
      wsRef.current.send(new Blob([]));
      wsRef.current.close();
    }
    wsRef.current = null;

    if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
      audioContextRef.current.close();
    }
    audioContextRef.current = null;

    setIsCapturing(false);
    updateStatus('idle');
  };
  
  const stopCapture = useCallback(() => {
    stopCaptureRef.current();
  }, []);

  useEffect(() => {
    return () => {
      stopCaptureRef.current();
    };
  }, []);

  return {
    isCapturing,
    status,
    startCapture,
    stopCapture
  };
}
